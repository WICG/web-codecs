<pre class='metadata'>
Title: WebCodecs
Repository: w3c/webcodecs
Status: ED
ED: https://w3c.github.io/webcodecs/
TR: https://www.w3.org/TR/webcodecs/
Shortname: webcodecs
Level: None
Group: mediawg
Editor: Chris Cunningham, w3cid 114832, Google Inc. https://www.google.com/
Editor: Paul Adenot, w3cid 62410, Mozilla https://www.mozilla.org/
Editor: Bernard Aboba, w3cid 65611, Microsoft Corporation https://www.microsoft.com/

Abstract: This specification defines interfaces to codecs for encoding and
    decoding of audio, video, and images.

    This specification does not specify or require any particular codec or
    method of encoding or decoding. The purpose of this specification is to
    provide JavaScript interfaces to implementations of existing codec
    technology developed elsewhere. Implementers may support any combination of
    codecs or none at all.

Markup Shorthands:css no, markdown yes, dfn yes
!Participate: <a href="https://github.com/w3c/webcodecs">Git Repository.</a>
!Participate: <a href="https://github.com/w3c/webcodecs/issues/new">File an issue.</a>
!Version History: <a href="https://github.com/w3c/webcodecs/commits">https://github.com/w3c/webcodecs/commits</a>
</pre>

<pre class=link-defaults>
spec:webidl; type:interface; text:Promise
</pre>

<pre class='anchors'>
spec: media-source; urlPrefix: https://www.w3.org/TR/media-source/
    type: method
        for: MediaSource; text: isTypeSupported(); url: #dom-mediasource-istypesupported

spec: html; urlPrefix: https://html.spec.whatwg.org/multipage/;
    for: HTMLMediaElement;
        type: method; text: canPlayType(); url: #dom-navigator-canplaytype
    for: PlatformObject;
        type: attribute; text: [[Detached]]; url: structured-data.html#detached
    for: ImageBitmap;
        type: attribute; text: resizeWidth; url:#dom-imagebitmapoptions-resizewidth
        type: attribute; text: resizeHeight; url:#dom-imagebitmapoptions-resizeheight
        type: dfn; text: cropped to the source rectangle with formatting; url: imagebitmap-and-animations.html#cropped-to-the-source-rectangle-with-formatting
        type: dfn; text: bitmap data; url: imagebitmap-and-animations.html#concept-imagebitmap-bitmap-data
    for: Canvas;
        type: dfn; text: Check the usability of the image argument; url: canvas.html#check-the-usability-of-the-image-argument
    for: origin;
        type: dfn; text: origin; url: origin.html#concept-origin
    for: webappapis;
        type: dfn; text: global object; url: webappapis.html#global-object
        type: dfn; text: entry settings object; url: webappapis.html#entry-settings-object
    for: media;
        type: dfn; text: current playback position; url: media.html#current-playback-position
    type: dfn; text: live; url: infrastructure.html#live

spec: mediacapture-streams; urlPrefix: https://www.w3.org/TR/mediacapture-streams/
    for: mediaDevices;
        type: method; text: getUserMedia(); url: #dom-mediadevices-getusermedia

spec: mediacapture-screen-share; urlPrefix: https://w3c.github.io/mediacapture-screen-share/
    for: mediaDevices; type: method; text: getDisplayMedia(); url: #dom-mediadevices-getdisplaymedia

spec: mediacapture-main; urlPrefix: https://w3c.github.io/mediacapture-main/
    for:MediaStreamTrackState;
        type: enum-value; text: live; url: #idl-def-MediaStreamTrackState.live
        type: enum-value; text: ended; url: #idl-def-MediaStreamTrackState.ended

spec: mimesniff; urlPrefix: https://mimesniff.spec.whatwg.org/#
    type: dfn; text: MIME type; url: mime-type
    type: dfn; text: valid MIME type string; url:valid-mime-type

spec: infra; urlPrefix: https://infra.spec.whatwg.org/#
    type: dfn; text: queue; url: queues
    type: dfn; text: enqueing; url: queue-enqueue;
    type: dfn; text: dequeued; url: queue-dequeue;
    type: dfn; text: empty; url: list-is-empty;
    type: dfn; text: list; url: lists;

spec: mediastream-recording; urlPrefix: https://www.w3.org/TR/mediastream-recording/#
    type: interface; text: MediaRecorder; url: mediarecorder

spec: media-capabilities; urlPrefix: https://w3c.github.io/media-capabilities/#
    type: method; text: decodingInfo(); url: dom-mediacapabilities-decodinginfo
    type: attribute; text: powerEfficient; url: dom-mediacapabilitiesinfo-powerefficient

spec: css-images-3; urlPrefix: https://www.w3.org/TR/css-images-3/
    type: dfn; text: natural dimensions; url: #natural-dimensions
    type: dfn; text: natural width; url: #natural-width
    type: dfn; text: natural height; url: #natural-height

spec: webrtc-svc; urlPrefix: https://w3c.github.io/webrtc-svc/
    type: dfn; text: scalability mode identifier; url:#scalabilitymodes*
</pre>

<style>
main > dl > dd {
  margin-bottom: 1em;
}

table {
  width: 100%;
}

table#sample-types td, table#sample-types th {
  text-align: center;
}

table#sample-types .even {
    background-color: lightgrey;
}


</style>


Definitions {#definitions}
==========================

: <dfn>Codec</dfn>
:: Refers generically to an instance of AudioDecoder, AudioEncoder,
    VideoDecoder, or VideoEncoder.

: <dfn lt="Key Chunk|Key Frame">Key Chunk</dfn>
:: An encoded chunk that does not depend on any other frames for decoding. Also
    commonly referred to as a "key frame".

: <dfn>Internal Pending Output</dfn>
:: Codec outputs such as {{VideoFrame}}s that currently reside in the internal
    pipeline of the underlying codec implementation. The underlying codec
    implementation may emit new outputs only when a new inputs are provided. The
    underlying codec implementation must emit all outputs in response to a
    flush.

: <dfn lt="system resources">Codec System Resources</dfn>
:: Resources including CPU memory, GPU memory, and exclusive handles to specific
    decoding/encoding hardware that may be allocated by the User Agent as part
    of codec configuration or generation of {{AudioData}} and {{VideoFrame}}
    objects. Such resources may be quickly exhausted and should be released
    immediately when no longer in use.

: <dfn>Temporal Layer</dfn>
:: A grouping of {{EncodedVideoChunk}}s whose timestamp cadence produces a
    particular framerate. See {{VideoEncoderConfig/scalabilityMode}}.

: <dfn>Progressive Image</dfn>
:: An image that supports decoding to multiple levels of detail, with lower
    levels becoming available while the encoded data is not yet fully buffered.

: <dfn>Progressive Image Frame Generation</dfn>
:: A generational identifier for a given [=Progressive Image=] decoded output.
    Each successive generation adds additional detail to the decoded output.
    The mechanism for computing a frame's generation is implementer defined.

: <dfn>Primary Image Track</dfn>
:: An image track that is marked by the given image file as being the default
    track. The mechanism for indiciating a primary track is format defined.


<dfn>Codec Processing Model</dfn> {#codec-processing-model-section}
===================================================================

Background {#processing-model-background}
-----------------------------------------

This section is non-normative.

The codec interfaces defined by the specification are designed such that new
codec tasks may be scheduled while previous tasks are still pending. For
example, web authors may call `decode()` without waiting for a previous
`decode()` to complete. This is achieved by offloading underlying codec tasks to
a separate thread for parallel execution.

This section describes threading behaviors as they are visible from the
perspective of web authors. Implementers may choose to use more or less threads
as long the exernally visible behaviors of blocking and sequencing are
maintained as follows.

Control Thread and Codec Thread {#control-thread-and-codec-thread}
------------------------------------------------------------------

All steps in this specificaiton will run on either a [=control thread=] or
a [=codec thread=].

The <dfn>control thread</dfn> is the thread from which authors will construct
a [=codec=] and invoke its methods. Invoking a codec's methods will typically
result in the creation of [=control messages=] which are later executed on the
[=codec thread=]. Each [=webappapis/global object=] has a separate control
thread.

The <dfn>codec thread</dfn> is the thread from which a [=codec=] will
[=dequeue=] [=control messages=] and execute their steps. Each [=codec=]
instance has a separate codec thread. The lifetime of a codec thread matches
that of its associated [=codec=] instance.

The [=control thread=] uses a traditional event loop, as described in
[[!HTML]].

The [=codec thread=] uses a specialized [=codec processing loop=].

Communication from the [=control thread=] to the [=codec thread=] is done using
[=control message=] passing. Communication in the other direction is done using
regular event loop tasks.

Each [=codec=] instance has a single <dfn>control message queue</dfn> that is
a [=queue=] of <dfn>control messages</dfn>.

<dfn lt="Enqueues a control message|Queue a control message">Queuing a control
message</dfn> means [=enqueing=] the message to a [=codec=]’s [=control
message queue=]. Invoking codec methods will often queue a control message
to schedule work.

<dfn lt="running a control message|control message steps">Running a control
message</dfn> means performing a sequence of steps specified by the method
that enqueued the message. The steps of a control message may depend on
<dfn>injected state</dfn>, supplied by the method that enqueued the message.

<dfn lt="Reset the control message queue">Resetting the control message
    queue</dfn> means performing these steps:
1. For each [=control message=] in the [=control message queue=]:
    1. If a control message's [=injected state=] includes a promise, reject
        that promise.
    2. Remove the message from the queue.

The <dfn>codec processing loop</dfn> must run these steps:
1. While true:
    1. If the [=control message queue=] is emtpy, [=continue=].
    2. Dequeue |front message| from the [=control message queue=].
    3. Run [=control message steps=] described by |front message|.

AudioDecoder Interface {#audiodecoder-interface}
================================================

<xmp class='idl'>
[Exposed=(Window,DedicatedWorker)]
interface AudioDecoder {
  constructor(AudioDecoderInit init);

  readonly attribute CodecState state;
  readonly attribute long decodeQueueSize;

  undefined configure(AudioDecoderConfig config);
  undefined decode(EncodedAudioChunk chunk);
  Promise<undefined> flush();
  undefined reset();
  undefined close();

  static Promise<AudioDecoderSupport> isConfigSupported(AudioDecoderConfig config);
};

dictionary AudioDecoderInit {
  required AudioDataOutputCallback output;
  required WebCodecsErrorCallback error;
};

callback AudioDataOutputCallback = undefined(AudioData output);
</xmp>

Internal Slots {#audiodecoder-internal-slots}
---------------------------------------------
: <dfn attribute for=AudioDecoder>[[codec implementation]]</dfn>
:: Underlying decoder implementation provided by the User Agent.
: <dfn attribute for=AudioDecoder>[[output callback]]</dfn>
:: Callback given at construction for decoded outputs.
: <dfn attribute for=AudioDecoder>[[error callback]]</dfn>
:: Callback given at construction for decode errors.
: <dfn attribute for=AudioDecoder>[[key chunk required]]</dfn>
:: A boolean indicating that the next chunk passed to {{AudioDecoder/decode()}}
    must describe a [=key chunk=] as indicated by
    {{EncodedAudioChunk/type}}.

Constructors {#audiodecoder-constructors}
-----------------------------------------
<dfn constructor for=AudioDecoder title="AudioDecoder(init)">
  AudioDecoder(init)
</dfn>
1. Let d be a new {{AudioDecoder}} object.
2. Assign init.output to {{AudioDecoder/[[output callback]]}}.
3. Assign init.error to {{AudioDecoder/[[error callback]]}}.
4. Assign `true` to {{AudioDecoder/[[key chunk required]]}}.
5. Assign "unconfigured" to d.state.
6. Return d.

Attributes {#audiodecoder-attributes}
-------------------------------------
<dl>
  <dt>
    <dfn attribute for=AudioDecoder>state</dfn>
  </dt>
  <dd>Describes the current state of the codec.</dd>
  <dt>
    <dfn attribute for=AudioDecoder>decodeQueueSize</dfn>
  </dt>
  <dd>
    The number of pending decode requests. This number will decrease as the
    underlying codec is ready to accept new input.
  </dd>
</dl>

Methods {#audiodecoder-methods}
-------------------------------
<dl>
  <dt><dfn method for=AudioDecoder>configure(config)</dfn></dt>
  <dd>
    [=Enqueues a control message=] to configure the audio decoder for decoding
    chunks as described by |config|.

    NOTE: This method will trigger a {{NotSupportedError}} if the user agent
        does not support |config|. Authors should first check support by calling
        {{AudioDecoder/isConfigSupported()}} with |config|. User agents are not
        required to support any particular codec type or configuration.

    When invoked, run these steps:
    1. If |config| is not a [=valid AudioDecoderConfig=], throw a
        {{TypeError}}.
    2. If {{AudioDecoder/state}} is `“closed”`, throw an {{InvalidStateError}}.
    3. Set {{AudioDecoder/state}} to `"configured"`.
    4. Set {{AudioDecoder/[[key chunk required]]}} to `true`.
    5. [=Queue a control message=] to configure the decoder with |config|.

    [=Running a control message=] to configure the decoder means running
    these steps:
    1. Let |supported| be the result of running the <a>Check Configuration
        Support</a> algorith with |config|.
    2. If |supported| is `true`, assign
        {{AudioDecoder/[[codec implementation]]}} with an implementation
        supporting |config|.
    3. Otherwise, run the <a>Close AudioDecoder</a> algorithm with
        {{NotSupportedError}}.
  </dd>

  <dt><dfn method for=AudioDecoder>decode(chunk)</dfn></dt>
  <dd>
    [=Enqueues a control message=] to decode the given |chunk|.

    When invoked, run these steps:
    1. If {{AudioDecoder/state}} is not `"configured"`, throw an
        {{InvalidStateError}}.
    2. If {{AudioDecoder/[[key chunk required]]}} is `true`:
        1. If |chunk|.{{EncodedAudioChunk/type}} is not
            {{EncodedAudioChunkType/key}}, throw a {{DataError}}.
        2. Implementers should inspect the |chunk|'s
            {{EncodedAudioChunk/[[internal data]]}} to verify that
            it is truly a [=key chunk=]. If a mismatch is detected, throw a
            {{DataError}}.
        3. Otherwise, assign `false` to
            {{AudioDecoder/[[key chunk required]]}}.
    3. Increment {{AudioDecoder/decodeQueueSize}}.
    4. [=Queue a control message=] to decode the |chunk|.

    [=Running a control message=] to decode the chunk means performing these
    steps:
    1. Attempt to use {{AudioDecoder/[[codec implementation]]}} to decode the
        chunk.
    2. If decoding results in an error, queue a task on the [=control thread=]
        event loop to run the [=Close AudioDecoder=] algorithm with
        {{EncodingError}}.
    3. Queue a task on the [=control thread=] event loop to decrement
        {{AudioDecoder/decodeQueueSize}}
    4. Let |decoded outputs| be a [=list=] of decoded video data outputs emitted
        by {{AudioDecoder/[[codec implementation]]}}.
    5. If |decoded outputs| is not empty, queue a task on the [=control thread=]
        event loop to run the [=Output AudioData=] algorithm with
        |decoded outputs|.
  </dd>

  <dt><dfn method for=AudioDecoder>flush()</dfn></dt>
  <dd>
    Completes all [=control messages=] in the [=control message queue=]
    and emits all outputs.

    When invoked, run these steps:
    1. If {{AudioDecoder/state}} is not `"configured"`, return
        [=a promise rejected with=] {{InvalidStateError}} {{DOMException}}.
    2. Set {{AudioDecoder/[[key chunk required]]}} to `true`.
    3. Let |promise| be a new Promise.
    4. [=Queue a control message=] to flush the codec with |promise|.
    5. Return |promise|.

    [=Running a control message=] to flush the codec means performing these steps
        with |promise|.
    1. Signal {{AudioDecoder/[[codec implementation]]}} to emit all [=internal
        pending outputs=].
    2. Let |decoded outputs| be a [=list=] of decoded audio data outputs emitted
        by {{AudioDecoder/[[codec implementation]]}}.
    3. If |decoded outputs| is not empty, queue a task on the [=control thread=]
        event loop to run the [=Output AudioData=] algorithm with
        |decoded outputs|.
    4. Queue a task on the [=control thread=] event loop to resolve |promise|.
  </dd>

  <dt><dfn method for=AudioDecoder>reset()</dfn></dt>
  <dd>
    Immediately resets all state including configuration,
    [=control messages=] in the [=control message queue=], and all pending
    callbacks.

    When invoked, run the [=Reset AudioDecoder=] algorithm.
  </dd>

  <dt><dfn method for=AudioDecoder>close()</df></dt>
  <dd>
    Immediately aborts all pending work and releases [=system resources=].
    Close is final.

    When invoked, run the [=Close AudioDecoder=] algorithm.
  </dd>

  <dt><dfn method for=AudioDecoder>isConfigSupported(config)</dfn></dt>
  <dd>
    Returns a promise indicating whether the provided |config| is supported by
    the user agent.

    NOTE: The returned {{AudioDecoderSupport}} {{AudioDecoderSupport/config}}
        will contain only the dictionary members that user agent recognized.
        Unrecognized dictionary memebers will be ignored. Authors may detect
        unrecognized dictionary members by comparinging
        {{AudioDecoderSupport/config}} to their provided |config|.

    When invoked, run these steps:
    1. If |config| is not a <a>valid AudioDecoderConfig</a>, return
        [=a promise rejected with=] {{TypeError}}.
    2. Let |p| be a new Promise.
    3. Let |checkSupportQueue| be the result of starting a new <a>parallel
        queue</a>.
    4. Enqueue the following steps to |checkSupportQueue|:
        1. Let |decoderSupport| be a newly constructed
            {{AudioDecoderSupport}}, initialized as follows:
            1. Set {{AudioDecoderSupport/config}} to the result of running the
                <a>Clone Configuration</a> algorithm with |config|.
            2. Set {{AudioDecoderSupport/supported}} to the result of running
                the <a>Check Configuration Support</a> algorithm with |config|.
        2. Resolve |p| with |decoderSupport|.
    5. Return  |p|.
  </dd>
</dl>

Algorithms {#audiodecoder-algorithms}
-------------------------------------
<dl>
  <dt><dfn>Output AudioData</dfn> (with |outputs|)</dt>
  <dd>
    Run these steps:
    1. For each |output| in |outputs|:
        1. Let |data| be an {{AudioData}}, intialized as follows:
            1. Assign `false` to {{AudioData/[[detached]]}}.
            2. Let |resource| be the [=media resource=] described by |output|.
            3. Let |resourceReference| be a reference to |resource|.
            4. Assign |resourceReference| to
                {{AudioData/[[resource reference]]}}.
            5. Let |timestamp| be the {{EncodedAudioChunk/timestamp}} of the
                {{EncodedAudioChunk}} associated with |output|.
            6. Assign |timestamp| to {{AudioData/[[timestamp]]}}.
            7. Assign values to {{AudioData/[[sample format]]}},
                {{AudioData/[[sample rate]]}},
                {{AudioData/[[number of frames]]}}, and
                {{AudioData/[[number of channels]]}} as determined by |output|.
        3. Invoke {{AudioDecoder/[[output callback]]}} with |data|.
  </dd>
  <dt><dfn>Reset AudioDecoder</dfn></dt>
  <dd>
    Run these steps:
    1. If {{AudioDecoder/state}} is `"closed"`, throw an {{InvalidStateError}}.
    2. Set {{AudioDecoder/state}} to `"unconfigured"`.
    3. Signal {{AudioDecoder/[[codec implementation]]}} to cease producing
        output for the previous configuration.
    4. [=Reset the control message queue=].
    5. Set {{AudioDecoder/decodeQueueSize}} to zero.
  </dd>
  <dt><dfn>Close AudioDecoder</dfn> (with error)</dt>
  <dd>
    Run these steps:
    1. Run the [=Reset AudioDecoder=] algorithm.
    2. Set {{AudioDecoder/state}} to `"closed"`.
    3. Clear {{AudioDecoder/[[codec implementation]]}} and release associated
        [=system resources=].
    4. If |error| is set, queue a task on the [=control thread=] event loop to
        invoke the {{AudioDecoder/[[error callback]]}} with |error|.
  </dd>
</dl>

VideoDecoder Interface {#videodecoder-interface}
================================================

<xmp class='idl'>
[Exposed=(Window,DedicatedWorker)]
interface VideoDecoder {
  constructor(VideoDecoderInit init);

  readonly attribute CodecState state;
  readonly attribute long decodeQueueSize;

  undefined configure(VideoDecoderConfig config);
  undefined decode(EncodedVideoChunk chunk);
  Promise<undefined> flush();
  undefined reset();
  undefined close();

  static Promise<VideoDecoderSupport> isConfigSupported(VideoDecoderConfig config);
};

dictionary VideoDecoderInit {
  required VideoFrameOutputCallback output;
  required WebCodecsErrorCallback error;
};

callback VideoFrameOutputCallback = undefined(VideoFrame output);
</xmp>

Internal Slots {#videodecoder-internal-slots}
---------------------------------------------
: <dfn attribute for=VideoDecoder>[[codec implementation]]</dfn>
:: Underlying decoder implementation provided by the User Agent.
: <dfn attribute for=VideoDecoder>[[output callback]]</dfn>
:: Callback given at construction for decoded outputs.
: <dfn attribute for=VideoDecoder>[[error callback]]</dfn>
:: Callback given at construction for decode errors.
: <dfn attribute for=VideoDecoder>[[active decoder config]]</dfn>
:: The {{VideoDecoderConfig}} that is actively applied.
: <dfn attribute for=VideoDecoder>[[key chunk required]]</dfn>
:: A boolean indicating that the next chunk passed to {{VideoDecoder/decode()}}
    must describe a [=key chunk=] as indicated by {{EncodedVideoChunk/type}}.

Constructors {#videodecoder-constructors}
-----------------------------------------
<dfn constructor for=VideoDecoder title="VideoDecoder(init)">
  VideoDecoder(init)
</dfn>
1. Let d be a new VideoDecoder object.
2. Assign `init.output` to the {{VideoDecoder/[[output callback]]}} internal slot.
3. Assign `init.error` to the {{VideoDecoder/[[error callback]]}} internal slot.
4. Assign `true` to {{VideoDecoder/[[key chunk required]]}}.
5. Assign "unconfigured" to `d.state`.
5. Return d.

Attributes {#videodecoder-attributes}
-------------------------------------
<dl>
  <dt>
    <dfn attribute for=VideoDecoder>state</dfn>
  </dt>
  <dd>Describes the current state of the codec.</dd>
  <dt>
    <dfn attribute for=VideoDecoder>decodeQueueSize</dfn>
  </dt>
  <dd>
    The number of pending decode requests. This number will decrease as the
    underlying codec is ready to accept new input.
  </dd>
</dl>

Methods {#videodecoder-methods}
-------------------------------
<dl>
  <dt><dfn method for=VideoDecoder>configure(config)</dfn></dt>
  <dd>
    [=Enqueues a control message=] to configure the video decoder for decoding
    chunks as described by |config|.

    NOTE: This method will trigger a {{NotSupportedError}} if the user agent
        does not support |config|. Authors should first check support by calling
        {{VideoDecoder/isConfigSupported()}} with |config|. User agents are not
        required to support any particular codec type or configuration.

    When invoked, run these steps:
    1. If |config| is not a [=valid VideoDecoderConfig=], throw a
        {{TypeError}}.
    2. If {{VideoDecoder/state}} is `“closed”`, throw an {{InvalidStateError}}.
    3. Set {{VideoDecoder/state}} to `"configured"`.
    4. Set {{VideoDecoder/[[key chunk required]]}} to `true`.
    5. [=Queue a control message=] to configure the decoder with |config|.

    [=Running a control message=] to configure the decoder means running
    these steps:
    1. Let |supported| be the result of running the <a>Check Configuration
        Support</a> algorith with |config|.
    2. If |supported| is `true`, assign
        {{VideoDecoder/[[codec implementation]]}} with an implementation
        supporting |config|.
    3. Otherwise, run the <a>Close VideoDecoder</a> algorithm with
        {{NotSupportedError}} and abort these steps.
    4. Set {{VideoDecoder/[[active decoder config]]}} to `config`.
  </dd>

  <dt><dfn method for=VideoDecoder>decode(chunk)</dfn></dt>
  <dd>
    [=Enqueues a control message=] to decode the given |chunk|.

    NOTE: Authors should call {{VideoFrame/close()}} on ouput
        {{VideoFrame}}s immediately when frames are no longer needed. The
        underlying [=media resource=]s are owned by the {{VideoDecoder}} and
        failing to release them (or waiting for garbage collection) may cause
        decoding to stall.

    When invoked, run these steps:
    1. If {{VideoDecoder/state}} is not `"configured"`, throw an
        {{InvalidStateError}}.
    2. If {{VideoDecoder/[[key chunk required]]}} is `true`:
        1. If |chunk|.{{EncodedVideoChunk/type}} is not
            {{EncodedVideoChunkType/key}}, throw a {{DataError}}.
        2. Implementers should inspect the |chunk|'s
            {{EncodedVideoChunk/[[internal data]]}} to verify that
            it is truly a [=key chunk=]. If a mismatch is detected, throw a
            {{DataError}}.
        3. Otherwise, assign `false` to
            {{VideoDecoder/[[key chunk required]]}}.
    3. Increment {{VideoDecoder/decodeQueueSize}}.
    4. [=Queue a control message=] to decode the |chunk|.

    [=Running a control message=] to decode the chunk means performing these steps:
    1. Attempt to use {{VideoDecoder/[[codec implementation]]}} to decode the
        chunk.
    2. If decoding results in an error, queue a task on the [=control thread=]
        event loop to run the [=Close VideoDecoder=] algorithm with
        {{EncodingError}}.
    3. Queue a task on the [=control thread=] event loop to decrement
        {{VideoDecoder/decodeQueueSize}}
    4. Let |decoded outputs| be a [=list=] of decoded video data outputs emitted
        by {{VideoDecoder/[[codec implementation]]}}.
    5. If |decoded outputs| is not empty, queue a task on the [=control thread=]
        event loop to run the [=Output VideoFrames=] algorithm with
        |decoded outputs|.
  </dd>

  <dt><dfn method for=VideoDecoder>flush()</dfn></dt>
  <dd>
    Completes all [=control messages=] in the [=control message queue=]
    and emits all outputs.

    When invoked, run these steps:
    1. If {{VideoDecoder/state}} is not `"configured"`, return
        [=a promise rejected with=] {{InvalidStateError}} {{DOMException}}.
    2. Set {{VideoDecoder/[[key chunk required]]}} to `true`.
    3. Let |promise| be a new Promise.
    4. [=Queue a control message=] to flush the codec with |promise|.
    5. Return |promise|.

    [=Running a control message=] to flush the codec means performing these steps
        with |promise|.
    1. Signal {{VideoDecoder/[[codec implementation]]}} to emit all [=internal
        pending outputs=].
    2. Let |decoded outputs| be a [=list=] of decoded video data outputs emitted
        by {{VideoDecoder/[[codec implementation]]}}.
    3. If |decoded outputs| is not empty, queue a task on the [=control thread=]
        event loop to run the [=Output VideoFrames=] algorithm with
        |decoded outputs|.
    4. Queue a task on the [=control thread=] event loop to resolve |promise|.
  </dd>

  <dt><dfn method for=VideoDecoder>reset()</dfn></dt>
  <dd>
    Immediately resets all state including configuration,
    [=control messages=] in the [=control message queue=], and all pending
    callbacks.

    When invoked, run the [=Reset VideoDecoder=] algorithm.
  </dd>

  <dt><dfn method for=VideoDecoder>close()</df></dt>
  <dd>
    Immediately aborts all pending work and releases [=system resources=].
    Close is final.

    When invoked, run the [=Close VideoDecoder=] algorithm.
  </dd>

  <dt><dfn method for=VideoDecoder>isConfigSupported(config)</dfn></dt>
  <dd>
    Returns a promise indicating whether the provided |config| is supported by
    the user agent.

    NOTE: The returned {{VideoDecoderSupport}} {{VideoDecoderSupport/config}}
        will contain only the dictionary members that user agent recognized.
        Unrecognized dictionary memebers will be ignored. Authors may detect
        unrecognized dictionary members by comparinging
        {{VideoDecoderSupport/config}} to their provided |config|.

    When invoked, run these steps:
    1. If |config| is not a <a>valid VideoDecoderConfig</a>, return
        [=a promise rejected with=] {{TypeError}}.
    2. Let |p| be a new Promise.
    3. Let |checkSupportQueue| be the result of starting a new <a>parallel
        queue</a>.
    4. Enqueue the following steps to |checkSupportQueue|:
        1. Let |decoderSupport| be a newly constructed
            {{VideoDecoderSupport}}, initialized as follows:
            1. Set {{VideoDecoderSupport/config}} to the result of running the
                <a>Clone Configuration</a> algorithm with |config|.
            2. Set {{VideoDecoderSupport/supported}} to the result of running
                the <a>Check Configuration Support</a> algorithm with |config|.
        2. Resolve |p| with |decoderSupport|.
    5. Return  |p|.
  </dd>
</dl>

Algorithms {#videodecoder-algorithms}
-------------------------------------
<dl>
  <dt><dfn>Output VideoFrames</dfn> (with |outputs|)</dt>
  <dd>
    Run these steps:
    1. For each |output| in |outputs|:
        1. Let |timestamp| and |duration| be the
            {{EncodedVideoChunk/timestamp}} and {{EncodedVideoChunk/duration}}
            from the {{EncodedVideoChunk}} associated with |output|.
        2. Let |displayAspectWidth| and |displayAspectHeight| be undefined.
        3. If {{VideoDecoderConfig/displayAspectWidth}} and
            {{VideoDecoderConfig/displayAspectHeight}} [=map/exist=] in the
            {{VideoDecoder/[[active decoder config]]}}, assign their values to
            |displayAspectWidth| and |displayAspectHeight| respectively.
        4. Let |frame| be the result of running the [=Create a VideoFrame=]
            algorithm with |output|, |timestamp|, |duration|, |displayAspectWidth|
            and |displayAspectHeight|.
        5. Invoke {{VideoDecoder/[[output callback]]}} with |frame|.
  </dd>
  <dt><dfn>Reset VideoDecoder</dfn></dt>
  <dd>
    Run these steps:
    1. If {{VideoDecoder/state}} is `"closed"`, throw an {{InvalidStateError}}.
    2. Set {{VideoDecoder/state}} to `"unconfigured"`.
    3. Signal {{VideoDecoder/[[codec implementation]]}} to cease producing
        output for the previous configuration.
    4. [=Reset the control message queue=].
    5. Set {{VideoDecoder/decodeQueueSize}} to zero.
  </dd>
  <dt><dfn>Close VideoDecoder</dfn> (with |error|)</dt>
  <dd>
    Run these steps:
    1. Run the [=Reset VideoDecoder=] algorithm.
    2. Set {{VideoDecoder/state}} to `"closed"`.
    3. Clear {{VideoDecoder/[[codec implementation]]}} and release associated
        [=system resources=].
    4. If |error| is set, queue a task on the [=control thread=] event loop to
        invoke the {{VideoDecoder/[[error callback]]}} with |error|.
  </dd>
</dl>


AudioEncoder Interface {#audioencoder-interface}
================================================

<xmp class='idl'>
[Exposed=(Window,DedicatedWorker)]
interface AudioEncoder {
  constructor(AudioEncoderInit init);

  readonly attribute CodecState state;
  readonly attribute long encodeQueueSize;

  undefined configure(AudioEncoderConfig config);
  undefined encode(AudioData data);
  Promise<undefined> flush();
  undefined reset();
  undefined close();

  static Promise<AudioEncoderSupport> isConfigSupported(AudioEncoderConfig config);
};

dictionary AudioEncoderInit {
  required EncodedAudioChunkOutputCallback output;
  required WebCodecsErrorCallback error;
};

callback EncodedAudioChunkOutputCallback =
    undefined (EncodedAudioChunk output,
               optional EncodedAudioChunkMetadata metadata = {});
</xmp>

Internal Slots {#audioencoder-internal-slots}
---------------------------------------------
<dl>
<dt><dfn attribute for=AudioEncoder>[[codec implementation]]</dfn></dt>
<dd>Underlying encoder implementation provided by the User Agent.</dd>
<dt><dfn attribute for=AudioEncoder>[[output callback]]</dfn></dt>
<dd>Callback given at construction for encoded outputs.</dd>
<dt><dfn attribute for=AudioEncoder>[[error callback]]</dfn></dt>
<dd>Callback given at construction for encode errors.</dd>
<dt><dfn attribute for=AudioEncoder>[[active encoder config]]</dfn></dt>
<dd>The {{AudioEncoderConfig}} that is actively applied.</dd>
<dt><dfn attribute for=AudioEncoder>[[active output config]]</dfn></dt>
<dd>
  The {{AudioDecoderConfig}} that describes how to decode the most recently
  emitted {{EncodedAudioChunk}}.
</dd>
</dl>

Constructors {#audioencoder-constructors}
-----------------------------------------
<dfn constructor for=AudioEncoder title="AudioEncoder(init)">
  AudioEncoder(init)
</dfn>
1. Let e be a new AudioEncoder object.
2. Assign `init.output` to the {{AudioEncoder/[[output callback]]}} internal slot.
3. Assign `init.error` to the {{AudioEncoder/[[error callback]]}} internal slot.
4. Assign "unconfigured" to `e.state`.
5. Assign `null` to {{AudioEncoder/[[active encoder config]]}}.
6. Assign `null` to {{AudioEncoder/[[active output config]]}}.
7. Return e.

Attributes {#audioencoder-attributes}
-------------------------------------
<dl>
  <dt>
    <dfn attribute for=AudioEncoder>state</dfn>
  </dt>
  <dd>Describes the current state of the codec.</dd>
  <dt>
    <dfn attribute for=AudioEncoder>encodeQueueSize</dfn>
  </dt>
  <dd>
    The number of pending encode requests. This number will decrease as the
    underlying codec is ready to accept new input.
  </dd>
</dl>

Methods {#audioencoder-methods}
-------------------------------
<dl>
  <dt><dfn method for=AudioEncoder>configure(config)</dfn></dt>
  <dd>
    [=Enqueues a control message=] to configure the audio encoder for
    decoding chunks as described by |config|.

    NOTE: This method will trigger a {{NotSupportedError}} if the user agent
        does not support |config|. Authors should first check support by calling
        {{AudioEncoder/isConfigSupported()}} with |config|. User agents are not
        required to support any particular codec type or configuration.

    When invoked, run these steps:
    1. If |config| is not a [=valid AudioEncoderConfig=], throw a
        {{TypeError}}.
    2. If {{AudioEncoder/state}} is `"closed"`, throw an {{InvalidStateError}}.
    3. Set {{AudioEncoder/state}} to `"configured"`.
    4. [=Queue a control message=] to configure the encoder using |config|.

    [=Running a control message=] to configure the encoder means performing these
    steps:
    1. Let |supported| be the result of running the <a>Check Configuration
        Support</a> algorith with |config|.
    2. If |supported| is `true`, assign
        {{AudioEncoder/[[codec implementation]]}} with an implementation
        supporting |config|.
    3. Otherwise, run the <a>Close AudioEncoder</a> algorithm with
        {{NotSupportedError}} and abort these steps.
    4. Assign |config| to {{AudioEncoder/[[active encoder config]]}}
  </dd>

  <dt><dfn method for=AudioEncoder>encode(data)</dfn></dt>
  <dd>
    [=Enqueues a control message=] to encode the given |data|.

    When invoked, run these steps:
    1. If the value of |data|'s {{AudioData/[[detached]]}} internal slot is
        `true`, throw a {{TypeError}}.
    2. If {{AudioEncoder/state}} is not `"configured"`, throw an
        {{InvalidStateError}}.
    3. Let |dataClone| hold the result of running the [=Clone AudioData=]
        algorithm with |data|.
    4. Increment {{AudioEncoder/encodeQueueSize}}.
    5. [=Queue a control message=] to encode |dataClone|.

    [=Running a control message=] to encode the data means performing these steps.
    1. Attempt to use {{AudioEncoder/[[codec implementation]]}} to encode
        the [=media resource=] described by |dataClone|.
    2. If encoding results in an error, queue a task on the [=control thread=]
        event loop to run the [=Close AudioEncoder=] algorithm with
        {{EncodingError}}.
    3. Queue a task on the [=control thread=] event loop to decrement
        {{AudioEncoder/encodeQueueSize}}.
    4. Let |encoded outputs| be a [=list=] of encoded audio data outputs
        emitted by {{AudioEncoder/[[codec implementation]]}}.
    5. If |encoded outputs| is not empty, queue a task on the
        [=control thread=] event loop to run the [=Output EncodedAudioChunks=] algorithm with |encoded outputs|.
  </dd>

  <dt><dfn method for=AudioEncoder>flush()</dfn></dt>
  <dd>
    Completes all [=control messages=] in the [=control message queue=]
    and emits all outputs.

    When invoked, run these steps:
    1. If {{AudioEncoder/state}} is not `"configured"`, return
        [=a promise rejected with=] {{InvalidStateError}} {{DOMException}}.
    2. Let |promise| be a new Promise.
    3. [=Queue a control message=] to flush the codec with |promise|.
    4. Return |promise|.

    [=Running a control message=] to flush the codec means performing these steps
        with |promise|.
    1. Signal {{AudioEncoder/[[codec implementation]]}} to emit all [=internal
        pending outputs=].
    2. Let |encoded outputs| be a [=list=] of encoded audio data outputs
        emitted by {{AudioEncoder/[[codec implementation]]}}.
    5. If |encoded outputs| is not empty, queue a task on the [=control thread=]
        event loop to run the [=Output EncodedAudioChunks=] algorithm with
        |encoded outputs|.
    3. Queue a task on the [=control thread=] event loop to resolve |promise|.
  </dd>

  <dt><dfn method for=AudioEncoder>reset()</dfn></dt>
  <dd>
    Immediately resets all state including configuration,
    [=control messages=] in the [=control message queue=], and all pending
    callbacks.

    When invoked, run the [=Reset AudioEncoder=] algorithm.
  </dd>

  <dt><dfn method for=AudioEncoder>close()</df></dt>
  <dd>
    Immediately aborts all pending work and releases [=system resources=].
    Close is final.

    When invoked, run the [=Close AudioEncoder=] algorithm.
  </dd>

  <dt><dfn method for=AudioEncoder>isConfigSupported(config)</dfn></dt>
  <dd>
    Returns a promise indicating whether the provided |config| is supported by
    the user agent.

    NOTE: The returned {{AudioEncoderSupport}} {{AudioEncoderSupport/config}}
        will contain only the dictionary members that user agent recognized.
        Unrecognized dictionary memebers will be ignored. Authors may detect
        unrecognized dictionary members by comparinging
        {{AudioEncoderSupport/config}} to their provided |config|.

    When invoked, run these steps:
    1. If |config| is not a <a>valid AudioEncoderConfig</a>, return
        [=a promise rejected with=] {{TypeError}}.
    2. Let |p| be a new Promise.
    3. Let |checkSupportQueue| be the result of starting a new <a>parallel
        queue</a>.
    4. Enqueue the following steps to |checkSupportQueue|:
        1. Let |encoderSupport| be a newly constructed
            {{AudioEncoderSupport}}, initialized as follows:
            1. Set {{AudioEncoderSupport/config}} to the result of running the
                <a>Clone Configuration</a> algorithm with |config|.
            2. Set {{AudioEncoderSupport/supported}} to the result of running
                the <a>Check Configuration Support</a> algorithm with |config|.
        2. Resolve |p| with |encoderSupport|.
    5. Return  |p|.
  </dd>
</dl>

Algorithms {#audioencoder-algorithms}
-------------------------------------
<dl>
  <dt><dfn>Output EncodedAudioChunks</dfn> (with |outputs|)</dt>
  <dd>
    Run these steps:
    1. For each |output| in |outputs|:
        1. Let |chunkInit| be an {{EncodedAudioChunkInit}} with the following
            keys:
            1. Let {{EncodedAudioChunkInit/data}} contain the encoded audio data
                from |output|.
            2. Let {{EncodedAudioChunkInit/type}} be the
                {{EncodedAudioChunkType}} of |output|.
            3. Let {{EncodedAudioChunkInit/timestamp}} be the
                {{AudioData/timestamp}} from the AudioData associated with
                |output|.
        2. Let |chunk| be a new {{EncodedAudioChunk}} constructed with
            |chunkInit|.
        3. Let |chunkMetadata| be a new {{EncodedAudioChunkMetadata}}.
        4. Let |encoderConfig| be the
            {{AudioEncoder/[[active encoder config]]}}.
        5. Let |outputConfig| be a new {{AudioDecoderConfig}} that describes
            |output|. Intialize |outputConfig| as follows:
            1. Assign |encoderConfig|.{{AudioEncoderConfig/codec}} to
                |outputConfig|.{{AudioDecoderConfig/codec}}.
            2. Assign |encoderConfig|.{{AudioEncoderConfig/sampleRate}} to
                |outputConfig|.{{AudioDecoderConfig/sampleRate}}.
            3. Assign to
                |encoderConfig|.{{AudioEncoderConfig/numberOfChannels}} to
                |outputConfig|.{{AudioDecoderConfig/numberOfChannels}}.
            4. Assign |outputConfig|.{{AudioDecoderConfig/description}} with a
                sequence of codec specific bytes as determined by the
                {{AudioEncoder/[[codec implementation]]}}. The user agent must
                ensure that the provided description could be used to
                correctly decode output.

                NOTE: The codec specific requirements for populating the
                    {{AudioDecoderConfig/description}} are described in the
                    [[WEBCODECS-CODEC-REGISTRY]].

        6. If |outputConfig| and {{AudioEncoder/[[active output config]]}} are
            not [=equal dictionaries=]:
            1. Assign |outputConfig| to
                |chunkMetadata|.{{EncodedAudioChunkMetadata/decoderConfig}}.
            2. Assign |outputConfig| to
                {{AudioEncoder/[[active output config]]}}.
        7. Invoke {{AudioEncoder/[[output callback]]}} with |chunk| and
            |chunkMetadata|.
  </dd>
  <dt><dfn>Reset AudioEncoder</dfn></dt>
  <dd>
    Run these steps:
    1. If {{AudioEncoder/state}} is `"closed"`, throw an {{InvalidStateError}}.
    2. Set {{AudioEncoder/state}} to `"unconfigured"`.
    3. Set {{AudioEncoder/[[active encoder config]]}} to `null`.
    4. Set {{AudioEncoder/[[active output config]]}} to `null`.
    5. Signal {{AudioEncoder/[[codec implementation]]}} to cease producing
        output for the previous configuration.
    6. [=Reset the control message queue=].
    7. Set {{AudioEncoder/encodeQueueSize}} to zero.
  </dd>
  <dt><dfn>Close AudioEncoder</dfn> (with |error|)</dt>
  <dd>
    Run these steps:
    1. Run the [=Reset AudioEncoder=] algorithm.
    2. Set {{AudioEncoder/state}} to `"closed"`.
    3. Clear {{AudioEncoder/[[codec implementation]]}} and release associated
        [=system resources=].
    4. If |error| is set, queue a task on the [=control thread=] event loop
        invoke the {{AudioEncoder/[[error callback]]}} with |error|.
  </dd>
</dl>

EncodedAudioChunkMetadata {#encoded-audio-chunk-metadata}
---------------------------------------------------------
The following metadata dictionary is emitted by the
{{EncodedVideoChunkOutputCallback}} alongside an associated
{{EncodedVideoChunk}}.

<xmp class='idl'>
dictionary EncodedAudioChunkMetadata {
  AudioDecoderConfig decoderConfig;
};
</xmp>

: <dfn dict-member for=EncodedAudioChunkMetadata>decoderConfig</dfn>
:: A {{AudioDecoderConfig}} that authors may use to decode the associated
    {{EncodedAudioChunk}}.


VideoEncoder Interface {#videoencoder-interface}
================================================

<xmp class='idl'>
[Exposed=(Window,DedicatedWorker)]
interface VideoEncoder {
  constructor(VideoEncoderInit init);

  readonly attribute CodecState state;
  readonly attribute long encodeQueueSize;

  undefined configure(VideoEncoderConfig config);
  undefined encode(VideoFrame frame, optional VideoEncoderEncodeOptions options = {});
  Promise<undefined> flush();
  undefined reset();
  undefined close();

  static Promise<boolean> isConfigSupported(VideoEncoderConfig config);
};

dictionary VideoEncoderInit {
  required EncodedVideoChunkOutputCallback output;
  required WebCodecsErrorCallback error;
};

callback EncodedVideoChunkOutputCallback =
    undefined (EncodedVideoChunk chunk,
               optional EncodedVideoChunkMetadata metadata = {});
</xmp>

Internal Slots {#videoencoder-internal-slots}
---------------------------------------------
<dl>
<dt><dfn attribute for=VideoEncoder>[[codec implementation]]</dfn></dt>
<dd>Underlying encoder implementation provided by the User Agent.</dd>
<dt><dfn attribute for=VideoEncoder>[[output callback]]</dfn></dt>
<dd>Callback given at construction for encoded outputs.</dd>
<dt><dfn attribute for=VideoEncoder>[[error callback]]</dfn></dt>
<dd>Callback given at construction for encode errors.</dd>
<dt><dfn attribute for=VideoEncoder>[[active encoder config]]</dfn></dt>
<dd>The {{VideoEncoderConfig}} that is actively applied.</dd>
<dt><dfn attribute for=VideoEncoder>[[active output config]]</dfn></dt>
<dd>
  The {{VideoDecoderConfig}} that describes how to decode the most recently
  emitted {{EncodedVideoChunk}}.
</dd>
</dl>

Constructors {#videoencoder-constructors}
-----------------------------------------
<dfn constructor for=VideoEncoder title="VideoEncoder(init)">
  VideoEncoder(init)
</dfn>
1. Let e be a new VideoEncoder object.
2. Assign `init.output` to the {{VideoEncoder/[[output callback]]}} internal slot.
3. Assign `init.error` to the {{VideoEncoder/[[error callback]]}} internal slot.
4. Assign "unconfigured" to `e.state`.
5. Return e.

Attributes {#videoencoder-attributes}
-------------------------------------
<dl>
  <dt>
    <dfn attribute for=VideoEncoder>state</dfn>
  </dt>
  <dd>Describes the current state of the codec.</dd>
  <dt>
    <dfn attribute for=VideoEncoder>encodeQueueSize</dfn>
  </dt>
  <dd>
    The number of pending encode requests. This number will decrease as the
    underlying codec is ready to accept new input.
  </dd>
</dl>

Methods {#videoencoder-methods}
-------------------------------
<dl>
  <dt><dfn method for=VideoEncoder>configure(config)</dfn></dt>
  <dd>
    [=Enqueues a control message=] to configure the video encoder for
    decoding chunks as described by |config|.

    NOTE: This method will trigger a {{NotSupportedError}} if the user agent
        does not support |config|. Authors should first check support by calling
        {{VideoEncoder/isConfigSupported()}} with |config|. User agents are not
        required to support any particular codec type or configuration.

    When invoked, run these steps:
    1. If |config| is not a [=valid VideoEncoderConfig=], throw a
        {{TypeError}}.
    2. If {{VideoEncoder/state}} is `"closed"`, throw an {{InvalidStateError}}.
    3. Set {{VideoEncoder/state}} to `"configured"`.
    4. [=Queue a control message=] to configure the encoder using |config|.

    [=Running a control message=] to configure the encoder means performing these
    steps:
    1. Let |supported| be the result of running the <a>Check Configuration
        Support</a> algorith with |config|.
    2. If |supported| is `true`, assign
        {{VideoEncoder/[[codec implementation]]}} with an implementation
        supporting |config|.
    3. Otherwise, run the <a>Close VideoEncoder</a> algorithm with
        {{NotSupportedError}} and abort these steps.
    4. Assign |config| to {{VideoEncoder/[[active encoder config]]}}.
  </dd>

  <dt><dfn method for=VideoEncoder>encode(|frame|, |options|)</dfn></dt>
  <dd>
    [=Enqueues a control message=] to encode the given |frame|.

    When invoked, run these steps:
    1. If the value of |frame|'s {{VideoFrame/[[detached]]}} internal slot is
        `true`, throw a {{TypeError}}.
    2. If {{VideoEncoder/state}} is not `"configured"`, throw an
        {{InvalidStateError}}.
    3. Let |frameClone| hold the result of running the [=Clone VideoFrame=]
        algorithm with |frame|.
    4. Increment {{VideoEncoder/encodeQueueSize}}.
    5. [=Queue a control message=] to encode |frameClone|.

    [=Running a control message=] to encode the frame means performing these steps.
    1. Attempt to use {{VideoEncoder/[[codec implementation]]}} to encode
        |frameClone| according to |options|.
    2. If encoding results in an error, queue a task on the [=control thread=]
        event loop to run the [=Close VideoEncoder=] algorithm with
        {{EncodingError}}.
    3. Queue a task on the [=control thread=] event loop to decrement
        {{VideoEncoder/encodeQueueSize}}.
    4. Let |encoded outputs| be a [=list=] of encoded video data outputs
        emitted by {{VideoEncoder/[[codec implementation]]}}.
    5. If |encoded outputs| is not empty, queue a task on the [=control thread=]
        event loop to run the [=Output EncodedVideoChunks=] algorithm with
        |encoded outputs|.
  </dd>

  <dt><dfn method for=VideoEncoder>flush()</dfn></dt>
  <dd>
    Completes all [=control messages=] in the [=control message queue=]
    and emits all outputs.

    When invoked, run these steps:
    1. If {{VideoEncoder/state}} is not `"configured"`, return
        [=a promise rejected with=] {{InvalidStateError}} {{DOMException}}.
    2. Let |promise| be a new Promise.
    3. [=Queue a control message=] to flush the codec with |promise|.
    4. Return |promise|.

    [=Running a control message=] to flush the codec means performing these steps
        with |promise|.
    1. Signal {{VideoEncoder/[[codec implementation]]}} to emit all [=internal
        pending outputs=].
    2. Let |encoded outputs| be a [=list=] of encoded video data outputs
        emitted by {{VideoEncoder/[[codec implementation]]}}.
    5. If |encoded outputs| is not empty, queue a task on the [=control thread=]
        event loop to run the [=Output EncodedVideoChunks=] algorithm with
        |encoded outputs|.
    3. Queue a task on the [=control thread=] event loop to resolve |promise|.
  </dd>

  <dt><dfn method for=VideoEncoder>reset()</dfn></dt>
  <dd>
    Immediately resets all state including configuration,
    [=control messages=] in the [=control message queue=], and all pending
    callbacks.

    When invoked, run the [=Reset VideoEncoder=] algorithm.
  </dd>

  <dt><dfn method for=VideoEncoder>close()</df></dt>
  <dd>
    Immediately aborts all pending work and releases [=system resources=].
    Close is final.

    When invoked, run the [=Close VideoEncoder=] algorithm.
  </dd>

  <dt><dfn method for=VideoEncoder>isConfigSupported(config)</dfn></dt>
  <dd>
    Returns a promise indicating whether the provided |config| is supported by
    the user agent.

    NOTE: The returned {{VideoEncoderSupport}} {{VideoEncoderSupport/config}}
        will contain only the dictionary members that user agent recognized.
        Unrecognized dictionary memebers will be ignored. Authors may detect
        unrecognized dictionary members by comparinging
        {{VideoEncoderSupport/config}} to their provided |config|.

    When invoked, run these steps:
    1. If |config| is not a <a>valid VideoEncoderConfig</a>, return
        [=a promise rejected with=] {{TypeError}}.
    2. Let |p| be a new Promise.
    3. Let |checkSupportQueue| be the result of starting a new <a>parallel
        queue</a>.
    4. Enqueue the following steps to |checkSupportQueue|:
        1. Let |encoderSupport| be a newly constructed
            {{VideoEncoderSupport}}, initialized as follows:
            1. Set {{VideoEncoderSupport/config}} to the result of running the
                <a>Clone Configuration</a> algorithm with |config|.
            2. Set {{VideoEncoderSupport/supported}} to the result of running
                the <a>Check Configuration Support</a> algorithm with |config|.
        2. Resolve |p| with |encoderSupport|.
    5. Return  |p|.
  </dd>
</dl>

Algorithms {#videoencoder-algorithms}
-------------------------------------
<dl>
  <dt><dfn>Output EncodedVideoChunks</dfn> (with |outputs|)</dt>
  <dd>
    Run these steps:
    1. For each |output| in |outputs|:
        1. Let |chunkInit| be an {{EncodedVideoChunkInit}} with the following
            keys:
            1. Let {{EncodedVideoChunkInit/data}} contain the encoded video data
                from |output|.
            2. Let {{EncodedVideoChunkInit/type}} be the
                {{EncodedVideoChunkType}} of |output|.
            3. Let {{EncodedVideoChunkInit/timestamp}} be the
                {{VideoFrame/[[timestamp]]}} from the {{VideoFrame}}
                associated with |output|.
            4. Let {{EncodedVideoChunkInit/duration}} be the
                {{VideoFrame/[[duration]]}} from the {{VideoFrame}} associated
                with |output|.
        2. Let |chunk| be a new {{EncodedVideoChunk}} constructed with
            |chunkInit|.
        3. Let |chunkMetadata| be a new {{EncodedVideoChunkMetadata}}.
        4. Let |encoderConfig| be the
            {{VideoEncoder/[[active encoder config]]}}.
        5. Let |outputConfig| be a {{VideoDecoderConfig}} that describes
            |output|. Initialize |outputConfig| as follows:
            1. Assign `encoderConfig.codec` to `outputConfig.codec`.
            2. Assign `encoderConfig.width` to `outputConfig.cropWidth`.
            3. Assign `encoderConfig.height` to `outputConfig.cropHeight`.
            4. Assign `encoderConfig.displayWidth` to
                `outputConfig.displayWidth`.
            5. Assign `encoderConfig.displayHeight` to
                `outputConfig.displayHeight`.
            6. Assign the remaining keys of `outputConfig` as determined by
                {{VideoEncoder/[[codec implementation]]}}. The user agent
                must ensure that the configuration is completely described
                such that |outputConfig| could be used to correctly decode
                |output|.

                NOTE: The codec specific requirements for populating the
                    {{VideoDecoderConfig/description}} are described in the
                    [[WEBCODECS-CODEC-REGISTRY]].

        6. If |outputConfig| and {{VideoEncoder/[[active output config]]}} are
            not <a>equal dictionaries</a>:
            1. Assign |outputConfig| to
                |chunkMetadata|.{{EncodedVideoChunkMetadata/decoderConfig}}.
            2. Assign |outputConfig| to
                {{VideoEncoder/[[active output config]]}}.
        7. If |encoderConfig|.{{VideoEncoderConfig/scalabilityMode}}
            describes multiple [=temporal layers=]:
            1. Let |temporal_layer_id| be the zero-based index describing the
                temporal layer for |output|.
            2. Assign |temporal_layer_id| to
                |chunkMetadata|.{{EncodedVideoChunkMetadata/temporalLayerId}}.
        8. Invoke {{VideoEncoder/[[output callback]]}} with |chunk| and
            |chunkMetadata|.
  </dd>
  <dt><dfn>Reset VideoEncoder</dfn></dt>
  <dd>
    Run these steps:
    1. If {{VideoEncoder/state}} is `"closed"`, throw an {{InvalidStateError}}.
    2. Set {{VideoEncoder/state}} to `"unconfigured"`.
    3. Set {{VideoEncoder/[[active encoder config]]}} to `null`.
    4. Set {{VideoEncoder/[[active output config]]}} to `null`.
    5. Signal {{VideoEncoder/[[codec implementation]]}} to cease producing
        output for the previous configuration.
    6. [=Reset the control message queue=].
    7. Set {{VideoEncoder/encodeQueueSize}} to zero.
  </dd>
  <dt><dfn>Close VideoEncoder</dfn> (with |error|)</dt>
  <dd>
    Run these steps:
    1. Run the [=Reset VideoEncoder=] algorithm.
    2. Set {{VideoEncoder/state}} to `"closed"`.
    3. Clear {{VideoEncoder/[[codec implementation]]}} and release associated
        [=system resources=].
    4. If |error| is set, queue a task on the [=control thread=] event loop
        invoke the {{VideoEncoder/[[error callback]]}} with |error|.
  </dd>
</dl>

EncodedVideoChunkMetadata {#encoded-video-chunk-metadata}
---------------------------------------------------------
The following metadata dictionary is emitted by the
{{EncodedVideoChunkOutputCallback}} alongside an associated
{{EncodedVideoChunk}}.

<xmp class='idl'>
dictionary EncodedVideoChunkMetadata {
  VideoDecoderConfig decoderConfig;
  unsigned long temporalLayerId;
};
</xmp>

: <dfn dict-member for=EncodedVideoChunkMetadata>decoderConfig</dfn>
:: A {{VideoDecoderConfig}} that authors may use to decode the associated
    {{EncodedVideoChunk}}.

: <dfn dict-member for=EncodedVideoChunkMetadata>temporalLayerId</dfn>
:: A number that identifies the [=temporal layer=] for the associated
    {{EncodedVideoChunk}}.


Configurations{#configurations}
===============================

<dfn>Check Configuration Support</dfn> (with |config|) {#config-support}
------------------------------------------------------------------------
Run these steps:
1. If the user agent can provide a <a>codec</a> to support all entries of the
    |config|, including applicable default values for keys that are not
    included, return `true`.

    NOTE: The types {{AudioDecoderConfig}}, {{VideoDecoderConfig}},
        {{AudioEncoderConfig}}, and {{VideoEncoderConfig}} each define their
        respective configuration entries and defaults.

    NOTE: Support for a given configuration may change dynamically if the
        hardware is altered (e.g. external GPU unplugged) or if required
        hardware resources are exhausted. User agents should describe support on
        a best-effort basis given the resources that are available at the time
        of the query.

2. Otherwise, return false.

<dfn>Clone Configuration</dfn> (with |config|) {#clone-config}
--------------------------------------------------------------

NOTE: This algorithm will copy only the dictionary members that the user agent
    recognizes as part of the dictionary type.

Run these steps:
1. Let |dictType| be the type of dictionary |config|.
2. Let <var ignore=''>clone</var> be a new empty instance of |dictType|.
3. For each dictionary member |m| defined on |dictType|:
    1. If |m| does not [=map/exist=] in |config|, then [=iteration/continue=].
    2. If `config[m]` is a nested dictionary, set `clone[m]` to the result of
        recursively running the <a>Clone Configuration</a> algorithm with
        `config[m]`.
    3. Otherwise, assign the value of `config[m]` to `clone[m]`.


Signalling Configuration Support{#config-support-info}
------------------------------------------------------

### AudioDecoderSupport ### {#audio-decoder-support}
<xmp class='idl'>
dictionary AudioDecoderSupport {
  boolean supported;
  AudioDecoderConfig config;
};
</xmp>

<dl>
  <dt><dfn dict-member for=AudioDecoderSupport>supported</dfn></dt>
  <dd>
    A boolean indicating the whether the corresponding
    {{AudioDecoderSupport/config}} is supported by the user agent.
  </dd>
  <dt><dfn dict-member for=AudioDecoderSupport>config</dfn></dt>
  <dd>
    An {{AudioDecoderConfig}} used by the user agent in determining the value of
    {{AudioDecoderSupport/supported}}.
  </dd>
</dl>

### VideoDecoderSupport ### {#video-decoder-support}
<xmp class='idl'>
dictionary VideoDecoderSupport {
  boolean supported;
  VideoDecoderConfig config;
};
</xmp>

<dl>
  <dt><dfn dict-member for=VideoDecoderSupport>supported</dfn></dt>
  <dd>
    A boolean indicating the whether the corresponding
    {{VideoDecoderSupport/config}} is supported by the user agent.
  </dd>
  <dt><dfn dict-member for=VideoDecoderSupport>config</dfn></dt>
  <dd>
    A {{VideoDecoderConfig}} used by the user agent in determining the value of
    {{VideoDecoderSupport/supported}}.
  </dd>
</dl>

### AudioEncoderSupport ### {#audio-encoder-support}
<xmp class='idl'>
dictionary AudioEncoderSupport {
  boolean supported;
  AudioEncoderConfig config;
};
</xmp>

<dl>
  <dt><dfn dict-member for=AudioEncoderSupport>supported</dfn></dt>
  <dd>
    A boolean indicating the whether the corresponding
    {{AudioEncoderSupport/config}} is supported by the user agent.
  </dd>
  <dt><dfn dict-member for=AudioEncoderSupport>config</dfn></dt>
  <dd>
    An {{AudioEncoderConfig}} used by the user agent in determining the value of
    {{AudioEncoderSupport/supported}}.
  </dd>
</dl>

### VideoEncoderSupport ### {#video-encoder-support}
<xmp class='idl'>
dictionary VideoEncoderSupport {
  boolean supported;
  VideoEncoderConfig config;
};
</xmp>

<dl>
  <dt><dfn dict-member for=VideoEncoderSupport>supported</dfn></dt>
  <dd>
    A boolean indicating the whether the corresponding
    {{VideoEncoderSupport/config}} is supported by the user agent.
  </dd>
  <dt><dfn dict-member for=VideoEncoderSupport>config</dfn></dt>
  <dd>
    A {{VideoEncoderConfig}} used by the user agent in determining the value of
    {{VideoEncoderSupport/supported}}.
  </dd>
</dl>

<dfn export>Codec String</dfn>{#config-codec-string}
----------------------------------------------------
A codec string describes a given codec format to be used for encoding or
decoding.

A <dfn>valid codec string</dfn> must meet the following conditions.
1. Is valid per the relevant codec specification (see examples below).
2. It describes a single codec.
3. It is unambiguous about codec profile and level for codecs that define these
    concepts.

NOTE: In other media specifications, codec strings historically accompanied a
    [=MIME type=] as the "codecs=" parameter
    ({{MediaSource/isTypeSupported()}}, {{HTMLMediaElement/canPlayType()}})
    [[RFC6381]]. In this specification, encoded media is not containerized;
    hence, only the value of the codecs parameter is accepted.

The format and semantics for codec strings are defined by codec registrations
listed in the [[WEBCODECS-CODEC-REGISTRY]]. A compliant implementation may support any
combination of codec registrations or none at all.

AudioDecoderConfig{#audio-decoder-config}
-----------------------------------------
<xmp class='idl'>
dictionary AudioDecoderConfig {
  required DOMString codec;
  [EnforceRange] required unsigned long sampleRate;
  [EnforceRange] required unsigned long numberOfChannels;
  BufferSource description;
};
</xmp>

To check if an {{AudioDecoderConfig}} is a <dfn>valid AudioDecoderConfig</dfn>,
    run these steps:
1. If codec is not a <a>valid codec string</a>, return `false`.
2. Return `true`.

<dl>
  <dt><dfn dict-member for=AudioDecoderConfig>codec</dfn></dt>
  <dd>Contains a <a>codec string</a> describing the codec.</dd>

  <dt><dfn dict-member for=AudioDecoderConfig>sampleRate</dfn></dt>
  <dd>The number of frame samples per second.</dd>

  <dt><dfn dict-member for=AudioDecoderConfig>numberOfChannels</dfn></dt>
  <dd>The number of audio channels.</dd>

  <dt><dfn dict-member for=AudioDecoderConfig>description</dfn></dt>
  <dd>
    A sequence of codec specific bytes, commonly known as extradata.

    NOTE: The registrations in the [[WEBCODECS-CODEC-REGISTRY]] describe whether/how to
        populate this sequence, corresponding to the provided
        {{AudioDecoderConfig/codec}}.
  </dd>
</dl>


VideoDecoderConfig{#video-decoder-config}
-----------------------------------------
<xmp class='idl'>
dictionary VideoDecoderConfig {
  required DOMString codec;
  BufferSource description;
  [EnforceRange] unsigned long codedWidth;
  [EnforceRange] unsigned long codedHeight;
  [EnforceRange] unsigned long displayAspectWidth;
  [EnforceRange] unsigned long displayAspectHeight;
  HardwareAcceleration hardwareAcceleration = "allow";
};
</xmp>

To check if a {{VideoDecoderConfig}} is a <dfn>valid VideoDecoderConfig</dfn>,
run these steps:
1. If {{VideoDecoderConfig/codec}} is not a <a>valid codec string</a>, return
    `false`.
2. If one of {{VideoDecoderConfig/codedWidth}} or
    {{VideoDecoderConfig/codedHeight}} is provided but the other isn't,
    return `false`.
3. If {{VideoDecoderConfig/codedWidth}} = 0 or
    {{VideoDecoderConfig/codedHeight}} = 0, return `false`.
4. If one of {{VideoDecoderConfig/displayAspectWidth}} or
    {{VideoDecoderConfig/displayAspectHeight}} is provided but the other isn't,
    return `false`.
5. If {{VideoDecoderConfig/displayAspectWidth}} = 0 or
    {{VideoDecoderConfig/displayAspectHeight}} = 0, return `false`.
6. Return `true`.

<dl>
  <dt><dfn dict-member for=VideoDecoderConfig>codec</dfn></dt>
  <dd>Contains a codec string describing the codec.</dd>

  <dt><dfn dict-member for=VideoDecoderConfig>description</dfn></dt>
  <dd>
    A sequence of codec specific bytes, commonly known as extradata.

    NOTE: The registrations in the [[WEBCODECS-CODEC-REGISTRY]] may describe whether/how
        to populate this sequence, corresponding to the provided
        {{VideoDecoderConfig/codec}}.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>codedWidth</dfn></dt>
  <dd>
    Width of the VideoFrame in pixels, prior to any cropping or aspect ratio
        adjustments.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>codedHeight</dfn></dt>
  <dd>
    Height of the VideoFrame in pixels, prior to any cropping or aspect ratio
        adjustments.
  </dd>

  NOTE: {{VideoDecoderConfig/codedWidth}} and {{VideoDecoderConfig/codedHeight}}
    are used when selecting a {{VideoDecoder/[[codec implementation]]}}.

  <dt><dfn dict-member for=VideoDecoderConfig>displayAspectWidth</dfn></dt>
  <dd>
    Horizontal dimension of the VideoFrame's aspect ratio when displayed.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>displayAspectHeight</dfn></dt>
  <dd>
    Vertical dimension of the VideoFrame's aspect ratio when displayed.
  </dd>

Note: {{VideoFrame/displayWidth}} and {{VideoFrame/displayHeight}} can both be
  different from {{VideoDecoderConfig/displayAspectWidth}} and
  {{VideoDecoderConfig/displayAspectHeight}}, but they should have identical
  ratios, after scaling is applied when
  [=create a videoframe|creating the video frame=].

  <dt><dfn dict-member for=VideoDecoderConfig>hardwareAcceleration</dfn></dt>
  <dd>
    Configures hardware acceleration for this codec. See
    {{HardwareAcceleration}}.
  </dd>
</dl>


AudioEncoderConfig{#audio-encoder-config}
-----------------------------------------
<xmp class='idl'>
dictionary AudioEncoderConfig {
  required DOMString codec;
  [EnforceRange] unsigned long sampleRate;
  [EnforceRange] unsigned long numberOfChannels;
  [EnforceRange] unsigned long long bitrate;
};
</xmp>

NOTE: Codec-specific extensions to {{AudioEncoderConfig}} may be defined by the
    registrations in the [[WEBCODECS-CODEC-REGISTRY]].

To check if an {{AudioEncoderConfig}} is a <dfn>valid AudioEncoderConfig</dfn>,
run these steps:
1. If {{AudioEncoderConfig/codec}} is not a <a>valid codec string</a>, return
    `false`.
2. Return `true`.

<dl>
  <dt><dfn dict-member for=AudioEncoderConfig>codec</dfn></dt>
  <dd>Contains a codec string describing the codec.</dd>

  <dt><dfn dict-member for=AudioEncoderConfig>sampleRate</dfn></dt>
  <dd>The number of frame samples per second.</dd>

  <dt><dfn dict-member for=AudioEncoderConfig>numberOfChannels</dfn></dt>
  <dd>The number of audio channels.</dd>

  <dt><dfn dict-member for=AudioEncoderConfig>bitrate</dfn></dt>
  <dd>
    The average bitrate of the encoded audio given in units of bits per second.
  </dd>
</dl>


VideoEncoderConfig{#video-encoder-config}
-----------------------------------------
<xmp class='idl'>
dictionary VideoEncoderConfig {
  required DOMString codec;
  [EnforceRange] unsigned long long bitrate;
  [EnforceRange] required unsigned long width;
  [EnforceRange] required unsigned long height;
  [EnforceRange] unsigned long displayWidth;
  [EnforceRange] unsigned long displayHeight;
  HardwareAcceleration hardwareAcceleration = "allow";
  DOMString scalabilityMode;
};
</xmp>

NOTE: Codec-specific extensions to {{VideoEncoderConfig}} may be defined by the
    registrations in the [[WEBCODECS-CODEC-REGISTRY]].

To check if a {{VideoEncoderConfig}} is a <dfn>valid VideoEncoderConfig</dfn>,
    run these steps:
1. If {{VideoEncoderConfig/codec}} is not a <a>valid codec string</a>, return
    `false`.
2. If {{VideoEncoderConfig/width}} = 0 or {{VideoEncoderConfig/height}}
    = 0, return `false`.
3. If {{VideoEncoderConfig/displayWidth}} = 0 or
    {{VideoEncoderConfig/displayHeight}} = 0, return `false`.
4. Return `true`.

<dl>
  <dt><dfn dict-member for=VideoEncoderConfig>codec</dfn></dt>
  <dd>Contains a <a>codec string</a> describing the codec.</dd>

  <dt><dfn dict-member for=VideoEncoderConfig>bitrate</dfn></dt>
  <dd>The average bitrate of the encoded video given in units of bits per second.</dd>

  <dt><dfn dict-member for=VideoEncoderConfig>width</dfn></dt>
  <dd>
    The encoded width of output {{EncodedVideoChunk}}s in pixels, prior to any
    display aspect ratio adjustments.

    The encoder must scale any {{VideoFrame}} whose
    {{VideoFrame/[[crop width]]}} differs from this value.
  </dd>

  <dt><dfn dict-member for=VideoEncoderConfig>height</dfn></dt>
  <dd>
    The encoded height of output {{EncodedVideoChunk}}s in pixels, prior to any
    display aspect ratio adjustments.

    The encoder must scale any {{VideoFrame}} whose
    {{VideoFrame/[[crop height]]}} differs from this value.
  </dd>
</dl>

<dl>
  <dt><dfn dict-member for=VideoEncoderConfig>displayWidth</dfn></dt>
  <dd>
    The intended display width of output {{EncodedVideoChunk}}s in pixels.
    Defaults to {{VideoEncoderConfig/width}} if not present.
  </dd>

  <dt><dfn dict-member for=VideoEncoderConfig>displayHeight</dfn></dt>
  <dd>
    The intended display height of output {{EncodedVideoChunk}}s in pixels.
    Defaults to {{VideoEncoderConfig/width}} if not present.
  </dd>
</dl>

<div class='note'>
  NOTE: Providing a {{VideoEncoderConfig/displayWidth}} or
      {{VideoEncoderConfig/displayHeight}} that differs from
      {{VideoEncoderConfig/width}} and {{VideoEncoderConfig/height}} signals
      that chunks should be scaled after decoding to arrive at the final
      display aspect ratio.

      For many codecs this is merely pass-through information, but some codecs
      may optionally include display sizing in the bitstream.
</div>

<dl>
  <dt><dfn dict-member for=VideoEncoderConfig>hardwareAcceleration</dfn></dt>
  <dd>
    Configures hardware acceleration for this codec. See
    {{HardwareAcceleration}}.
  </dd>

  <dt><dfn dict-member for=VideoEncoderConfig>scalabilityMode</dfn></dt>
  <dd>
    An encoding [=scalability mode identifier=] as defined by [[WebRTC-SVC]].
  </dd>
</dl>

Hardware Acceleration{#hardware-acceleration}
---------------------------------------------
<xmp class='idl'>
enum HardwareAcceleration {
  "allow",
  "deny",
  "require",
};
</xmp>

When supported, hardware acceleration offloads encoding or decoding to
specialized hardware.

<div class='note'>
  NOTE: Most authors will be best served by using the default of
  {{HardwareAcceleration/allow}}. This gives the user agent flexibility to
  optimize based on its knowledge of the system and configuration. A common
  strategy will be to prioritize hardware acceleration at higher resolutions
  with a fallback to software codecs if hardware acceleration fails.

  Authors should carefully weigh the tradeoffs setting a hardware acceleration
  preference. The precise trade-offs will be device-specific, but authors should
  generally expect the following:

  * Setting a value of {{HardwareAcceleration/require}} may significantly
      restrict what configurations are supported. It may occur that the user's
      device does not offer acceleration for any codec, or only for the most
      common profiles of older codecs.
  * Hardware acceleration does not simply imply faster encoding / decoding.
      Hardware acceleration often has higher startup latency but more consistent
      throughput performance. Acceleration will generally reduce CPU load.
  * For decoding, hardware acceleration is often less robust to inputs that are
      mislabeled or violate the relevant codec specification.
  * Hardware acceleration will often be more power efficient than purely
      software based codecs.
  * For lower resolution content, the overhead added by hardware acceleration
      may yield decreased performance and power efficiency compared to purely
      software based codecs.

  Given these tradeoffs, a good example of using "require" would be if an author
  intends to provide their own software based fallback via WebAssembly.

  Alternatively, a good example of using "disallow" would be if an author is
  especially sensitive to the higher startup latency or decreased robustness
  generally associated with hardware acceleration.
</div>

<dl>
  <dt><dfn enum-value for=HardwareAcceleration>allow</dfn></dt>
  <dd>
    Indicates that the user agent may use hardware acceleration if it is
    available and compatible with other aspects of the codec configuration.
  </dd>
  <dt><dfn enum-value for=HardwareAcceleration>deny</dfn></dt>
  <dd>
    Indicates that the user agent must not use hardware acceleration.

    NOTE: This will cause the configuration to be unsupported on platforms where
    an unaccelerated codec is unavailable or is incompatible with other aspects
    of the codec configuration.
  </dd>
  <dt><dfn enum-value for=HardwareAcceleration>require</dfn></dt>
  <dd>
    Indicates that the user agent must use hardware acceleration.

    NOTE: This will cause the configuration to be unsupported on platforms where
    an accelerated codec is unavailable or is incompatible with other aspects of
    the codec configuration.
  </dd>
</dl>

Configuration Equivalence{#config-equivalence}
----------------------------------------------
Two dictionaries are <dfn>equal dictionaries</dfn> if they contain the same
keys and values. For nested dictionaries, apply this definition recursively.


VideoEncoderEncodeOptions{#video-encoder-options}
-------------------------------------------------

<xmp class='idl'>
dictionary VideoEncoderEncodeOptions {
  boolean keyFrame = false;
};
</xmp>

<dl>
  <dt><dfn dict-member for=VideoEncoderEncodeOptions>keyFrame</dfn></dt>
  <dd>
    A value of `true` indicates that the given frame MUST be encoded as a key
    frame. A value of `false` indicates that the user agent has flexibility to
    decide whether the frame will be encoded as a [=key frame=].
  </dd>
</dl>


CodecState{#codec-state}
------------------------
<xmp class='idl'>
enum CodecState {
  "unconfigured",
  "configured",
  "closed"
};
</xmp>

<dl>
  <dt><dfn enum-value for=CodecState>unconfigured</dfn></dt>
  <dd>The codec is not configured for encoding or decoding.</dd>
  <dt><dfn enum-value for=CodecState>configured</dfn></dt>
  <dd>
    A valid configuration has been provided. The codec is ready for encoding or
        decoding.
  </dd>
  <dt><dfn enum-value for=CodecState>closed</dfn></dt>
  <dd>
    The codec is no longer usable and underlying [=system resources=] have
        been released.
  </dd>
</dl>

WebCodecsErrorCallback{#error-callback}
---------------------------------------
<xmp class='idl'>
callback WebCodecsErrorCallback = undefined(DOMException error);
</xmp>


Encoded Media Interfaces (Chunks) {#encoded-media-interfaces}
=============================================================
These interfaces represent chunks of encoded media.

EncodedAudioChunk Interface {#encodedaudiochunk-interface}
------------------------------------------------------------
<xmp class='idl'>
[Exposed=(Window,DedicatedWorker)]
interface EncodedAudioChunk {
  constructor(EncodedAudioChunkInit init);
  readonly attribute EncodedAudioChunkType type;
  readonly attribute long long timestamp;    // microseconds
  readonly attribute unsigned long byteLength;

  undefined copyTo(ArrayBufferView dst);
};

dictionary EncodedAudioChunkInit {
  required EncodedAudioChunkType type;
  [EnforceRange] required long long timestamp;    // microseconds
  required BufferSource data;
};

enum EncodedAudioChunkType {
    "key",
    "delta",
};
</xmp>

### Internal Slots ### {#encodedaudiochunk-internal-slots}
: <dfn attribute for=EncodedAudioChunk>[[internal data]]</dfn></dt>
:: An array of bytes representing the encoded chunk data.

### Constructors ###{#encodedaudiochunk-constructors}
<dfn constructor for=EncodedAudioChunk title="EncodedAudioChunk(init)">
  EncodedAudioChunk(init)
</dfn>
1. Let |chunk| be a new {{EncodedAudioChunk}} object, initialized as follows
    1. Assign `init.type` to {{EncodedAudioChunk/type}}.
    2. Assign `init.timestamp` to {{EncodedAudioChunk/timestamp}}.
    3. Assign a copy of `init.data` to {{EncodedAudioChunk/[[internal data]]}}.
    4. Assign `init.data.byteLength` to {{EncodedAudioChunk/byteLength}};
5. Return |chunk|.

### Attributes ###{#encodedaudiochunk-attributes}
: <dfn attribute for=EncodedAudioChunk>type</dfn>
:: Describes whether the chunk is a [=key chunk=].

: <dfn attribute for=EncodedAudioChunk>timestamp</dfn>
:: The presentation timestamp, given in microseconds.

: <dfn attribute for=EncodedAudioChunk>byteLength</dfn>
:: The byte length of {{EncodedAudioChunk/[[internal data]]}}.

### Methods ###{#encodedaudiochunk-methods}
: <dfn method for=EncodedAudioChunk>copyTo(dst)</dfn>
:: When invoked, run these steps:
    1. If {{EncodedAudioChunk/byteLength}} is greater than
        |dst|.`byteLength`,
        throw a {{TypeError}}.
    2. Copy the {{EncodedAudioChunk/[[internal data]]}} into |dst|.

EncodedVideoChunk Interface{#encodedvideochunk-interface}
-----------------------------------------------------------
<xmp class='idl'>
[Exposed=(Window,DedicatedWorker)]
interface EncodedVideoChunk {
  constructor(EncodedVideoChunkInit init);
  readonly attribute EncodedVideoChunkType type;
  readonly attribute long long timestamp;    // microseconds
  readonly attribute long long? duration;    // microseconds
  readonly attribute unsigned long byteLength;

  undefined copyTo(ArrayBufferView dst);
};

dictionary EncodedVideoChunkInit {
  required EncodedVideoChunkType type;
  [EnforceRange] required long long timestamp;    // microseconds
  [EnforceRange] long long duration;              // microseconds
  required BufferSource data;
};

enum EncodedVideoChunkType {
    "key",
    "delta",
};
</xmp>

### Internal Slots ### {#encodedvideochunk-internal-slots}
: <dfn attribute for=EncodedVideoChunk>[[internal data]]</dfn></dt>
:: An array of bytes representing the encoded chunk data.

### Constructors ###{#encodedvideochunk-constructors}
<dfn constructor for=EncodedVideoChunk title="EncodedVideoChunk(init)">
  EncodedVideoChunk(init)
</dfn>
1. Let |chunk| be a new {{EncodedVideoChunk}} object, initialized as follows
    1. Assign `init.type` to {{EncodedVideoChunk/type}}.
    2. Assign `init.timestamp` to {{EncodedVideoChunk/timestamp}}.
    3. If duration is present in init, assign `init.duration` to
        {{EncodedVideoChunk/duration}}. Otherwise, assign `null` to
        {{EncodedVideoChunk/duration}}.
    4. Assign a copy of `init.data` to {{EncodedVideoChunk/[[internal data]]}}.
    5. Assign `init.data.byteLength` to {{EncodedVideoChunk/byteLength}};
3. Return |chunk|.

### Attributes ###{#encodedvideochunk-attributes}
: <dfn attribute for=EncodedVideoChunk>type</dfn>
:: Describes whether the chunk is a [=key chunk=].

: <dfn attribute for=EncodedVideoChunk>timestamp</dfn>
:: The presentation timestamp, given in microseconds.

: <dfn attribute for=EncodedVideoChunk>duration</dfn>
:: The presentation duration, given in microseconds.

: <dfn attribute for=EncodedVideoChunk>byteLength</dfn>
:: The byte length of {{EncodedVideoChunk/[[internal data]]}}.

### Methods ###{#encodedvideochunk-methods}
: <dfn method for=EncodedVideoChunk>copyTo(dst)</dfn>
:: When invoked, run these steps:
    1. If {{EncodedVideoChunk/byteLength}} is greater than
        |dst|.`byteLength`,
        throw a {{TypeError}}.
    2. Copy the {{EncodedVideoChunk/[[internal data]]}} into |dst|.


Raw Media Interfaces {#raw-media-interfaces}
====================================================
These interfaces represent unencoded (raw) media.

Memory Model {#raw-media-memory-model}
--------------------------------------

### Background ### {#raw-media-memory-model-background}

This section is non-normative.

Decoded media data may occupy a large amount of system memory. To minimize the
need for expensive copies, this specification defines a scheme for reference
counting (`clone()` and `close()`).

NOTE: Authors should take care to invoke `close()` immediately when frames are
    no longer needed.

### Reference Counting ### {#raw-media-memory-model-reference-counting}

A <dfn>media resource</dfn> is storage for the actual pixel data or the audio
sample data described by a {{VideoFrame}} or {{AudioData}}.

The {{AudioData}} {{AudioData/[[resource reference]]}} and {{VideoFrame}}
{{VideoFrame/[[resource reference]]}} internal slots hold a reference to a
[=media resource=].

{{VideoFrame}}.{{VideoFrame/clone()}} and
{{AudioData}}.{{AudioData/clone()}} return new frame objects whose
`[[resource reference]]` points to the same [=media resource=] as the original
frame.

{{VideoFrame}}.{{VideoFrame/close()}} and {{AudioData}}.{{AudioData/close()}}
will clear their [[resource reference]] slot, releasing the reference their
[=media resource=]

A [=media resource=] must remain alive at least as long as it continues to be
referenced by a `[[resource reference]]`.

NOTE: When a [=media resource=] is no longer referenced by a
    `[[resource reference]]`, the resource may be destroyed. User agents are
    encouraged to destroy such resources quickly to reduce memory pressure and
    facilitate resouce reuse.

AudioData Interface {#audiodata-interface}
---------------------------------------------

<xmp class='idl'>
[Exposed=(Window,DedicatedWorker)]
interface AudioData {
  constructor(AudioDataInit init);

  readonly attribute AudioSampleFormat sampleFormat;
  readonly attribute float sampleRate;
  readonly attribute unsigned long numberOfFrames;
  readonly attribute unsigned long numberOfChannels;
  readonly attribute long long duration;     // microseconds
  readonly attribute long long timestamp;    // microseconds

  unsigned long allocationSize(AudioDataCopyToOptions options);
  undefined copyTo([AllowShared] BufferSource destination, AudioDataCopyToOptions options);
  AudioData clone();
  undefined close();
};

dictionary AudioDataInit {
  required AudioSampleFormat sampleFormat;
  [EnforceRange] required float sampleRate;
  [EnforceRange] required unsigned long numberOfFrames;
  [EnforceRange] required unsigned long numberOfChannels;
  [EnforceRange] required long long timestamp;    // microseconds
  required BufferSource data;
};
</xmp>

### Internal Slots ###{#audiodata-internal-slots}
: <dfn attribute for=AudioData>\[[detached]]</dfn>
:: Boolean indicating whether {{AudioData/close()}} was invoked on this
    {{AudioData}}.

: <dfn attribute for=AudioData>[[resource reference]]</dfn>
:: A reference to a [=media resource=] that stores the audio sample data for
    this {{AudioData}}.

: <dfn attribute for=AudioData>[[sample format]]</dfn>
:: The {{AudioSampleFormat}} used by this {{AudioData}}.

: <dfn attribute for=AudioData>[[sample rate]]</dfn>
:: The sample-rate, in Hz, for this {{AudioData}}.

: <dfn attribute for=AudioData>[[number of frames]]</dfn>
:: The number of [=frames=] for this {{AudioData}}.

: <dfn attribute for=AudioData>[[number of channels]]</dfn>
:: The number of audio channels for this {{AudioData}}.

: <dfn attribute for=AudioData>\[[timestamp]]</dfn>
:: The presentation timestamp, in microseconds, for this {{AudioData}}.

### Constructors ###{#audiodata-constructors}
<dfn constructor for=AudioData title="AudioData(init)">
  AudioData(init)
</dfn>
1. Let |frame| be a new {{AudioData}} object, initialized as follows:
    1. Assign `false` to {{AudioData/[[detached]]}}.
    2. Assign |init|.{{AudioDataInit/sampleFormat}} to
        {{AudioData/[[sample format]]}}.
    3. Assign |init|.{{AudioDataInit/sampleRate}} to
        {{AudioData/[[sample rate]]}}.
    4. Assign |init|.{{AudioDataInit/numberOfFrames}} to
        {{AudioData/[[number of frames]]}}.
    5. Assign |init|.{{AudioDataInit/numberOfChannels}} to
        {{AudioData/[[number of channels]]}}.
    6. Assign |init|.{{AudioDataInit/timestamp}} to
        {{AudioData/[[timestamp]]}}.
    7. Let |resource| be a [=media resource=] containing a copy of
        |init|.{{AudioDataInit/data}}.
    8. Let |resourceReference| be a reference to |resource|.
    9. Assign |resourceReference| to {{AudioData/[[resource reference]]}}.
2. Return |frame|.

### Attributes ###{#audiodata-attributes}

: <dfn attribute for=AudioData>sampleFormat</dfn>
:: The {{AudioSampleFormat}} used by this {{AudioData}}.

    The {{AudioData/sampleFormat}} getter steps are to return
    {{AudioData/[[sample format]]}}.

: <dfn attribute for=AudioData>sampleRate</dfn>
:: The sample-rate, in Hz, for this {{AudioData}}.

    The {{AudioData/sampleRate}} getter steps are to return
    {{AudioData/[[sample rate]]}}.

: <dfn attribute for=AudioData>numberOfFrames</dfn>
:: The number of [=frames=] for this {{AudioData}}.

    The {{AudioData/numberOfFrames}} getter steps are to return
    {{AudioData/[[number of frames]]}}.

: <dfn attribute for=AudioData>numberOfChannels</dfn>
:: The number of audio channels for this {{AudioData}}.

    The {{AudioData/numberOfChannels}} getter steps are to return
    {{AudioData/[[number of channels]]}}.

: <dfn attribute for=AudioData>timestamp</dfn>
:: The presentation timestamp, in microseconds, for this {{AudioData}}.

    The {{AudioData/numberOfChannels}} getter steps are to return
    {{AudioData/[[timestamp]]}}.

: <dfn attribute for=AudioData>duration</dfn>
:: The duration, in microseconds, for this {{AudioData}}.

    The {{AudioData/duration}} getter steps are to:
    1. Let |microsecondsPerSecond| be `1,000,000`.
    2. Let |durationInSeconds| be the result of dividing
        {{AudioData/[[number of frames]]}} by {{AudioData/[[sample rate]]}}.
    3. Return the product of |durationInSeconds| and |microsecondsPerSecond|.

### Methods ###{#audiodata-methods}
: <dfn method for=AudioData>allocationSize(|options|)</dfn>
:: Returns the number of bytes required to hold the samples as described by
    |options|.

    When invoked, run these steps:
    1. Let |copyElementCount| be the result of running the
        [=Compute Copy Element Count=] algorithm with |options|.
    2. Let |bytesPerSample| be the number of bytes per sample, as defined by
        the {{AudioData/[[sample format]]}}.
    3. Return the product of multiplying |bytesPerSample| by
        |copyElementCount|.

: <dfn method for=AudioData>copyTo(|destination|, |options|)</dfn>
:: Copies the samples from the specified plane of the {{AudioData}} to the
    destination buffer.

    When invoked, run these steps:
    1. If the value of |frame|'s {{AudioData/[[detached]]}} internal slot is
        `true`, throw an {{InvalidStateError}} {{DOMException}}.
    2. Let |copyElementCount| be the result of running the
        [=Compute Copy Element Count=] algorithm with |options|.
    3. Let |bytesPerSample| be the number of bytes per sample, as defined by
        the {{AudioData/[[sample format]]}}.
    4. If the product of multiplying |bytesPerSample| by |copyElementCount| is
        greater than `destination.byteLength`, throw a {{RangeError}}.
    5. Let |resource| be the [=media resource=] referenced by
        {{AudioData/[[resource reference]]}}.
    6. Let |planeFrames| be the region of |resource| corresponding to
        |options|.{{AudioDataCopyToOptions/planeIndex}}.
    7. Copy elements of |planeFrames| into |destination|, starting with the
        [=frame=] positioned at |options|.{{AudioDataCopyToOptions/frameOffset}}
        and stopping after |copyElementCount| samples have been copied.

: <dfn method for=AudioData>clone()</dfn>
:: Creates a new AudioData with a reference to the same [=media resource=].

    When invoked, run these steps:
    1. If the value of |frame|'s {{AudioData/[[detached]]}} internal slot is
        `true`, throw an {{InvalidStateError}} {{DOMException}}.
    2. Return the result of running the [=Clone AudioData=] algorithm with
        [=this=].

: <dfn method for=AudioData>close()</dfn>
:: Clears all state and releases the reference to the [=media resource=].
    Close is final.

    When invoked, run these steps:
    1. Assign `true` to the {{AudioData/[[detached]]}} internal slot.
    2. Assign `null` to {{AudioData/[[resource reference]]}}.

### Algorithms ### {#audiodata-algorithms}

: <dfn>Compute Copy Element Count</dfn> (with |options|)
:: Run these steps:
    1. Let |frameCount| be the number of frames in the plane identified by
        |options|.{{AudioDataCopyToOptions/planeIndex}}.
    2. If |options|.{{AudioDataCopyToOptions/frameOffset}} is greater than or
        equal to |frameCount|, throw a {{RangeError}}.
    3. Let |copyFrameCount| be the difference of subtracting
        |options|.{{AudioDataCopyToOptions/frameOffset}} from |frameCount|.
    4. If |options|.{{AudioDataCopyToOptions/frameCount}} [=map/exists=]:
        1. If |options|.{{AudioDataCopyToOptions/frameCount}} is greater than
            |copyFrameCount|, throw a {{RangeError}}.
        2. Otherwise, assign |options|.{{AudioDataCopyToOptions/frameCount}}
            to |copyFrameCount|.
    5. Let |elementCount| be |copyFrameCount|.
    6. If {{AudioData/[[sample format]]}} describes an interleaved
        {{AudioSampleFormat}}, mutliply |elementCount| by
        {{AudioData/[[number of channels]]}}
    7. return |elementCount|.

: <dfn>Clone AudioData</dfn> (with |data|)
:: Run these steps:
    1. Let |clone| be a new {{AudioData}} initialized as follows:
        1. Let |resource| be the [=media resource=] refrenced by |data|'s
            {{AudioData/[[resource reference]]}}.
        2. Let |reference| be a new reference to |resource|.
        3. Assign |reference| to {{AudioData/[[resource reference]]}}.
        4. Assign the values of |data|'s {{AudioData/[[detached]]}},
            {{AudioData/[[sample format]]}}, {{AudioData/[[sample rate]]}},
            {{AudioData/[[number of frames]]}},
            {{AudioData/[[number of channels]]}}, and
            {{AudioData/[[timestamp]]}} slots to the corresponding slots in
            |clone|.
    2. Return |clone|.

### AudioDataCopyToOptions ### {#audiodata-copy-to-options}

<xmp class='idl'>
dictionary AudioDataCopyToOptions {
  required unsigned long planeIndex;
  unsigned long frameOffset = 0;
  unsigned long frameCount;
};
</xmp>

: <dfn dict-member for=AudioDataCopyToOptions>planeIndex</dfn>
:: The index identifying the plane to copy from.

: <dfn dict-member for=AudioDataCopyToOptions>frameOffset</dfn>
:: An offset into the source plane data indicating which [=frame=] to begin
    copying from. Defaults to `0`.

: <dfn dict-member for=AudioDataCopyToOptions>frameCount</dfn>
:: The number of [=frames=] to copy. If not provided, the copy will include all
    [=frames=] in the plane beginning with {{AudioDataCopyToOptions/frameOffset}}.

## Audio Sample Format ##{#audio-sample-formats}

An audio sample format describes the numeric type used to represent a
single sample (e.g. 32-bit floating point) and the arrangement of samples from
different channels as either [=interleaved=] or [=planar=]. The <dfn>audio
sample type</dfn> refers solely to the numeric type and interval used to store
the data, this is {{U8}}, {{S16}}, {{S24}}, {{S32}}, or {{FLT}} for respectively
unsigned 8-bits, signed 16-bits, signed 32-bits, signed 32-bits, and 32-bits
floating point number. The [[#audio-buffer-arrangement|audio buffer
arrangement]] refers solely to the way the samples are laid out in memory
([=planar=] or [=interleaved=]).

A <dfn>sample</dfn> refers to a single value that is the magnitude of a
signal at a particular point in time in a particular channel.

A <dfn>frame</dfn> or (sample-frame) refers to a set of values of all channels
of a multi-channel signal, that happen at the exact same time.

Note: Consequently if an audio signal is mono (has only one channel), a frame
and a sample refer to the same thing.

All audio [=samples=] in this specification are using linear pulse-code
modulation (Linear PCM): quantization levels are uniform between values.

Note: The Web Audio API, that is expected to be used with this specificaion,
also uses Linear PCM.

<xmp class='idl'>
enum AudioSampleFormat {
  "U8",
  "S16",
  "S24",
  "S32",
  "FLT",
  "U8P",
  "S16P",
  "S24P",
  "S32P",
  "FLTP",
};
</xmp>

: <dfn enum-value for=AudioSampleFormat>U8</dfn>
:: [[WEBIDL#idl-octet|8-bit unsigned integer]] [=samples=] with [=interleaved=] [[#audio-buffer-arrangement|channel arrangement]].

: <dfn enum-value for=AudioSampleFormat>S16</dfn>
:: [[WEBIDL#idl-short|16-bit signed integer]] [=samples=] with [=interleaved=] [[#audio-buffer-arrangement|channel arrangement]].

: <dfn enum-value for=AudioSampleFormat>S24</dfn>
:: [[WEBIDL#idl-long|32-bit signed integer]] [=samples=] with [=interleaved=] [[#audio-buffer-arrangement|channel arrangement]], holding value in the 24-bit of lowest significance.

: <dfn enum-value for=AudioSampleFormat>S32</dfn>
:: [[WEBIDL#idl-long|32-bit signed integer]] [=samples=] with [=interleaved=] [[#audio-buffer-arrangement|channel arrangement]].

: <dfn enum-value for=AudioSampleFormat>FLT</dfn>
:: [[WEBIDL#idl-float|32-bit float]] [=samples=] with [=interleaved=] [[#audio-buffer-arrangement|channel arrangement]].

: <dfn enum-value for=AudioSampleFormat>U8P</dfn>
:: [[WEBIDL#idl-octet|8-bit unsigned integer]] [=samples=] with [=planar=] [[#audio-buffer-arrangement|channel arrangement]].

: <dfn enum-value for=AudioSampleFormat>S16P</dfn>
:: [[WEBIDL#idl-short|16-bit signed integer]] [=samples=] with [=planar=] [[#audio-buffer-arrangement|channel arrangement]].

: <dfn enum-value for=AudioSampleFormat>S24P</dfn>
:: [[WEBIDL#idl-long|32-bit signed integer]] [=samples=] with [=planar=] [[#audio-buffer-arrangement|channel arrangement]], holding value in the 24-bit of lowest significance.

: <dfn enum-value for=AudioSampleFormat>S32P</dfn>
:: [[WEBIDL#idl-long|32-bit signed integer]] [=samples=] with [=planar=] [[#audio-buffer-arrangement|channel arrangement]].

: <dfn enum-value for=AudioSampleFormat>FLTP</dfn>
:: [[WEBIDL#idl-float|32-bit float]] [=samples=] with [=planar=] [[#audio-buffer-arrangement|channel arrangement]].


### Arrangement of audio buffer ### {#audio-buffer-arrangement}

When an {{AudioData}} has an {{AudioSampleFormat}} that is
<dfn>interleaved</dfn>, the audio samples from different channels are laid out
consecutively in the same buffer, in the order described in the section
[[#audio-channel-ordering]]. The {{AudioData}} has a single plane, that contains a
number of elements therefore equal to {{AudioData/numberOfFrames}} *
{{AudioData/numberOfChannels}}.

When an {{AudioData}} has an {{AudioSampleFormat}} that is
<dfn>planar</dfn>, the audio samples from different channels are laid out
in different buffers, themselves arranged in an order described in the section
[[#audio-channel-ordering]]. The {{AudioData}} has a number of planes equal to the
{{AudioData}}'s {{AudioData/numberOfChannels}}. Each plane contains
{{AudioData/numberOfFrames}} elements.

Note: The [[WEBAUDIO|Web Audio API]] currently uses {{FLTP}} exclusively.

### Magnitude of the audio samples ### {#audio-samples-magnitude}

The <dfn>minimum value</dfn> and <dfn>maximum value</dfn> of an audio sample,
for a particular audio sample type, are the values below which
(respectively above which) audio clipping might occur. They are otherwise regular
types, that can hold values outside this interval during intermeditate
processing.

The <dfn>bias value</dfn> for an audio sample type is the value that often
corresponds to the middle of the range (but often the range is not symmetrical).
An audio buffer comprised only of values equal to the [=bias value=] is silent.

<table id="sample-types">
<thead>
<tr class="header">
<th>[=Audio sample type|Sample type=]</th>
<th>IDL type</th>
<th>[=Minimum value=]</th>
<th>[=Bias value=]</th>
<th>[=Maximum value=]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>{{U8}}</td>
<td>[[WEBIDL#idl-octet|octet]]</td>
<td>0</td>
<td>128</td>
<td>+255</td>
</tr>
<tr class="even">
<td>{{S16}}</td>
<td>[[WEBIDL#idl-short|short]]</td>
<td>-32768</td>
<td>0</td>
<td>+32767</td>
</tr>
<tr class="odd">
<td>{{S24}}</td>
<td>[[WEBIDL#idl-long|long]]</td>
<td>-8388608</td>
<td>0</td>
<td>+8388607</td>
</tr>
<tr class="even">
<td>{{S32}}</td>
<td>[[WEBIDL#idl-long|long]]</td>
<td>-2147483648</td>
<td>0</td>
<td>+2147483647</td>
</tr>
<tr class="odd">
<td>{{FLT}}</td>
<td>[[WEBIDL#idl-float|float]]</td>
<td>-1.0</td>
<td>0.0</td>
<td>+1.0</td>
</tr>
</tbody>
</table>

Note: There is no data type that can hold 24 bits of information conveniently,
but audio content using 24-bit samples is common, so 32-bits integers are
commonly used to hold 24-bit content.

### Audio channel ordering ### {#audio-channel-ordering}

When decoding, the ordering of the audio channels in the resulting {{AudioData}}
MUST be the same as what is present in the {{EncodedAudioChunk}}.

When encoding, the ordering of the audio channels in the resulting
{{EncodedAudioChunk}} MUST be the same as what is preset in the given
{{AudioData}};

In other terms, no channel reordering is performed when encoding and decoding.

Note: The container either implies or specifies the channel mapping: the
channel attributed to a particular channel index.


VideoFrame Interface {#videoframe-interface}
--------------------------------------------

NOTE: {{VideoFrame}} is a {{CanvasImageSource}}. A {{VideoFrame}} may be
    passed to any method accepting a {{CanvasImageSource}}, including
    {{CanvasDrawImage}}'s {{CanvasDrawImage/drawImage()}}.

<xmp class='idl'>
[Exposed=(Window,DedicatedWorker)]
interface VideoFrame {
  constructor(CanvasImageSource image, optional VideoFrameInit init = {});
  constructor(sequence<(Plane or PlaneInit)> planes,
              VideoFramePlaneInit init);

  readonly attribute PixelFormat format;
  readonly attribute FrozenArray<Plane>? planes;
  readonly attribute unsigned long codedWidth;
  readonly attribute unsigned long codedHeight;
  readonly attribute unsigned long cropLeft;
  readonly attribute unsigned long cropTop;
  readonly attribute unsigned long cropWidth;
  readonly attribute unsigned long cropHeight;
  readonly attribute unsigned long displayWidth;
  readonly attribute unsigned long displayHeight;
  readonly attribute long long? duration;     // microseconds
  readonly attribute long long? timestamp;    // microseconds

  VideoFrame clone();
  undefined close();
};

dictionary VideoFrameInit {
  long long duration;     // microseconds
  long long timestamp;    // microseconds
};

dictionary VideoFramePlaneInit {
  required PixelFormat format;
  [EnforceRange] required unsigned long codedWidth;
  [EnforceRange] required unsigned long codedHeight;
  [EnforceRange] unsigned long cropLeft;
  [EnforceRange] unsigned long cropTop;
  [EnforceRange] unsigned long cropWidth;
  [EnforceRange] unsigned long cropHeight;
  [EnforceRange] unsigned long displayWidth;
  [EnforceRange] unsigned long displayHeight;
  [EnforceRange] long long duration;     // microseconds
  [EnforceRange] long long timestamp;    // microseconds
};
</xmp>

### Internal Slots ###{#videoframe-internal-slots}

: <dfn attribute for=VideoFrame>\[[detached]]</dfn>
:: A boolean indicating whether {{destroy()}} was invoked and underlying
    resources have been released.

: <dfn attribute for=VideoFrame>[[resource reference]]</dfn>
:: A reference to the [=media resource=] that stores the pixel data for
    this frame.

: <dfn attribute for=VideoFrame>\[[format]]</dfn>
:: A {{PixelFormat}} describing the pixel format of the {{VideoFrame}}.

: <dfn attribute for=VideoFrame>\[[planes]]</dfn>
:: A list of {{Plane}}s describing the memory layout of the pixel data in
    {{VideoFrame}}. The number of {{Plane}}s and their semantics are
    determined by {{VideoFrame/[[format]]}}.

: <dfn attribute for=VideoFrame>[[coded width]]</dfn>
:: Width of the {{VideoFrame}} in pixels, prior to any cropping or aspect
    ratio adjustments.

: <dfn attribute for=VideoFrame>[[coded height]]</dfn>
:: Height of the {{VideoFrame}} in pixels, prior to any cropping or aspect
    ratio adjustments.

: <dfn attribute for=VideoFrame>[[crop left]]</dfn>
:: The number of pixels to remove from the left of the {{VideoFrame}},
    prior to aspect ratio adjustments.

: <dfn attribute for=VideoFrame>[[crop top]]</dfn>
:: The number of pixels to remove from the top of the {{VideoFrame}},
    prior to aspect ratio adjustments.

: <dfn attribute for=VideoFrame>[[crop width]]</dfn>
:: The width of pixels to include in the crop, starting from cropLeft.

: <dfn attribute for=VideoFrame>[[crop height]]</dfn>
:: The height of pixels to include in the crop, starting from cropLeft.

: <dfn attribute for=VideoFrame>[[display width]]</dfn>
:: Width of the {{VideoFrame}} when displayed after applying aspect ratio
    adjustments.

: <dfn attribute for=VideoFrame>[[display height]]</dfn>
:: Height of the {{VideoFrame}} when displayed after applying aspect ratio
    adjustments.

: <dfn attribute for=VideoFrame>\[[duration]]</dfn>
:: The presentation duration, given in microseconds. The duration is copied
        from the {{EncodedVideoChunk}} corresponding to this {{VideoFrame}}.

: <dfn attribute for=VideoFrame>\[[timestamp]]</dfn>
::  The presentation timestamp, given in microseconds. The timestamp is copied
    from the {{EncodedVideoChunk}} corresponding to this {{VideoFrame}}.

### Constructors ###{#videoframe-constructors}

<dfn constructor for=VideoFrame title="VideoFrame(image, init)">
  VideoFrame(image, init)
</dfn>
1. [=Canvas/Check the usability of the image argument=]. If this throws an
    exception or returns <var ignore=''>bad</var>, then throw an  {{InvalidStateError}} {{DOMException}}.
2. If the [=origin/origin=] of |image|'s image data is not [=same origin=]
    with the [=webappapis/entry settings object=]'s
    [=origin/origin=], then throw a {{SecurityError}}
    {{DOMException}}.
3. Let |frame| be a new {{VideoFrame}}.
5. Switch on |image|:
    - {{HTMLImageElement}}
    - {{SVGImageElement}}
        1. If {{VideoFrameInit/timestamp}} does not [=map/exist=] in
            |init|, throw a {{TypeError}}.
        2. If |image|'s media data has no [=natural dimensions=]
            (e.g., it's a vector graphic with no specified content size), then
            throw an {{InvalidStateError}} {{DOMException}}.
        3. Let |resource| be a new [=media resource=] containing a copy of
            |image|'s media data. If this is an animated image, |image|'s
            [=bitmap data=] must only be taken from the default image of the
            animation (the one that the format defines is to be used when
            animation is not supported or is disabled), or, if there is no
            such image, the first frame of the animation.
        4. Let |width| and |height| be the [=natural width=] and
            [=natural height=] of |image|.
        5. Run the [=VideoFrame/Initialize Frame With Resource and Size=]
            algorithm with |init|, |frame|, |resource|, |width|, and |height|

    - {{HTMLVideoElement}}
        1. If |image|'s {{HTMLMediaElement/networkState}} attribute is
            {{HTMLMediaElement/NETWORK_EMPTY}}, then throw an
            {{InvalidStateError}} {{DOMException}}.
        2. Let |currentPlaybackFrame| be the {{VideoFrame}} at the [=current
            playback position=].
        3. Run the [=VideoFrame/Initialize Frame From Other Frame=] algorithm
            with |init|, |frame|, and |currentPlaybackFrame|.

    - {{HTMLCanvasElement}}
    - {{ImageBitmap}}
    - {{OffscreenCanvas}}
        1. If {{VideoFrameInit/timestamp}} does not [=map/exist=] in
            |init|, throw a {{TypeError}}.
        2. Let |resource| be a new [=media resource=] containing a copy of
            |image|'s [=bitmap data=].

            NOTE: Implementers are should avoid a deep copy by using reference
                coutning where feasible.

        3. Let |width| be `image.width` and |height| be `image.height`.
        4. Run the [=VideoFrame/Initialize Frame With Resource and Size=]
            algorithm with |init|, |frame|, |resource|, |width|, and |height|.

    - {{VideoFrame}}
        1. Run the [=VideoFrame/Initialize Frame From Other Frame=] algorithm
            with |init|, |frame|, and |image|.

6. Return |frame|.


<dfn constructor for=VideoFrame title="VideoFrame(planes, init)">
  VideoFrame(planes, init)
</dfn>
1. If |init| is not a [=valid VideoFramePlaneInit=], throw a
    {{TypeError}}.
2. If |planes| is incompatible with the given {{VideoFramePlaneInit/format}}
    (e.g. wrong number of planes), throw a {{TypeError}}.

    ISSUE: The spec should list additional format specific validation steps (
        e.g. number and order of planes, acceptable sizing, etc...).  See
        [#165](https://github.com/w3c/webcodecs/issues/165).

3. Let |resource| be a new [=media resource=] allocated in accordance with
    |init|.

    ISSUE: The spec should define explicit rules for each
        {{PixelFormat}} and reference them in the steps above. See
        [#165](https://github.com/w3c/webcodecs/issues/165).

    NOTE: The user agent may choose to allocate resource with a larger coded
      size and plane strides to improve memory alignment. Increases will be
      reflected by {{VideoFrame/codedWidth}}, {{VideoFrame/codedHeight}}, and
      {{Plane/stride}}.

4. Let |resourceReference| be a reference to |resource|.
5. Let |frame| be a new {{VideoFrame}} object initialized as follows:
    1. Assign |resourceReference| to
            {{VideoFrame/[[resource reference]]}}.
    2. Assign {{VideoFramePlaneInit/format}} to {{VideoFrame/[[format]]}}.
    3. Assign a new [=list=] to {{VideoFrame/[[planes]]}}.
    4. For each |planeInit| in |planes|:
        1. Copy |planeInit|.{{PlaneInit/src}} to |resource|.

            NOTE: The user agent may use {{VideoFramePlaneInit/cropLeft}}
                and {{VideoFramePlaneInit/cropTop}} to copy only the crop
                region. It may also reposition the crop region within
                |resource|. The final position will be reflected by
                {{VideoFrame/cropLeft}} and {{VideoFrame/cropTop}}.

        2. Let |plane| be a new {{Plane}} initialized as follows:
            1. Assign |frame| to {{Plane/[[parent frame]]}}.
            2. Let |resourceStride| be the stride of the plane coresponding to
                |planeInit| in |resource|.

                ISSUE: The spec should provide a definition (and possibly
                    diagrams) for stride. See
                    [#166](https://github.com/w3c/webcodecs/issues/166).

            3. Assign |resourceStride| to {{Plane/stride}}.
            4. Assign |planeInit|.{{PlaneInit/rows}} to {{Plane/rows}}.
            5. Assign the product of ({{Plane/stride}} * {{Plane/rows}}) to
                {{Plane/length}}.
        3. Append |plane| to {{VideoFrame/[[planes]]}}.

    5. Let |resourceCodedWidth| be the coded width of |resource|.
    6. Let |resourceCodedHeight| be the coded height of |resource|.
    7. Let |resourceCropLeft| be the left offset of the crop origin of
        |resource|.
    8. Let |resourceCropTop| be the top offset of the crop origin of
        |resource|.

        ISSUE: The spec should provide definitions (and possibly diagrams) for
            coded size, crop size, and display size. See
            [#166](https://github.com/w3c/webcodecs/issues/166).

    9. Assign |resourceCodedWidth|, |resourceCodedHeight|, |resourceCropLeft|,
        and |resourceCropTop| to {{VideoFrame/[[coded width]]}},
        {{VideoFrame/[[coded height]]}}, {{VideoFrame/[[crop left]]}}, and
        {{VideoFrame/[[crop top]]}} respectively.
    10. If |init|.{{VideoFramePlaneInit/cropWidth}} [=map/exists=], assign
        it to {{VideoFrame/[[crop width]]}}. Otherwise, assign
        {{VideoFrame/[[coded width]]}} to {{VideoFrame/[[crop width]]}}.
    11. If |init|.{{VideoFramePlaneInit/cropHeight}} [=map/exists=], assign it
        to {{VideoFrame/[[crop height]]}}. Otehrwise, assign
        {{VideoFrame/[[coded height]]}} to {{VideoFrame/[[crop height]]}}.
    12. If |init|.{{VideoFramePlaneInit/displayWidth}} [=map/exists=], assign
        it to {{VideoFrame/[[display width]]}}. Otherwise, assign
        {{VideoFrame/[[crop width]]}} to {{VideoFrame/[[display width]]}}.
    13. If |init|.{{VideoFramePlaneInit/displayHeight}} [=map/exists=], assign
        it to {{VideoFrame/[[display height]]}}. Otherwise, assign
        {{VideoFrame/[[crop height]]}} to {{VideoFrame/[[display height]]}}.
    14. Assign |init|'s {{VideoFramePlaneInit/timestamp}} and
        {{VideoFramePlaneInit/duration}} to {{VideoFrame/[[timestamp]]}} and
        {{VideoFrame/[[duration]]}} respectively.
6. Return |frame|.

### Attributes ###{#videoframe-attributes}
: <dfn attribute for=VideoFrame>format</dfn>
:: Describes the arrangement of bytes in each plane as well as the number and
    order of the planes.

    The {{VideoFrame/format}} getter steps are to return
    {{VideoFrame/[[format]]}}.

: <dfn attribute for=VideoFrame>planes</dfn>
:: Holds pixel data data, laid out as described by format and Plane
    attributes.

    The {{VideoFrame/planes}} getter steps are to return
    {{VideoFrame/[[planes]]}}.

: <dfn attribute for=VideoFrame>codedWidth</dfn>
:: Width of the {{VideoFrame}} in pixels, prior to any cropping or aspect ratio
    adjustments.

    The {{VideoFrame/codedWidth}} getter steps are to return
    {{VideoFrame/[[coded width]]}}.

: <dfn attribute for=VideoFrame>codedHeight</dfn>
:: Height of the VideoFrame in pixels, prior to any cropping or aspect ratio
    adjustments.

    The {{VideoFrame/codedHeight}} getter steps are to return
    {{VideoFrame/[[coded height]]}}.

: <dfn attribute for=VideoFrame>cropLeft</dfn>
:: The number of pixels to remove from the left of the VideoFrame, prior to
    aspect ratio adjustments.

    The {{VideoFrame/cropLeft}} getter steps are to return
    {{VideoFrame/[[crop left]]}}.

: <dfn attribute for=VideoFrame>cropTop</dfn>
:: The number of pixels to remove from the top of the VideoFrame, prior to
    aspect ratio adjustments.

    The {{VideoFrame/cropTop}} getter steps are to return
    {{VideoFrame/[[crop top]]}}.

: <dfn attribute for=VideoFrame>cropWidth</dfn>
:: The width of pixels to include in the crop, starting from cropLeft.

    The {{VideoFrame/cropWidth}} getter steps are to return
    {{VideoFrame/[[crop width]]}}.

: <dfn attribute for=VideoFrame>cropHeight</dfn>
:: The height of pixels to include in the crop, starting from cropLeft.

    The {{VideoFrame/cropHeight}} getter steps are to return
    {{VideoFrame/[[crop height]]}}.

: <dfn attribute for=VideoFrame>displayWidth</dfn>
:: Width of the VideoFrame when displayed after applying aspect ratio
    adjustments.

    The {{VideoFrame/displayWidth}} getter steps are to return
    {{VideoFrame/[[display width]]}}.

: <dfn attribute for=VideoFrame>displayHeight</dfn>
:: Height of the VideoFrame when displayed after applying aspect ratio
    adjustments.

    The {{VideoFrame/displayHeight}} getter steps are to return
    {{VideoFrame/[[display height]]}}.

: <dfn attribute for=VideoFrame>timestamp</dfn>
:: The presentation timestamp, given in microseconds. The timestamp is copied
    from the {{EncodedVideoChunk}} corresponding to this VideoFrame.

    The {{VideoFrame/timestamp}} getter steps are to return
    {{VideoFrame/[[timestamp]]}}.

: <dfn attribute for=VideoFrame>duration</dfn>
:: The presentation duration, given in microseconds. The duration is copied
    from the {{EncodedVideoChunk}} corresponding to this VideoFrame.

    The {{VideoFrame/duration}} getter steps are to return
    {{VideoFrame/[[duration]]}}.

### Methods ###{#videoframe-methods}
: <dfn method for=VideoFrame>clone()</dfn>
:: Creates a new {{VideoFrame}} with a reference to the same
    [=media resource=].

    When invoked, run the these steps:
    1. If the value of |frame|’s {{VideoFrame/[[detached]]}} internal slot is
        `true`, throw an {{InvalidStateError}} {{DOMException}}.
    2. Return the result of running the [=Clone VideoFrame=] algorithm with
        [=this=].


: <dfn method for=VideoFrame>close()</dfn>
:: Clears all state and releases the reference to the [=media resource=].
    Close is final.

    When invoked, run these steps:
    1. Assign `null` to {{VideoFrame/[[resource reference]]}}.
    2. Assign `true` to {{VideoFrame/[[detached]]}}.
    3. Assign `""` to {{VideoFrame/format}}.
    4. Assign `null` to {{VideoFrame/planes}}.
    5. Assign `0` to {{VideoFrame/codedWidth}}, {{VideoFrame/codedHeight}},
        {{VideoFrame/cropLeft}}, {{VideoFrame/cropTop}},
        {{VideoFrame/cropWidth}}, {{VideoFrame/cropHeight}},
        {{VideoFrame/displayWidth}}, and {{VideoFrame/displayHeight}}.
    6. Assign `null` to {{VideoFrame/duration}} and {{VideoFrame/timestamp}}.

### Algorithms ###{#videoframe-algorithms}
  <dfn>Create a VideoFrame</dfn> (with |output|, |timestamp|, |duration|, |displayAspectWidth|, and |displayAspectHeight|)
  1. Let |planes| be a sequence of {{Plane}}s containing the decoded
      video frame data from |output|.
  2. Let |pixelFormat| be the {{PixelFormat}} of |planes|.
  3. Let |init| be a {{VideoFramePlaneInit}} with the following
      keys:
      1. Assign |timestamp| to {{VideoFrameInit/timestamp}}.
      2. Assign |duration| to {{VideoFrameInit/duration}}.
      3. Let {{VideoFramePlaneInit/codedWidth}} and
          {{VideoFramePlaneInit/codedHeight}}
          be the width and height of the decoded video frame |output| in
          pixels, prior to any cropping or aspect ratio adjustments.
      4. Let {{VideoFramePlaneInit/cropLeft}},
          {{VideoFramePlaneInit/cropTop}},
          {{VideoFramePlaneInit/cropWidth}}, and
          {{VideoFramePlaneInit/cropHeight}}
          be the crop region of the decoded video frame |output| in
          pixels, prior to any aspect ratio adjustments.
      5. Let |displayWidth| and |displayHeight| be the the display size of
          the decoded frame in pixels.
      6. If |displayAspectWidth| and |displayAspectHeight| are provided,
          increase |displayWidth| or |displayHeight| until the ratio of
          |displayWidth| to |displayHeight| matches the ratio of
          |displayAspectWidth| to |displayAspectHeight|.
      7. Assign the value of |displayWidth| and |displayHeight| to
          {{VideoFramePlaneInit/displayWidth}} and
          {{VideoFramePlaneInit/displayHeight}} respectively.
  4. Return a new {{VideoFrame}}, constructed with |pixelFormat|,
      |planes|, and |init|.

: To check if a {{VideoFramePlaneInit}} is a
    <dfn>valid VideoFramePlaneInit</dfn>, run these steps:
:: 1. If {{VideoFramePlaneInit/codedWidth}} = 0 or
        {{VideoFramePlaneInit/codedHeight}} = 0,return `false`.
    2. If {{VideoFramePlaneInit/cropWidth}} = 0 or
        {{VideoFramePlaneInit/cropHeight}} = 0, return `false`.
    3. If {{VideoFramePlaneInit/cropTop}} +
        {{VideoFramePlaneInit/cropHeight}} >=
        {{VideoFramePlaneInit/codedHeight}}, return `false`.
    4. If {{VideoFramePlaneInit/cropLeft}} +
        {{VideoFramePlaneInit/cropWidth}} >=
        {{VideoFramePlaneInit/codedWidth}}, return `false`.
    5. If {{VideoFramePlaneInit/displayWidth}} = 0 or
        {{VideoFramePlaneInit/displayHeight}} = 0, return `false`.
    6. Return `true`.

: <dfn for=VideoFrame>Initialize Frame From Other Frame</dfn> (with |init|,
    |frame|, and |otherFrame|)
:: 1. Let |resource| be the [=media resource=] referenced by |otherFrame|'s
        {{VideoFrame/[[resource reference]]}}.
    2. Assign a new reference for |resource| to |frame|'s
        {{VideoFrame/[[resource reference]]}}.
    3. Assign the following attributes from |otherFrame| to |frame|:
        {{VideoFrame/format}}, {{VideoFrame/codedWidth}},
        {{VideoFrame/codedHeight}}, {{VideoFrame/cropLeft}},
        {{VideoFrame/cropTop}}, {{VideoFrame/cropWidth}},
        {{VideoFrame/cropHeight}}, {{VideoFrame/displayWidth}},
        {{VideoFrame/displayHeight}}.
    4. Let |planes| be a new [=list=].
    5. For each |otherPlane| in |otherFrame|.{{VideoFrame/planes}}:
        1. Let |plane| be a new {{Plane}}.
        2. Assign a reference for |frame| to |plane|'s
            {{Plane/[[parent frame]]}}.
        3. Assign the following attributes from |otherPlane| to |plane|:
            {{Plane/stride}}, {{Plane/rows}}, {{Plane/length}}.
        4. Append |plane| to |planes|.
    6. Assign |planes| to |frame|.{{VideoFrame/planes}}.
    7. If {{VideoFrameInit/duration}} [=map/exists=] in |init|, assign it to
        |frame|.{{VideoFrame/duration}}. Otherwise, assign
        |otherFrame|.{{VideoFrame/duration}} to
        |frame|.{{VideoFrame/duration}}.
    8. If {{VideoFrameInit/timestamp}} [=map/exists=] in |init|, assign it to
        |frame|.{{VideoFrame/timestamp}}. Otherwise, assign
        |otherFrame|.{{VideoFrame/timestamp}} to
        |frame|.{{VideoFrame/timestamp}}.

: <dfn for=VideoFrame>Initialize Frame With Resource and Size</dfn> (with
    |init|,  |frame|, |resource|, |width| and |height|)
:: 1. Assign a new reference for |resource| to |frame|'s
        {{VideoFrame/[[resource reference]]}}.
    2. If |resource| uses a recognized {{PixelFormat}}:
        1. Assign the {{PixelFormat}} of |resource| to {{VideoFrame/format}}.
        2. Let |planes| be a list of {{Plane}}s describing the
            [=media resource=] in accordance with the {{VideoFrame/format}}.

            ISSUE: The spec should define explicit rules for each
                {{PixelFormat}} and reference them in the step above. See
                [#165](https://github.com/w3c/webcodecs/issues/165).

        3. Assign |planes| to {{VideoFrame/planes}}.
    3. Otherwise (|resource| does not use a recognized {{PixelFormat}}):
        1. Assign `""` to {{VideoFrame/format}}.
        2. Assign `null` to {{VideoFrame/planes}}.
    4. Assign |width| to the following attributes of |frame|:
        {{VideoFrame/codedWidth}}, {{VideoFrame/cropWidth}},
        {{VideoFrame/displayWidth}}.
    5. Assign |height| to the following attributes of |frame|:
        {{VideoFrame/codedHeight}}, {{VideoFrame/cropHeight}},
        {{VideoFrame/displayHeight}}.
    6. Assign `0` to frame's {{VideoFrame/cropTop}} and
        {{VideoFrame/cropLeft}}.
    7. Assign `init`.{{VideoFrameInit/duration}} to
        |frame|.{{VideoFrame/duration}}.
    8. Assign `init`.{{VideoFrameInit/timestamp}} to
        |frame|.{{VideoFrame/timestamp}}.

: <dfn>Clone VideoFrame</dfn> (with |frame|)
:: 1. Let |clone| be a new {{VideoFrame}} initialized as follows:
        1. Assign |frame|.{{VideoFrame/[[resource reference]]}} to
            {{VideoFrame/[[resource reference]]}}.
        2. Assign |frame|.{{VideoFrame/format}} to {{VideoFrame/format}}.
        3. Assign a new [=list=] to {{VideoFrame/planes}}.
        4. For each |plane| in {{VideoFrame/planes}}:
            1. Let |clonePlane| be a new {{Plane}} initialized as follows:
                1. Assign |clone| to |clonePlane|.{{Plane/[[parent frame]]}}.
                2. Assign |plane|.{{Plane/stride}} to {{Plane/stride}}.
                3. Assign |plane|.{{Plane/rows}} to {{Plane/rows}}.
                4. Assign |plane|.{{Plane/length}} to {{Plane/length}}.
            2. Append |clonePlane| to {{VideoFrame/planes}}.
        5. Assign all remaining attributes of |frame| (
            {{VideoFrame/codedWidth}}, {{VideoFrame/codedHeight}}, etc.) to those of the same name in |clone|.
    2. Return |clone|.

Plane Interface {#plane-interface}
----------------------------------
A {{Plane}} is solely constructed by its {{VideoFrame}}. During construction,
    the User Agent may use knowledge of the frame’s {{PixelFormat}} to add
    padding to the {{Plane}} to improve memory alignment.

A {{Plane}} cannot be used after the {{VideoFrame}} is destroyed. A new
    {{VideoFrame}} can be assembled from existing {{Plane}}s, and the new
    {{VideoFrame}} will remain valid when the original is destroyed. This makes
    it possible to efficiently add an alpha plane to an existing
    {{VideoFrame}}.


<xmp class='idl'>
[Exposed=(Window,DedicatedWorker)]
interface Plane {
  readonly attribute unsigned long stride;
  readonly attribute unsigned long rows;
  readonly attribute unsigned long length;

  undefined readInto(ArrayBufferView dst);
};

dictionary PlaneInit {
  required BufferSource src;
  [EnforceRange] required unsigned long stride;
  [EnforceRange] required unsigned long rows;
};
</xmp>

### Internal Slots ###{#plane-internal-slots}
<dl>
  <dt><dfn attribute for=Plane>[[parent frame]]</dfn></dt>
  <dd>Refers to the {{VideoFrame}} that constructed and owns this plane.</dd>
</dl>

### Attributes ###{#plane-attributes}
<dl>
  <dt><dfn attribute for=Plane>stride</dfn></dt>
  <dd>The width of each row including any padding.</dd>
  <dt><dfn attribute for=Plane>rows</dfn></dt>
  <dd>The number of rows.</dd>
  <dt><dfn attribute for=Plane>length</dfn></dt>
  <dd>The total byte length of the plane (stride * rows).</dd>
</dl>

### Methods ###{#plane-methods}
<dfn method for=Plane>readInto(|dst|)</dfn>

Copies the plane data into dst.

When invoked, run these steps:
1. If {{Plane/[[parent frame]]}} has been destroyed, throw an
    {{InvalidStateError}}.
2. If {{Plane/length}} is greater than |`dst.byteLength`|, throw a
    {{TypeError}}.
3. Let |resource| be the [=media resource=] refrenced by
    {{Plane/[[parent frame]]}}'s {{VideoFrame/[[resource reference]]}}.
4. Let |plane bytes| be the region of bytes in [=media resource=] coresponding
    to this plane.
5. Copy the |plane bytes| into |dst|.


Pixel Format{#pixel-format}
---------------------------
Pixel formats describe the arrangement of bytes in each plane as well as the
number and order of the planes.

NOTE: This section needs work. We expect to add more pixel formats and offer
    much more verbose definitions. For now, please see
    <a href="http://www.fourcc.org/pixel-format/yuv-i420/">
    http://www.fourcc.org/pixel-format/yuv-i420/</a> for a more complete
    description.

<xmp class='idl'>
enum PixelFormat {
  "I420"
};
</xmp>

<dl>
  <dt><dfn enum-value for=PixelFormat>I420</dfn></dt>
  <dd>
    Planar 4:2:0 YUV.
  </dd>
</dl>


Image Decoding {#image-decoding}
====================================

Background {#image-decoding-background}
-------------------------------------

This section is non-normative.

Image codec definitions are typically accompanied by a definition for a
corresponding file format. Hence image decoders often perform both duties of
unpacking (demuxing) as well as decoding the encoded image data. The WebCodecs
{{ImageDecoder}} follows this pattern, which motivates an interface design that
is notably different from that of {{VideoDecoder}} and {{AudioDecoder}}.

In spite of these differences, {{ImageDecoder}} uses the same
[=codec processing model=] as the other codec interfaces. Additionally,
{{ImageDecoder}} uses the {{VideoFrame}} interface to describe decoded outputs.

ImageDecoder Interface {#imagedecoder-interface}
------------------------------------------------

<pre class='idl'>
<xmp>
[Exposed=(Window,DedicatedWorker)]
interface ImageDecoder {
  constructor(ImageDecoderInit init);

  readonly attribute boolean complete;
  readonly attribute Promise<undefined> completed;
  readonly attribute ImageTrackList tracks;

  Promise<ImageDecodeResult> decode(optional ImageDecodeOptions options = {});
  undefined reset();
  undefined close();

  static Promise<boolean> isTypeSupported(DOMString type);
};
</xmp>
</pre>

### Internal Slots ### {#imagedecoder-internal-slots}

: <dfn attribute for=ImageDecoder>\[[ImageTrackList]]</dfn>
:: An {{ImageTrackList}} describing the tracks found in
    {{ImageDecoder/[[encoded data]]}}

: <dfn attribute for=ImageDecoder>\[[complete]]</dfn>
:: A boolean indicating whether {{ImageDecoder/[[encoded data]]}} is completely
    buffered.

: <dfn attribute for=ImageDecoder>[[completed promise]]</dnf>
:: The promise used to signal when {{ImageDecoder/[[complete]]}} becomes
    `true`.

: <dfn attribute for=ImageDecoder>[[codec implementation]]</dfn>
:: An underlying image decoder implementation provided by the User Agent.

: <dfn attribute for=ImageDecoder>[[encoded data]]</dfn>
:: A [=byte sequence=] containing the encoded image data to be decoded.

: <dfn attribute for=ImageDecoder>[[prefer animation]]</dfn>
:: A boolean reflecting the value of {{ImageDecoderInit/preferAnimation}} given
    at construction.

: <dfn attribute for=ImageDecoder>[[pending decode promises]]</dfn>
:: A list of unresolved promises returned by calls to decode().

: <dfn attribute for=ImageDecoder>[[internal selected track index]]</dfn>
:: Identifies the image track within {{ImageDecoder/[[encoded data]]}} that is
    used by decoding algorithms on the [=codec thread=].

: <dfn attribute for=ImageDecoder>[[tracks established]]</dfn>
:: A boolean indicating whether the track list has been established in
    {{ImageDecoder/[[ImageTrackList]]}}.

: <dfn attribute for=ImageDecoder>\[[closed]]</dfn>
:: A boolean indicating that the ImageDecoder is in a permanent closed state
    and can no longer be used.

: <dfn attribute for=ImageDecoder>[[progressive frame generations]]</dfn>
:: A mapping of frame indices to [=Progressive Image Frame Generations=]. The
    values represent the Progressive Image Frame Generation for the
    {{VideoFrame}} which was most recently output by a call to
    {{ImageDecoder/decode()}} with the given frame index.


### Constructor ### {#imagedecoder-constructor}

: <dfn constructor for=ImageDecoder title="ImageDecoder(init)">
    ImageDecoder(init)
    </dfn>
:: NOTE: Calling {{ImageDecoder/decode()}} on the constructed {{ImageDecoder}}
    will trigger a {{NotSupportedError}} if the user agent does not support
    |type|. Authors should first check support by calling
    {{ImageDecoder/isTypeSupported()}} with |type|. User agents are not
    required to support any particular type.

    When invoked, run these steps:
    1. If |init| is not [=valid ImageDecoderInit=], throw a {{TypeError}}.
    2. Let |d| be a new {{ImageDecoder}} object. In the steps below, all
        mentions of {{ImageDecoder}} members apply to |d| unless stated
        otherwise.
    3. Assign {{ImageDecoder/[[ImageTrackList]]}} a new {{ImageTrackList}}
        initialized as follows:
        1. Assign a new [=list=] to {{ImageTrackList/[[track list]]}}.
        2. Assign `-1` to {{ImageTrackList/[[selected index]]}}.
    4. Assign `null` to {{ImageDecoder/[[codec implementation]]}}.
    5. If `init.preferAnimation` [=map/exists=], assign `init.preferAnimation`
        to the {{ImageDecoder/[[prefer animation]]}} internal slot. Otherwise,
        assign 'null' to {{ImageDecoder/[[prefer animation]]}} internal slot.
    7. Assign a new [=list=] to {{ImageDecoder/[[pending decode promises]]}}.
    8. Assign `-1` to {{ImageDecoder/[[internal selected track index]]}}.
    9. Assign `false` to {{ImageDecoder/[[tracks established]]}}.
    10. Assign `false` to {{ImageDecoder/[[closed]]}}.
    11. Assign a new [=map=] to {{ImageDecoder/[[progressive frame
        generations]]}}.
    12. If |init|'s {{ImageDecoderInit/data}} member is of type
        {{ReadableStream}}:
        1. Assign a new [=list=] to {{ImageDecoder/[[encoded data]]}}.
        2. Assign `false` to {{ImageDecoder/complete}}
        3. [=Queue a control message=] to [=configure the image decoder=] with
            |init|.
        4. Let |reader| be the result of [=getting a reader=] for
            {{ImageDecoderInit/data}}.
        5. In parallel, perform the [=Fetch Stream Data Loop=] on |d| with
            |reader|.
    13. Otherwise:
        1. Assert that `init.data` is of type {{BufferSource}}.
        2. Assign a copy of `init.data` to  {{ImageDecoder/[[encoded data]]}}.
        3. Assign `true` to {{ImageDecoder/complete}}.
        4. Reslove {{ImageDecoder/[[completed promise]]}}.
        5. Queue a control message to [=configure the image decoder=] with
            |init|.
        6. Queue a control message to [=decode track metadata=].
    14. return |d|.

    [=Running a control message=] to <dfn>configure the image decoder</dfn>
    means running these steps:
    1. Let |supported| be the result of running the [=ImageDecoder/Check Type
        Support=] algorithm with `init.type`.
    2. If |supported| is `false`, queue a task on the [=control thread=] event
        loop to run the [=ImageDecoder/Close ImageDecoder=] algorithm
        with a {{NotSupportedError}} {{DOMException}} and abort
        these steps.
    3. If |supported| is `true`, assign the
        {{ImageDecoder/[[codec implementation]]}} internal slot with an
        implementation supporting `init.type`
    4. Configure {{ImageDecoder/[[codec implementation]]}} in accordance with
        the values given for {{ImageDecoderInit/premultiplyAlpha}},
        {{ImageDecoderInit/colorSpaceConversion}},
        {{ImageDecoderInit/desiredWidth}}, and
        {{ImageDecoderInit/desiredHeight}}.

    [=Running a control message=] to <dfn>decode track metadata</dfn> means
    running these steps:
    1. Run the [=ImageDecoder/Establish Tracks=] algorithm.

### Attributes ### {#imagedecoder-attributes}
: <dfn attribute for=ImageDecoder>complete</dfn>
:: Indicates whether {{ImageDecoder/[[encoded data]]}} is completely buffered.

    The {{ImageDecoder/complete}} getter steps are to return
    {{ImageDecoder/[[complete]]}}.

: <dfn attribute for=ImageDecoder>completed</dfn>
:: The promise used to signal when {{ImageDecoder/complete}} becomes `true`.

    The {{ImageDecoder/completed}} getter steps are to return
    {{ImageDecoder/[[completed promise]]}}.

: <dfn attribute for=ImageDecoder>tracks</dfn>
:: Returns a [=live=] {{ImageTrackList}}, which provides metadata
    for the available tracks and a mechanism for selecting a track to decode.

    The {{ImageDecoder/tracks}} getter steps are to return
    {{ImageDecoder/[[ImageTrackList]]}}.

### Methods ### {#imagedecoder-methods}
: <dfn method for=ImageDecoder>decode(options)</dfn>
:: Enqueues a control message to decode the frame according to |options|.

    When invoked, run these steps:
    1. If {{ImageDecoder/[[closed]]}} is `true`, return a {{Promise}}
        rejected with an {{InvalidStateError}} {{DOMException}}.
    2. If {{ImageDecoder/[[ImageTrackList]]}}'s
        {{ImageTrackList/[[selected index]]}} is '-1', return a {{Promise}}
        rejected with an {{InvalidStateError}} {{DOMException}}.
    3. If |options| is `undefined`, assign a new {{ImageDecodeOptions}} to
        |options|.
    4. Let |promise| be a new {{Promise}}.
    5. [=Queue a control message=] to decode the the image with |options|, and
        |promise|.
    6. Append |promise| to {{ImageDecoder/[[pending decode promises]]}}.
    7. Return |promise|.

    [=Running a control message=] to decode the image means running these
    steps:
    1. Wait for {{ImageDecoder/[[tracks established]]}} to become `true`.
    2. If |options|.{{ImageDecodeOptions/completeFramesOnly}} is `false` and
        the image is a [=Progressive Image=] for which the user agent supports
        progressive decoding, run the [=Decode Progressive Frame=] algorithm with |options|.{{ImageDecodeOptions/frameIndex}} and |promise|.
    3. Otherwise, run the [=Decode Complete Frame=] algorithm with
        |options|.{{ImageDecodeOptions/frameIndex}} and |promise|.

: <dfn method for=ImageDecoder>reset()</dfn>
:: Immediately aborts all pending work.

    When invoked, run the [=ImageDecoder/Reset ImageDecoder=] algorithm with
    and {{AbortError}} {{DOMException}}.

: <dfn method for=ImageDecoder>close()</dfn>
:: Immediately aborts all pending work and releases system resources. Close is
    final.

    When invoked, run the [=ImageDecoder/Close ImageDecoder=] algorithm with
    and {{AbortError}} {{DOMException}}.

: <dfn method for=ImageDecoder>isTypeSupported(type)</dfn>
:: Returns a promise indicating whether the provided config is supported by the
    user agent.

    When invoked, run these steps:
    1. If |type| is not a [=valid image MIME type=], return a {{Promise}}
        rejected with {{TypeError}}.
    2. Let |p| be a new {{Promise}}.
    3. In parallel, resolve |p| with the result of running the
        [=Check Type Support=] algorithm with |type|.
    4. Return |p|.

### Algorithms ### {#imagedecoder-algorithms}

: <dfn for=ImageDecoder>Fetch Stream Data Loop</dfn> (with |reader|)
:: Run these steps:
    1. Let |readRequest| be the following [=read request=].

        : [=read request/chunk steps=], given |chunk|
        :: 1. If {{ImageDecoder/[[closed]]}} is `true`, abort these steps.
            2. If |chunk| is not a Uint8Array object, queue a task on the
                [=control thread=] event loop to run the
                [=ImageDecoder/Close ImageDecoder=] algorithm with a
                {{DataError}} {{DOMException}} and abort these steps.
            3. Let |bytes| be the byte sequence represented by the Uint8Array
                object.
            4. Append |bytes| to the  {{ImageDecoder/[[encoded data]]}}
                internal slot.
            5. If {{ImageDecoder/[[tracks established]]}} is `false`, run the
                [=Establish Tracks=] algorithm.
            6. Otherwise, run the [=Update Tracks=] algorithm.
            7. Run the [=Fetch Stream Data Loop=] algorithm with |reader|.

        : [=read request/close steps=]
        :: 1. Assign `true` to {{ImageDecoder/complete}}
            2. Resolve {{ImageDecoder/[[completed promise]]}}.

        : [=read request/error steps=]
        :: 1. Queue a task on the [=control thread=] event loop to run the
                [=ImageDecoder/Close ImageDecoder=] algorithm with a
                {{NotReadableError}} {{DOMException}}

    2. Read a chunk from |reader| given |readRequest|.

: <dfn for=ImageDecoder>Establish Tracks</dfn>
:: Run these steps:
    1. Assert {{ImageDecoder/[[tracks established]]}} is `false`.
    2. If {{ImageDecoder/[[encoded data]]}} does not contain enough data to
        determine the number of tracks:
        1. If {{ImageDecoder/complete}} is `true`, queue a task on the
            [=control thread=] event loop to run the [=ImageDecoder/Close ImageDecoder=] algorithm.
        2. Abort these steps.
    3. If the number of tracks is found to be `0`, queue a task on the
        [=control thread=] event loop to run the
        [=ImageDecoder/Close ImageDecoder=] algorithm and abort these steps.
    4. Let |newTrackList| be a new [=list=].
    5. For each |image track| found in {{ImageDecoder/[[encoded data]]}}:
        1. Let |newTrack| be a new {{ImageTrack}}, initialized as follows:
            1. Assign [=this=] to {{ImageTrack/[[ImageDecoder]]}}.
            2. Assign {{ImageDecoder/tracks}} to
                {{ImageTrack/[[ImageTrackList]]}}.
            3. If |image track| is found to be animated, assign `true` to
                |newTrack|'s {{ImageTrack/[[animated]]}} internal slot.
                Otherwise, assign `false`.
            4. If |image track| is found to describe a frame count, assign
                that count to |newTrack|'s {{ImageTrack/[[frame count]]}}
                internal slot. Otherwise, assign `0`.

                NOTE: If [=this=] was constructed with
                  {{ImageDecoderInit/data}} as a {{ReadableStream}}, the
                  {{ImageTrack/frameCount}} may change as additional bytes are
                  appended to {{ImageDecoder/[[encoded data]]}}. See the
                  [=Update Tracks=] algorithm.

            5. If |image track| is found to describe a repetition count,
                assign that count to {{ImageTrack/[[repetition count]]}}
                internal slot. Otherwise, assign `0`.

                NOTE: A value of `Infinity` indicates infinite repetitions.

            6. Assign `false` to |newTrack|'s {{ImageTrack/[[selected]]}}
                internal slot.
        2. Append |newTrack| to |newTrackList|.
    6. Let |selectedTrackIndex| be the result of running the
        [=ImageDecoder/Get Default Selected Track Index=] algorithm with
        |newTrackList|.
    7. Let |selectedTrack| be the track at position |selectedTrackIndex| within
        |newTrackList|.
    8. Assign `true` to |selectedTrack|'s {{ImageTrack/[[selected]]}} internal
        slot.
    8. Assign |selectedTrackIndex| to {{ImageDecoder/[[internal selected track
        index]]}}.
    9. Assign `true` to {{ImageDecoder/[[tracks established]]}}.
    10. Queue a task on the [=control thread=] event loop to perform the
        following steps:
        1. Assign |newTrackList| to the {{ImageDecoder/tracks}}
            {{ImageTrackList/[[track list]]}} internal slot.
        2. Assign |selectedTrackIndex| to {{ImageDecoder/tracks}}
            {{ImageTrackList/[[selected index]]}}.
        3. Resolve {{ImageTrackList/[[ready promise]]}}.

: <dfn for=ImageDecoder>Get Default Selected Track Index</dfn> (with
    |trackList|)
:: Run these steps:
    1. If {{ImageDecoder/[[encoded data]]}} identifies a [=Primary Image
        Track=]:
        1. Let |primaryTrack| be the {{ImageTrack}} from |trackList| that
            describes the [=Primary Image Track=].
        2. Let |primaryTrackIndex| be position of |primaryTrack| within
            |trackList|.
        3. If {{ImageDecoder/[[prefer animation]]}} is `null`, return
            |primaryTrackIndex|.
        4. If |primaryTrack|.{{ImageTrack/animated}} equals
            {{ImageDecoder/[[prefer animation]]}}, return |primaryTrackIndex|.
    2. If any {{ImageTrack}}s in |trackList| have {{ImageTrack/animated}} equal
        to {{ImageDecoder/[[prefer animation]]}}, return the position of the
        earliest such track in |trackList|.
    3. Return `0`.

: <dfn for=ImageDecoder>Update Tracks</dfn>
:: A <dfn>track update struct</dfn> is a [=struct=] that consists of a
    <dfn for="track update struct">track index</dfn> ({{unsigned long}})
    and a <dfn for="track update struct">frame count</dfn>
    ({{unsigned long}}).

    Run these steps:
    1. Assert {{ImageDecoder/[[tracks established]]}} is `true`.
    2. Let |trackChanges| be a new [=list=].
    3. Let |trackList| be a copy of {{ImageDecoder/tracks}}'
        {{ImageTrackList/[[track list]]}}.
    4. For each |track| in |trackList|:
        1. Let |trackIndex| be  the position of |track| in |trackList|.
        2. Let |latestFrameCount| be the frame count as indicated by
            {{ImageDecoder/[[encoded data]]}} for the track corresponding to
            |track|.
        3. Assert that |latestFrameCount| is greater than or equal to
            `track.frameCount`.
        4. If |latestFrameCount| is greater than `track.frameCount`:
            1. Let |change| be a [=track update struct=] whose
                [=track update struct/track index=] is |trackIndex| and
                [=track update struct/frame count=] is |latestFrameCount|.
            2. Append |change| to |tracksChanges|.
    5. If |tracksChanges| is [=list/empty=], abort these steps.
    6. Queue a task on the [=control thread=] event loop to perform the
        following steps:
        1. For each <var ignore=''>update</var> in |trackChanges|:
            1. Let |updateTrack| be the {{ImageTrack}} at position
                `update.trackIndex` within {{ImageDecoder/tracks}}'
                {{ImageTrackList/[[track list]]}}.
            2. Assign `update.frameCount` to |updateTrack|'s
                {{ImageTrack/[[frame count]]}}.
            3. Fire a simple event named {{ImageTrack/change}} at the
                {{ImageDecoder/tracks}} object.

: <dfn for=ImageDecoder>Decode Complete Frame</dfn> (with |frameIndex| and
    |promise|)
:: 1. Assert that {{ImageDecoder/[[tracks established]]}} is `true`.
    2. Assert that {{ImageDecoder/[[internal selected track index]]}} is not
        `-1`.
    3. Let |encodedFrame| be the encoded frame identified by |frameIndex| and
        {{ImageDecoder/[[internal selected track index]]}}.
    4. Wait for any of the following conditions to be true (whichever happens
        first):
        1. {{ImageDecoder/[[encoded data]]}} contains enough bytes to
            completely decode |encodedFrame|.
        2. {{ImageDecoder/[[encoded data]]}} is found to be malformed.
        3. {{ImageDecoder/complete}} is `true`.
        4. {{ImageDecoder/[[closed]]}} is `true`.
    5. If {{ImageDecoder/[[encoded data]]}} is found to be malformed, run the
        [=ImageDecoder/Fatally Reject Bad Data=] algorithm and abort these
        steps.
    6. If {{ImageDecoder/[[encoded data]]}} does not contain enough bytes to
        completely decode |encodedFrame|, run the
        [=ImageDecoder/Reject Infeasible Decode=] algorithm with |promise| and
        abort these steps.
    7. Attempt to use {{ImageDecoder/[[codec implementation]]}} to decode
        |encodedFrame|.
    8. If decoding produces an error, run the
        [=ImageDecoder/Fatally Reject Bad Data=] algorithm and abort these
        steps.
    9. If {{ImageDecoder/[[progressive frame generations]]}} contains an entry
        keyed by |frameIndex|, remove the entry from the map.
    10. Let |output| be the decoded image data emitted by
        {{ImageDecoder/[[codec implementation]]}} corresponding to
        |encodedFrame|.
    11. Let |decodeResult| be a new {{ImageDecodeResult}} initialized as
        follows:
        1. Assign 'true' to {{ImageDecodeResult/complete}}.
        2. Let |timestamp| and |duration| be the presentation timestamp and
            duration for |output| as described by |encodedFrame|. If
            |encodedFrame| does not describe a timestamp or
            duration, assign `null` to the corresponding variable.
        3. Assign {{ImageDecodeResult/image}} with the result of running the
            [=Create a VideoFrame=] algorithm with |output|, |timestamp|, and
            |duration|.
    12. Run the [=ImageDecoder/Resolve Decode=] algorithm with |promise| and
        |decodeResult|.

: <dfn for=ImageDecoder>Decode Progressive Frame</dfn> (with |frameIndex| and
    |promise|)
:: 1. Assert that {{ImageDecoder/[[tracks established]]}} is `true`.
    2. Assert that {{ImageDecoder/[[internal selected track index]]}} is not
        `-1`.
    3. Let |encodedFrame| be the encoded frame identified by |frameIndex| and
        {{ImageDecoder/[[internal selected track index]]}}.
    4. Let |lastFrameGeneration| be `null`.
    5. If {{ImageDecoder/[[progressive frame generations]]}} contains a map
        entry with the key |frameIndex|, assign the value of the map entry to
        |lastFrameGeneration|.
    6. Wait for any of the following conditions to be true (whichever happens
        first):
        1. {{ImageDecoder/[[encoded data]]}} contains enough bytes to decode
            |encodedFrame| to produce an output whose [=Progressive Image
            Frame Generation=] exceeds |lastFrameGeneration|.
        2. {{ImageDecoder/[[encoded data]]}} is found to be malformed.
        3. {{ImageDecoder/complete}} is `true`.
        4. {{ImageDecoder/[[closed]]}} is `true`.
    7. If {{ImageDecoder/[[encoded data]]}} is found to be malformed, run the
        [=ImageDecoder/Fatally Reject Bad Data=] algorithm and abort these
        steps.
    8. Otherwise, if {{ImageDecoder/[[encoded data]]}} does not contain enough
        bytes to decode |encodedFrame| to produce an output whose
        [=Progressive Image Frame Generation=] exceeds |lastFrameGeneration|,
        run the [=ImageDecoder/Reject Infeasible Decode=] algorithm with
        |promise| and abort these steps.
    9. Attempt to use {{ImageDecoder/[[codec implementation]]}} to decode
        |encodedFrame|.
    10. If decoding produces an error, run the
        [=ImageDecoder/Fatally Reject Bad Data=] algorithm and abort these
        steps.
    11. Let |output| be the decoded image data emitted by
        {{ImageDecoder/[[codec implementation]]}} corresponding to
        |encodedFrame|.
    12. Let |decodeResult| be a new {{ImageDecodeResult}}.
    13. If |output| is the final full-detail progressive output corresponding
        to |encodedFrame|:
        1. Assign `true` to |decodeResult|'s {{ImageDecodeResult/complete}}.
        2. If {{ImageDecoder/[[progressive frame generations]]}} contains an
            entry keyed by |frameIndex|, remove the entry from the map.
    14. Otherwise:
        1. Assign `false` to |decodeResult|'s {{ImageDecodeResult/complete}}.
        2. Let |frameGeneration| be the [=Progressive Image Frame Generation=]
            for |output|.
        3. Add a new entry to {{ImageDecoder/[[progressive frame
            generations]]}} with key |frameIndex| and value |frameGeneration|.
    15. Let |timestamp| and |duration| be the presentation timestamp and
            duration for |output| as described by |encodedFrame|. If
            |encodedFrame| does not describe a timestamp or
            duration, assign `null` to the corresponding variable.
    16. Assign {{ImageDecodeResult/image}} with the result of running the
            [=Create a VideoFrame=] algorithm with |output|, |timestamp|, and
            |duration|.
    17. Remove |promise| from {{ImageDecoder/[[pending decode promises]]}}.
    18. Resolve |promise| with |decodeResult|.

: <dfn for=ImageDecoder>Resolve Decode</dfn> (with |promise| and |result|)
:: 1. Queue a task on the [=control thread=] event loop to run these steps:
        1. If {{ImageDecoder/[[closed]]}}, abort these steps.
        2. Assert that |promise| is an element of
            {{ImageDecoder/[[pending decode promises]]}}.
        3. Remove |promise| from {{ImageDecoder/[[pending decode promises]]}}.
        4. Resolve |promise| with |result|.

: <dfn for=ImageDecoder>Reject Infeasible Decode</dfn> (with |promise|)
:: 1. Assert that {{ImageDecoder/complete}} is `true` or
        {{ImageDecoder/[[closed]]}} is `true`.
    2. If {{ImageDecoder/complete}} is `true`, let |exception| be a
            {{RangeError}}. Otherwise, let |exception| be an
            {{InvalidStateError}} {{DOMException}}.
    3. Queue a task on the [=control thread=] event loop to run these steps:
        1. If {{ImageDecoder/[[closed]]}}, abort these steps.
        2. Assert that |promise| is an element of
            {{ImageDecoder/[[pending decode promises]]}}.
        3. Remove |promise| from {{ImageDecoder/[[pending decode promises]]}}.
        4. Reject |promise| with |exception|.

: <dfn for=ImageDecoder>Fatally Reject Bad Data</dfn>
:: 1. Queue a task on the [=control thread=] event loop to run these steps:
        1. If {{ImageDecoder/[[closed]]}}, abort these steps.
        2. Run the [=ImageDecoder/Close ImageDecoder=] algorithm with an
            {{EncodingError}} {{DOMException}}.

: <dfn for=ImageDecoder>Check Type Support</dfn> (with |type|)
:: 1. If the user agent can provide a codec to support decoding |type|, return
        `true`.
    2. Otherwise, return `false`.

: <dfn for=ImageDecoder>Reset ImageDecoder</dfn> (with |exception|)
:: 1. Signal {{ImageDecoder/[[codec implementation]]}} to abort any active
        decoding operation.
    2. For each |decodePromise| in
        {{ImageDecoder/[[pending decode promises]]}}:
        1. Reject |decodePromise| with |exception|.
        2. Remove |decodePromise| from
            {{ImageDecoder/[[pending decode promises]]}}.

: <dfn for=ImageDecoder>Close ImageDecoder</dfn> (with |exception|)
:: 1. Run the [=ImageDecoder/Reset ImageDecoder=] algorithm with |exception|.
    1. Assign `true` to {{ImageDecoder/[[closed]]}}.
    2. Clear {{ImageDecoder/[[codec implementation]]}} and release associated
        [=system resources=].
    3. Remove all entries from {{ImageDecoder/[[ImageTrackList]]}}.
    4. Assign `-1` to {{ImageDecoder/[[ImageTrackList]]}}'s
        {{ImageTrackList/[[selected index]]}}.


ImageDecoderInit Interface {#imagedecoderinit-interface}
--------------------------------------------------------
<pre class='idl'>
<xmp>
typedef (BufferSource or ReadableStream) ImageBufferSource;
dictionary ImageDecoderInit {
  required DOMString type;
  required ImageBufferSource data;
  PremultiplyAlpha premultiplyAlpha = "default";
  ColorSpaceConversion colorSpaceConversion = "default";
  [EnforceRange] unsigned long desiredWidth;
  [EnforceRange] unsigned long desiredHeight;
  boolean preferAnimation;
};
</xmp>
</pre>

To determine if an {{ImageDecoderInit}} is a <dfn>valid ImageDecoderInit</dfn>,
run these steps:
1. If |type| is not a [=valid image MIME type=], return `false`.
2. If |data| is of type {{ReadableStream}} and the ReadableStream is
    [=ReadableStream/disturbed=] or [=ReadableStream/locked=], return `false`.
3. If |data| is of type {{BufferSource}}:
    1. If the result of running  IsDetachedBuffer (described in
        [[!ECMASCRIPT]]) on |data| is `false`, return `false`.
    2. If |data| is [=empty=], return `false`.
4. If {{ImageDecoderInit/desiredWidth}} [=map/exists=] and
    {{ImageDecoderInit/desiredHeight}} does not exist, return `false`.
5. If {{ImageDecoderInit/desiredHeight}} [=map/exists=] and
    {{ImageDecoderInit/desiredWidth}} does not exist, return `false`.
6. Return `true`.

A <dfn>valid image MIME type</dfn> is a string that is a [=valid MIME type
string=] and for which the `type`, per Section 3.1.1.1 of [[RFC7231]], is
`image`.

: <dfn dict-member for=ImageDecoderInit>type</dfn>
:: String containing the MIME type of the image file to be decoded.

: <dfn dict-member for=ImageDecoderInit>data</dfn>
:: {{BufferSource}} or {{ReadableStream}} of bytes representing an encoded
    image file as described by {{ImageDecoderInit/type}}.

: <dfn dict-member for=ImageDecoderInit>premultiplyAlpha</dfn>
:: Controls whether decoded outputs' color channels are to be premultiplied by
    their alpha channel, as defined by {{ImageBitmapOptions/premultiplyAlpha}}
    in {{ImageBitmapOptions}}.

: <dfn dict-member for=ImageDecoderInit>colorSpaceConversion</dfn>
:: Controls whether decoded outputs' color space is converted or ignored, as
    defined by {{ImageBitmapOptions/colorSpaceConversion}} in
    {{ImageBitmapOptions}}.

: <dfn dict-member for=ImageDecoderInit>desiredWidth</dfn>
:: Indicates a desired width for decoded outputs. Implementation is best
    effort; decoding to a desired width may not be supported by all formats/
    decoders.

: <dfn dict-member for=ImageDecoderInit>desiredHeight</dfn>
:: Indicates a desired height for decoded outputs. Implementation is best
    effort; decoding to a desired height may not be supported by all
    formats/decoders.

: <dfn dict-member for=ImageDecoderInit>preferAnimation</dfn>
:: For images with multiple tracks, this indicates whether the
    initial track selection should prefer an animated track.

    NOTE: See the [=ImageDecoder/Get Default Selected Track Index=] algorithm.

ImageDecodeOptions Interface {#imagedecodeoptions-interface}
------------------------------------------------------------
<pre class='idl'>
<xmp>
dictionary ImageDecodeOptions {
  [EnforceRange] unsigned long frameIndex = 0;
  boolean completeFramesOnly = true;
};
</xmp>
</pre>

: <dfn dict-member for=ImageDecodeOptions>frameIndex</dfn>
:: The index of the frame to decode.

: <dfn dict-member for=ImageDecodeOptions>completeFramesOnly</dfn>
:: For [=Progressive Images=], a value of `false` indicates that the decoder
    may output an {{ImageDecodeResult/image}} with reduced detail. Each
    subsequent call to {{ImageDecoder/decode()}} for the same
    {{ImageDecodeOptions/frameIndex}} will resolve to produce an image with a
    higher [=Progressive Image Frame Generation=] (more image detail) than the
    previous call, until finally the full-detail image is produced.

    If {{ImageDecodeOptions/completeFramesOnly}} is assigned `true`, or if the
    image is not a [=Progressive Image=], or if the user agent does not support
    progressive decoding for the given image type, calls to
    {{ImageDecoder/decode()}} will only resolve once the full detail image is
    decoded.

    <div class='note'>
      NOTE: For [=Progressive Images=], setting
          {{ImageDecodeOptions/completeFramesOnly}} to `false` may be used to
          offer users a preview an image that is still being buffered from the
          network (via the {{ImageDecoderInit/data}} {{ReadableStream}}).

          Upon decoding the full detail image, the {{ImageDecodeResult}}'s
          {{ImageDecodeResult/complete}} will be set to true.
    </div>


ImageDecodeResult Interface {#imagedecoderesult-interface}
----------------------------------------------------------
<pre class='idl'>
<xmp>
dictionary ImageDecodeResult {
  required VideoFrame image;
  required boolean complete;
};
</xmp>
</pre>

: <dfn dict-member for=ImageDecodeResult>image</dfn>
:: The decoded image.

: <dfn dict-member for=ImageDecodeResult>complete</dfn>
:: Indicates whether {{ImageDecodeResult/image}} contains the final full-detail
    output.

    NOTE: {{ImageDecodeResult/complete}} is always `true` when
        {{ImageDecoder/decode()}} is invoked with
        {{ImageDecodeOptions/completeFramesOnly}} set to `true`.

ImageTrackList Interface {#imagetracklist-interface}
----------------------------------------------------
<pre class='idl'>
<xmp>
[Exposed=(Window,DedicatedWorker)]
interface ImageTrackList {
  getter ImageTrack (unsigned long index);

  readonly attribute Promise<undefined> ready;
  [EnforceRange] readonly attribute unsigned long length;
  [EnforceRange] readonly attribute long selectedIndex;
  readonly attribute ImageTrack? selectedTrack;
};
</xmp>
</pre>

### Internal Slots ### {#imagetracklist-internal-slots}
: <dfn attribute for=ImageTrackList>[[ready promise]]</dfn>
:: The promise used to signal when the {{ImageTrackList}} has been populated
    with {{ImageTrack}}s.

    NOTE: {{ImageTrack}} {{ImageTrack/frameCount}} may receive subsequent
        updates until {{ImageDecoder/complete}} is `true`.

: <dfn attribute for=ImageTrackList>[[track list]]</dfn>
:: The list of {{ImageTrack}}s describe by this {{ImageTrackList}}.

: <dfn attribute for=ImageTrackList>\[[selected index]]</dfn>
:: The index of the selected track in {{ImageTrackList/[[track list]]}}. A
    value of `-1` indeicates that no track is selected.

### Attributes ### {#imagetracklist-attributes}
: <dfn attribute for=ImageTrackList>ready</dfn>
:: The {{ImageTrackList/ready}} getter steps are to return the
    {{ImageTrackList/[[ready promise]]}}.

: <dfn attribute for=ImageTrackList>length</dfn>
:: The {{ImageTrackList/length}} getter steps are to return the length of
    {{ImageTrackList/[[track list]]}}.

: <dfn attribute for=ImageTrackList>selectedIndex</dfn>
:: The {{ImageTrackList/selectedIndex}} getter steps are to return
    {{ImageTrackList/[[selected index]]}};

: <dfn attribute for=ImageTrackList>selectedTrack</dfn>
:: The {{ImageTrackList/selectedTrack}} getter steps are:
    1. If {{ImageTrackList/[[selected index]]}} is `-1`, return `null`.
    2. Otherwise, return the ImageTrack from {{ImageTrackList/[[track list]]}}
        at the position indicated by {{ImageTrackList/[[selected index]]}}.

ImageTrack Interface {#imagetrack-interface}
--------------------------------------------
<pre class='idl'>
<xmp>
[Exposed=(Window,DedicatedWorker)]
interface ImageTrack : EventTarget {
  readonly attribute boolean animated;
  [EnforceRange] readonly attribute unsigned long frameCount;
  [EnforceRange] readonly attribute unrestricted float repetitionCount;
  attribute EventHandler onchange;
  attribute boolean selected;
};
</xmp>
</pre>

### Internal Slots ### {#imagetrack-internal-slots}
: <dfn attribute for=ImageTrack>\[[ImageDecoder]]</dfn>
:: The {{ImageDecoder}} instance that constructed this {{ImageTrack}}.

: <dfn attribute for=ImageTrack>\[[ImageTrackList]]</dfn>
:: The {{ImageTrackList}} instance that lists this {{ImageTrack}}.

: <dfn attribute for=ImageTrack>\[[animated]]</dfn>
:: Indicates whether this track contains an animated image with multiple
    frames.

: <dfn attribute for=ImageTrack>[[frame count]]</dfn>
:: The number of frames in this track.

: <dfn attribute for=ImageTrack>[[repetition count]]</dfn>
:: The number of times the animation is intended to repeat.

: <dfn attribute for=ImageTrack>\[[selected]]</dfn>
:: Indicates whether this track is selected for decoding.

### Attributes ### {#imagetrack-attributes}

: <dfn attribute for=ImageTrack>animated</dfn>
:: The {{ImageTrack/animated}} getter steps are to return the value of
    {{ImageTrack/[[animated]]}}.

    NOTE: This attribute provides an early indication that
        {{ImageTrack/frameCount}} will ultimately exceed 0 for images where the
        {{ImageTrack/frameCount}} starts at `0` and later increments as new
        chunks of the {{ReadableStream}} {{ImageDecoderInit/data}} arrive.

: <dfn attribute for=ImageTrack>frameCount</dfn>
:: The {{ImageTrack/frameCount}} getter steps are to return the value of
    {{ImageTrack/[[frame count]]}}.

: <dfn attribute for=ImageTrack>repetitionCount</dfn>
:: The {{ImageTrack/repetitionCount}} getter steps are to return the value of
    {{ImageTrack/[[repetition count]]}}.

: <dfn attribute for=ImageTrack>onchange</dfn>
:: An [=event handler IDL attribute=] whose [=event handler event type=] is
    {{ImageTrack/change}}.

: <dfn attribute for=ImageTrack>selected</dfn>
:: The {{ImageTrack/selected}} getter steps are to return the value of
    {{ImageTrack/[[selected]]}}.

    The {{ImageTrack/selected}} setter steps are:
    1. If {{ImageTrack/[[ImageDecoder]]}}'s {{ImageDecoder/[[closed]]}} slot is
        `true`, abort these steps.
    2. Let |newValue| be [=the given value=].
    3. If |newValue| equals {{ImageTrack/[[selected]]}}, abort these steps.
    4. Assign |newValue| to {{ImageTrack/[[selected]]}}.
    5. Let |parentTrackList| be {{ImageTrack/[[ImageTrackList]]}}
    6. Let |oldSelectedIndex| be the value of |parentTrackList|
        {{ImageTrackList/[[selected index]]}}.
    7. If |oldSelectedIndex| is not `-1`:
        1. Let |oldSelectedTrack| be the {{ImageTrack}} in |parentTrackList|
            {{ImageTrackList/[[track list]]}} at the position of
            |oldSelectedIndex|.
        2. Assign `false` to |oldSelectedTrack| {{ImageTrack/[[selected]]}}

    8. If |newValue| is `true`, let |selectedIndex| be the index of [=this=]
        {{ImageTrack}} within |parentTrackList|'s
        {{ImageTrackList/[[track list]]}}. Otherwise, let |selectedIndex| be
        `-1`.
    9. Assign |selectedIndex| to |parentTrackList|
        {{ImageTrackList/[[selected index]]}}.
    10. Run the [=ImageDecoder/Reset ImageDecoder=] algorithm on
        {{ImageTrack/[[ImageDecoder]]}}.
    11. [=Queue a control message=] to {{ImageTrack/[[ImageDecoder]]}}'s
        [=control message queue=] to update the internal selected track
        index with |selectedIndex|.

    [=Running a control message=] to update the internal selected track index
    means running these steps:
    1. Assign |selectedIndex| to
        {{ImageDecoder/[[internal selected track index]]}}.
    2. Remove all entries from
        {{ImageDecoder/[[progressive frame generations]]}}.


### Event Summary ### {#imagetracklist-eventsummary}

: <dfn event for=ImageTrack>change</dfn>
:: Fired at the {{ImageTrack}} when the {{ImageTrack/frameCount}} is altered.


Security Considerations{#security-considerations}
=================================================

The primary security impact is that features of this API make it easier for an
attacker to exploit vulnerabilities in the underlying platform codecs.
Additionally, new abilities to configure and control the codecs may allow for
new exploits that rely on a specific configuration and/or sequence of control
operations.

Platform codecs are historically an internal detail of APIs like
{{HTMLMediaElement}}, [[WEBAUDIO]], and [[WebRTC]]. In this way, it has always
been possible to attack the underlying codecs by using malformed media
files/streams and invoking the various API control methods.

For example, you can send any stream to a decoder by first wrapping that stream
in a media container (e.g. mp4) and setting that as the {{HTMLMediaElement/src}}
of an {{HTMLMediaElement}}. You can then cause the underlying video decoder to
be {{VideoDecoder/reset()}} by setting a new value for `<video>.currentTime`.

WebCodecs makes such attacks easier by exposing low level control when inputs
are provided and direct access to invoke the codec control methods. This also
affords attackers the ability to invoke sequences of control methods that were
not previously possible via the higher level APIs.

User agents should mitigate this risk by extensively fuzzing their
implementation with random inputs and control method invocations. Additionally,
user agents are encouraged to isolate their underlying codecs in processes with
restricted privileges (sandbox) as a barrier against successful exploits being
able to read user data.

An additional concern is exposing the underlying codecs to input mutation race
conditions. Specifically, it should not be possible for a site to mutate a codec
input or output while the underlying codec may still be operating on that data.
This concern is mitigated by ensuring that input and output interfaces are
immutable.

Privacy Considerations{#privacy-considerations}
===============================================
The primary privacy impact is an increased ability to fingerprint users by
querying for different codec capabilities to establish a codec feature profile.
Much of this profile is already exposed by existing APIs. Such profiles are very
unlikely to be uniquely identifying, but may be used with other metrics to
create a fingerprint.

An attacker may accumulate a codec feature profile by calling
`IsConfigSupported()` methods with a number of different configuration
dictionaries. Similarly, an attacker may attempt to `configure()` a codec with
different configuration dictionaries and observe which configurations are
accepted.

Attackers may also use existing APIs to establish much of the codec feature
profile. For example, the [[media-capabilities]] {{decodingInfo()}} API
describes what types of decoders are supported and its {{powerEfficient}}
attribute may signal when a decoder uses hardware acceleration. Similarly, the
[[WebRTC]] {{RTCRtpSender/getCapabilities()}} API may be used to determine what
types of encoders are supported and the {{RTCPeerConnection/getStats()}} API may
be used to determine when an encoder uses hardware acceleration. WebCodecs will
expose some additional information in the form of low level codec features.

A codec feature profile alone is unlikely to be uniquely identifying. Underlying
codecs are often implemented entirely in software (be it part of the user agent
binary or part of the operating system), such that all users who run that
software will have a common set capabilities. Additionally, underlying codecs
are often implemented with hardware acceleration, but such hardware is mass
produced and devices of a particular class and manufacture date (e.g. flagship
phones manufactured in 2020) will often have common capabilities. There will be
outliers (some users may run outdated versions of software codecs or use a rare
mix of custom assembled hardware), but most of the time a given codec feature
profile is shared by a large group of users.

Segmenting groups of users by codec feature profile still amounts to a bit of
entropy that can be combined with other metrics to uniquely identify a user.
User agents may partially mitigate this by returning an error whenever a site
attempts to exhaustively probe for codec capabilities. Additionally, user agents
may implement a "privacy budget", which depletes as authors use WebCodecs and
other identifying APIs. Upon exhaustion of the privacy budget, codec
capabilities could be reduced to a common baseline or prompt for user approval.
