<pre class='metadata'>
Title: WebCodecs
Repository: wicg/web-codecs
Status: CG-DRAFT
ED: https://wicg.github.io/web-codecs/
Shortname: web-codecs
Level: 1
Group: wicg
Editor: Chris Cunningham, w3cid 114832, Google Inc. https://google.com/
Editor: Paul Adenot, w3cid 62410, Mozilla https://www.mozilla.org/

Abstract: This specification defines interfaces for encoding and decoding audio
Abstract: and video. It also includes an interface for retrieving raw video
Abstract: frames from MediaStreamStracks.

Markup Shorthands:css no, markdown yes, dfn yes
!Participate: <a href="https://github.com/wicg/web-codecs">Git Repository.</a>
!Participate: <a href="https://github.com/wicg/web-codecs/issues/new">File an issue.</a>
!Version History: <a href="https://github.com/wicg/web-codecs/commits">https://github.com/wicg/web-codecs/commits</a>
</pre>

<pre class='anchors'>
spec: media-source; urlPrefix: https://www.w3.org/TR/media-source/
    type: method
        for: MediaSource; text: isTypeSupported(); url: #dom-mediasource-istypesupported

spec: html; urlPrefix: https://html.spec.whatwg.org/multipage/;
    type: method
        for: HTMLMediaElement; text: canPlayType(); url: #dom-navigator-canplaytype
    type: attribute
        for: PlatformObject; text: [[Detached]]; url: structured-data.html#detached
    type: attribute
        for: ImageBitmap; text: resizeWidth; url:#dom-imagebitmapoptions-resizewidth
    type: attribute
        for: ImageBitmap; text: resizeHeight; url:#dom-imagebitmapoptions-resizeheight

spec: mediacapture-streams; urlPrefix: https://www.w3.org/TR/mediacapture-streams/
    type: method
        for: mediaDevices; text: getUserMedia(); url: #dom-mediadevices-getusermedia

spec: mediacapture-screen-share; urlPrefix: https://w3c.github.io/mediacapture-screen-share/
    type: method
        for: mediaDevices; text: getDisplayMedia(); url: #dom-mediadevices-getdisplaymedia

spec: mediacapture-main; urlPrefix: https://w3c.github.io/mediacapture-main/
    type: enum-value
        for:MediaStreamTrackState; text: live; url: #idl-def-MediaStreamTrackState.live
    type: enum-value
        for:MediaStreamTrackState; text: ended; url: #idl-def-MediaStreamTrackState.ended

spec: mimesniff; urlPrefix: https://mimesniff.spec.whatwg.org/#
    type: dfn; text: MIME type; url: mime-type

spec: infra; urlPrefix: https://infra.spec.whatwg.org/#
    type: dfn; text: queue; url: queues
    type: dfn; text: enqueing; url: queue-enqueue;
    type: dfn; text: dequeued; url: queue-dequeue;
    type: dfn; text: empty; url: list-is-empty;
</pre>


Definitions {#definitions}
==========================

: Codec
:: Refers generically to an instance of AudioDecoder, AudioEncoder,
    VideoDecoder, or VideoEncoder.

: Key Frame
:: An encoded frame that does not depend on any other frames for decoding.


Codec Processing Model {#codec-processing-model}
================================================

New codec tasks may be scheduled while previous tasks are still pending. For
example, web authors may call `decode()` without waiting for the previous
`decode()` to generate an output. This is facilitated by the following
mechanisms.

Each codec has a single <dfn>control message queue</dfn> that is a <a>queue</a>
of <dfn>control messages</dfn>.

<dfn lt="Enqueues a control message|Queue a control message">Queuing a control
    message</dfn> means <a>enqueing</a> the message to the codec’s <a>control
    message queue</a>. Invoking codec methods will often queue a control message
    to schedule work.

<dfn lt="running a control message|control message steps">Running a control
    message</dfn> means executing a sequence of steps specified by the method
    that enqueued the message.

<dfn lt="Run the control message processing loop">Running the control message
    processing loop</dfn> means executing these steps.
1. While the control message queue is not <a>empty</a>
    1. Let |front message| be the next <a>dequeued</a> <a>control message</a>
    2. If |front message| cannot be executed now, return.

        The User Agent must decide when further processing is blocked because of
            ongoing work as an implementation detail (e.g. the underlying
            decoder cannot accept more requests yet). The UA must restart the
            processing loop when the blockage is resolved.

        NOTE: a blocked processing loop is visible to authors via the
            `decodeQueueSize` and `encodeQueueSize` attributes.

    3. Dequeue |front message| from the <a>control message queue</a>.
    4. Run the |front message| <a>control message steps</a>.


AudioDecoder Interface {#audiodecoder-interface}
================================================

<pre class='idl'>
<xmp>
[Exposed=(Window,Worker)]
interface AudioDecoder {
  constructor(AudioDecoderInit init);

  readonly attribute CodecState state;
  readonly attribute long decodeQueueSize;

  undefined configure(AudioDecoderConfig config);
  undefined decode(EncodedAudioChunk chunk);
  Promise<undefined> flush();
  undefined reset();
  undefined close();
};

dictionary AudioDecoderInit {
  required AudioFrameOutputCallback output;
  required WebCodecsErrorCallback error;
};

callback AudioFrameOutputCallback = undefined(AudioFrame output);
</xmp>
</pre>

Internal Slots {#audiodecoder-internal-slots}
---------------------------------------------
<dl>
<dt><dfn attribute for=AudioDecoder>[[codec implementation]]</dfn></dt>
<dd>Underlying decoder implementation provided by the User Agent.</dd>
<dt><dfn attribute for=AudioDecoder>[[output callback]]</dfn></dt>
<dd>Callback given at construction for decoded outputs.</dd>
<dt><dfn attribute for=AudioDecoder>[[error callback]]</dfn></dt>
<dd>Callback given at construction for decode errors.</dd>
</dl>

Constructors {#audiodecoder-constructors}
-----------------------------------------
<dfn constructor for=AudioDecoder title="AudioDecoder(init)">
  AudioDecoder(init)
</dfn>
1. Let d be a new {{AudioDecoder}} object.
2. Assign init.output to the {{AudioDecoder/[[output callback]]}} internal slot.
3. Assign init.error to the {{AudioDecoder/[[error callback]]}} internal slot.
4. Assign "unconfigured" to d.state.
4. Return d.

Attributes {#audiodecoder-attributes}
-------------------------------------
<dl>
  <dt>
    <dfn attribute for=AudioDecoder>state</dfn>
  </dt>
  <dd>Describes the current state of the codec.</dd>
  <dt>
    <dfn attribute for=AudioDecoder>decodeQueueSize</dfn>
  </dt>
  <dd>
    The number of pending decode requests. This does not include requests that
    have been sent to the underlying codec.
  </dd>
</dl>

Methods {#audiodecoder-methods}
-------------------------------
<dl>
  <dt><dfn method for=AudioDecoder>configure(config)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to configure the audio decoder for
    decoding chunks as described by |config|.

    When invoked, run these steps:
    1. If |config| is not a <a>valid AudioDecoderConfig</a>, throw a
        {{TypeError}}.
    2. Run the <a>Configure Decoder</a> algorithm with |config|,
        {{AudioDecoder/state}}, and {{AudioDecoder/[[codec implementation]]}}.
  </dd>

  <dt><dfn method for=AudioDecoder>decode(chunk)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to decode the given |chunk|.

    When invoked, run these steps:
    1. Let |output algorithm| be the <a>AudioFrame Output</a> algorithm with
        {{AudioDecoder/[[output callback]]}}.
    2. Run the <a>Decode Chunk</a> algorithm with |chunk| and
        {{AudioDecoder/state}}, {{AudioDecoder/decodeQueueSize}},
        {{AudioDecoder/[[codec implementation]]}},
        {{AudioDecoder/[[error callback]]}}, and |output algorithm|.
  </dd>

  <dt><dfn method for=AudioDecoder>flush()</dfn></dt>
  <dd>
    Completes all <a>control messages</a> in the <a>control message queue</a>
    and emits all outputs.

    When invoked, run these steps:
    1. Let |output algorithm| be the <a>AudioFrame Output</a> algorithm with
        {{AudioDecoder/[[output callback]]}}.
    2. Run the <a>Flush</a> algorithm with {{AudioDecoder/state}},
        {{AudioDecoder/[[codec implementation]]}}, and |output algorithm|.
  </dd>

  <dt><dfn method for=AudioDecoder>reset()</dfn></dt>
  <dd>
    Immediately resets all state including configuration,
    <a>control messages</a> in the <a>control message queue</a>, and all pending
    callbacks.

    When invoked, run the <a>Reset</a> algorithm with {{AudioDecoder/state}} and
    {{AudioDecoder/[[codec implementation]]}}.
  </dd>

  <dt><dfn method for=AudioDecoder>close()</df></dt>
  <dd>
    Immediately aborts all pending work and releases system resources. Close is
    permanent.

    When invoked, run the <a>Close</a> algorithm with {{AudioDecoder/state}} and
    {{AudioDecoder/[[codec implementation]]}}.
  </dd>
</dl>

VideoDecoder Interface {#videodecoder-interface}
================================================

<pre class='idl'>
<xmp>
[Exposed=(Window,Worker)]
interface VideoDecoder {
  constructor(VideoDecoderInit init);

  readonly attribute CodecState state;
  readonly attribute long decodeQueueSize;

  undefined configure(VideoDecoderConfig config);
  undefined decode(EncodedVideoChunk chunk);
  Promise<undefined> flush();
  undefined reset();
  undefined close();
};

dictionary VideoDecoderInit {
  required VideoFrameOutputCallback output;
  required WebCodecsErrorCallback error;
};

callback VideoFrameOutputCallback = undefined(VideoFrame output);
</xmp>
</pre>

Internal Slots {#videodecoder-internal-slots}
---------------------------------------------
<dl>
<dt><dfn attribute for=VideoDecoder>[[codec implementation]]</dfn></dt>
<dd>Underlying decoder implementation provided by the User Agent.</dd>
<dt><dfn attribute for=VideoDecoder>[[output callback]]</dfn></dt>
<dd>Callback given at construction for decoded outputs.</dd>
<dt><dfn attribute for=VideoDecoder>[[error callback]]</dfn></dt>
<dd>Callback given at construction for decode errors.</dd>
</dl>

Constructors {#videodecoder-constructors}
-----------------------------------------
<dfn constructor for=VideoDecoder title="VideoDecoder(init)">
  VideoDecoder(init)
</dfn>
1. Let d be a new VideoDecoder object.
2. Assign `init.output` to the {{VideoDecoder/[[output callback]]}} internal slot.
3. Assign `init.error` to the {{VideoDecoder/[[error callback]]}} internal slot.
4. Assign "unconfigured" to `d.state`.
5. Return d.

Attributes {#videodecoder-attributes}
-------------------------------------
<dl>
  <dt>
    <dfn attribute for=VideoDecoder>state</dfn>
  </dt>
  <dd>Describes the current state of the codec.</dd>
  <dt>
    <dfn attribute for=VideoDecoder>decodeQueueSize</dfn>
  </dt>
  <dd>
    The number of pending decode requests. This does not include requests that
    have been sent to the underlying codec.
  </dd>
</dl>

Methods {#videodecoder-methods}
-------------------------------
<dl>
  <dt><dfn method for=VideoDecoder>configure(config)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to configure the video decoder for
    decoding chunks as described by |config|.

    When invoked, run these steps:
    1. If |config| is not a <a>valid VideoDecoderConfig</a>, throw a
        {{TypeError}}.
    2. Run the <a>Configure Decoder</a> algorithm with |config|,
        {{VideoDecoder/state}}, and {{VideoDecoder/[[codec implementation]]}}.
  </dd>

  <dt><dfn method for=VideoDecoder>decode(chunk)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to decode the given |chunk|.

    When invoked, run these steps:
    1. Let |output algorithm| be the <a>VideoFrame Output</a> algorithm with
        {{VideoDecoder/[[output callback]]}}.
    2. Run the <a>Decode Chunk</a> algorithm with |chunk|,
        {{VideoDecoder/state}}, {{VideoDecoder/decodeQueueSize}},
        {{VideoDecoder/[[codec implementation]]}},
        {{VideoDecoder/[[error callback]]}} and |output algorithm|.
  </dd>

  <dt><dfn method for=VideoDecoder>flush()</dfn></dt>
  <dd>
    Completes all <a>control messages</a> in the <a>control message queue</a>
    and emits all outputs.

    When invoked, run these steps:
    1. Let |output algorithm| be the <a>VideoFrame Output</a> algorithm with
        {{VideoDecoder/[[output callback]]}}.
    2. Run the <a>Flush</a> algorithm with {{VideoDecoder/state}},
        {{VideoDecoder/[[codec implementation]]}}, and |output algorithm|.
  </dd>

  <dt><dfn method for=VideoDecoder>reset()</dfn></dt>
  <dd>
    Immediately resets all state including configuration,
    <a>control messages</a> in the <a>control message queue</a>, and all pending
    callbacks.

    When invoked, run the <a>Reset</a> algorithm with {{VideoDecoder/state}} and
    {{VideoDecoder/[[codec implementation]]}}.
  </dd>

  <dt><dfn method for=VideoDecoder>close()</df></dt>
  <dd>
    Immediately aborts all pending work and releases system resources. Close is
    permanent.

    When invoked, run the <a>Close</a> algorithm with {{VideoDecoder/state}} and
    {{VideoDecoder/[[codec implementation]]}}.
  </dd>
</dl>


AudioEncoder Interface {#audioencoder-interface}
================================================

<pre class='idl'>
<xmp>
[Exposed=(Window,Worker)]
interface AudioEncoder {
  constructor(AudioEncoderInit init);
  readonly attribute CodecState state;
  readonly attribute long encodeQueueSize;
  undefined configure(AudioEncoderConfig config);
  undefined encode(AudioFrame frame);
  Promise<undefined> flush();
  undefined reset();
  undefined close();
};

dictionary AudioEncoderInit {
  required EncodedAudioChunkOutputCallback output;
  required WebCodecsErrorCallback error;
};

callback EncodedAudioChunkOutputCallback = undefined(EncodedAudioChunk output);
</xmp>
</pre>

Internal Slots {#audioencoder-internal-slots}
---------------------------------------------
<dl>
<dt><dfn attribute for=AudioEncoder>[[codec implementation]]</dfn></dt>
<dd>Underlying encoder implementation provided by the User Agent.</dd>
<dt><dfn attribute for=AudioEncoder>[[output callback]]</dfn></dt>
<dd>Callback given at construction for encoded outputs.</dd>
<dt><dfn attribute for=AudioEncoder>[[error callback]]</dfn></dt>
<dd>Callback given at construction for encode errors.</dd>
</dl>

Constructors {#audioencoder-constructors}
-----------------------------------------
<dfn constructor for=AudioEncoder title="AudioEncoder(init)">
  AudioEncoder(init)
</dfn>
1. Let e be a new AudioEncoder object.
2. Assign `init.output` to the {{AudioEncoder/[[output callback]]}} internal slot.
3. Assign `init.error` to the {{AudioEncoder/[[error callback]]}} internal slot.
4. Assign "unconfigured" to `e.state`.
5. Return e.

Attributes {#audioencoder-attributes}
-------------------------------------
<dl>
  <dt>
    <dfn attribute for=AudioEncoder>state</dfn>
  </dt>
  <dd>Describes the current state of the codec.</dd>
  <dt>
    <dfn attribute for=AudioEncoder>encodeQueueSize</dfn>
  </dt>
  <dd>
    The number of pending encode requests. This does not include requests that
    have been sent to the underlying codec.
  </dd>
</dl>

Methods {#audioencoder-methods}
-------------------------------
<dl>
  <dt><dfn method for=AudioEncoder>configure(config)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to configure the audio encoder for
    decoding chunks as described by |config|.

    When invoked, run these steps:
    1. If |config| is not a <a>valid AudioEncoderConfig</a>, throw a
        {{TypeError}}.
    2. Run the <a>Configure Encoder</a> algorithm with |config|,
        {{AudioEncoder/state}}, and {{AudioEncoder/[[codec implementation]]}}.
  </dd>

  <dt><dfn method for=AudioEncoder>encode(frame)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to encode the given |frame|.

    NOTE: This method will destroy the VideoFrame. Authors who wish to retain a
    copy, should call `frame.clone()` prior to calling encode().

    When invoked, run these steps:
    1. If the value of |frame|'s {{AudioFrame/[[detached]]}} internal slot is
        `true`, throw a {{TypeError}}.
    2. Let |output algorithm| be the <a>EncodedAudioChunk Output</a> algorithm.
    3. Run the <a>Encode Frame</a> algorithm with |frame|,
        {{AudioEncoder/state}}, {{AudioEncoder/encodeQueueSize}},
        {{AudioEncoder/[[codec implementation]]}},
        {{AudioEncoder/[[error callback]]}},
        {{AudioEncoder/[[output callback]]}}, and |output algorithm|.
  </dd>

  <dt><dfn method for=AudioEncoder>flush()</dfn></dt>
  <dd>
    Completes all <a>control messages</a> in the <a>control message queue</a>
    and emits all outputs.

    When invoked, run these steps:
    1. Let |output algorithm| be the <a>EncodedAudioChunk Output</a> algorithm.
    2. Run the <a>Flush</a> algorithm with |output algorithm|.
  </dd>

  <dt><dfn method for=AudioEncoder>reset()</dfn></dt>
  <dd>
    Immediately resets all state including configuration,
    <a>control messages</a> in the <a>control message queue</a>, and all pending
    callbacks.

    When invoked, run the <a>Reset</a> algorithm with {{AudioEncoder/state}} and
    {{AudioEncoder/[[codec implementation]]}}.
  </dd>

  <dt><dfn method for=AudioEncoder>close()</df></dt>
  <dd>
    Immediately aborts all pending work and releases system resources. Close is
    permanent.

    When invoked, run the <a>Close</a> algorithm with {{AudioEncoder/state}} and
    {{AudioEncoder/[[codec implementation]]}}.
  </dd>
</dl>


VideoEncoder Interface {#videoencoder-interface}
================================================

<pre class='idl'>
<xmp>
[Exposed=(Window,Worker)]
interface VideoEncoder {
  constructor(VideoEncoderInit init);
  readonly attribute CodecState state;
  readonly attribute long encodeQueueSize;
  undefined configure(VideoEncoderConfig config);
  undefined encode(VideoFrame frame, optional VideoEncoderEncodeOptions options = {});
  Promise<undefined> flush();
  undefined reset();
  undefined close();
};

dictionary VideoEncoderInit {
  required EncodedVideoChunkOutputCallback output;
  required WebCodecsErrorCallback error;
};

callback EncodedVideoChunkOutputCallback = undefined(EncodedVideoChunk output);
</xmp>
</pre>

Internal Slots {#videoencoder-internal-slots}
---------------------------------------------
<dl>
<dt><dfn attribute for=VideoEncoder>[[codec implementation]]</dfn></dt>
<dd>Underlying encoder implementation provided by the User Agent.</dd>
<dt><dfn attribute for=VideoEncoder>[[output callback]]</dfn></dt>
<dd>Callback given at construction for encoded outputs.</dd>
<dt><dfn attribute for=VideoEncoder>[[error callback]]</dfn></dt>
<dd>Callback given at construction for encode errors.</dd>
</dl>

Constructors {#videoencoder-constructors}
-----------------------------------------
<dfn constructor for=VideoEncoder title="VideoEncoder(init)">
  VideoEncoder(init)
</dfn>
1. Let e be a new VideoEncoder object.
2. Assign `init.output` to the {{VideoEncoder/[[output callback]]}} internal slot.
3. Assign `init.error` to the {{VideoEncoder/[[error callback]]}} internal slot.
4. Assign "unconfigured" to `e.state`.
5. Return e.

Attributes {#videoencoder-attributes}
-------------------------------------
<dl>
  <dt>
    <dfn attribute for=VideoEncoder>state</dfn>
  </dt>
  <dd>Describes the current state of the codec.</dd>
  <dt>
    <dfn attribute for=VideoEncoder>encodeQueueSize</dfn>
  </dt>
  <dd>
    The number of pending encode requests. This does not include requests that
    have been sent to the underlying codec.
  </dd>
</dl>

Methods {#videoencoder-methods}
-------------------------------
<dl>
  <dt><dfn method for=VideoEncoder>configure(config)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to configure the video encoder for
    decoding chunks as described by |config|.

    When invoked, run these steps:
    1. If |config| is not a <a>valid VideoEncoderConfig</a>, throw a
        {{TypeError}}.
    2. Run the <a>Configure Encoder</a> algorithm with |config|,
        {{VideoEncoder/state}}, and {{VideoEncoder/[[codec implementation]]}}.
  </dd>

  <dt><dfn method for=VideoEncoder>encode(frame, options)</dfn></dt>
  <dd>
    <a>Enqueues a control message</a> to encode the given |frame|.

    NOTE: This method will destroy the VideoFrame. Authors who wish to retain a
    copy, should call `frame.clone()` prior to calling encode().

    When invoked, run these steps:
    1. If the value of |frame|'s {{VideoFrame/[[detached]]}} internal slot is
        `true`, throw a {{TypeError}}.
    2. Let |output algorithm| be the <a>EncodedVideoChunk Output</a> algorithm.
    3. Run the <a>Encode Frame</a> algorithm with |frame|, |options|,
        {{VideoEncoder/state}}, {{VideoEncoder/encodeQueueSize}},
        {{VideoEncoder/[[codec implementation]]}},
        {{VideoEncoder/[[error callback]]}},
        {{VideoEncoder/[[error callback]]}} and |output algorithm|.
  </dd>

  <dt><dfn method for=VideoEncoder>flush()</dfn></dt>
  <dd>
    Completes all <a>control messages</a> in the <a>control message queue</a>
    and emits all outputs.

    When invoked, run these steps:
    1. Let |output algorithm| be the <a>EncodedVideoChunk Output</a> algorithm.
    2. Run the <a>Flush</a> algorithm with |output algorithm|.
  </dd>

  <dt><dfn method for=VideoEncoder>reset()</dfn></dt>
  <dd>
    Immediately resets all state including configuration,
    <a>control messages</a> in the <a>control message queue</a>, and all pending
    callbacks.

    When invoked, run the <a>Reset</a> algorithm with {{VideoEncoder/state}} and
    {{VideoEncoder/[[codec implementation]]}}.
  </dd>

  <dt><dfn method for=VideoEncoder>close()</df></dt>
  <dd>
    Immediately aborts all pending work and releases system resources. Close is
    permanent.

    When invoked, run the <a>Close</a> algorithm with {{VideoEncoder/state}} and
    {{VideoEncoder/[[codec implementation]]}}.
  </dd>
</dl>


Decoder and Encoder Algorithms {#decoder-and-encoder-algorithms}
================================================================

The following algorithms run in the scope of the methods that invoke them.
Mentions of attributes and internal slots refer to members of the interface that
owns the invoking method.

<dfn>Configure Decoder</dfn> {#configure-decoder-algorithm}
-----------------------------------------------------------
Given a |config|, |state| and an internal slot for |codec implementation|, this
algorithm attempts to assign |codec implementation| with an implementation that
supports |config|.

Run the following steps:
1. If |state| is `“closed”`, throw an {{InvalidStateError}}.
2. If the user agent cannot provide a codec implementation to support |config|,
    throw a {{NotSupportedError}}.
3. Set |state| to `"configured"`.
4. <a>Queue a control message</a> to configure the decoder with |config|.
5. <a>Run the control message processing loop</a>.

<a>Running a control message</a> to configure the decoder means running these
    steps:
1. Assign |codec implementation| with an implementation
    supporting |config|.

<dfn>Decode Chunk</dfn> {#decode-chunk-algorithm}
-------------------------------------------------
Given a |chunk|, |state|, |decodeQueueSize|, |codec implementation|,
|error callback| and |output algorithm|, this algorithm will decode the provided
|chunk|.

Run these steps:
1. If |state| is not `"configured"`, throw an {{InvalidStateError}}.
2. Increment |decodeQueueSize|.
3. <a>Queue a control message</a> to decode the |chunk|.
4. <a>Run the control message processing loop</a>.

Running a control message to decode the chunk means running these steps:
1. Decrement |decodeQueueSize|
2. Let |codec implementation queue| be the result of starting a new <a>parallel
    queue</a>.
3. Enqueue the following steps to |codec implementation queue|:
    1. Attempt to use |codec implementation| to decode the chunk.
    2. If decoding results in an error, queue a task on the media element task
        source to run the <a>Codec Error</a> algorithm with |state|,
        |codec implementation| and |error callback|.
4. Otherwise, for each |output|, queue a task on the media element task source to
    run the provided |output algorithm| with |output|.

<dfn>Flush</dfn> {#flush-algorithm}
-----------------------------------
Given a |state|, |codec implementation|, and |output algorithm|, this algorithm
emits all pending outputs to the codec output callback.

Run these steps:
1. If |state| is not `"configured"`, return a Promise rejected with a newly
    created {{InvalidStateError}}.
2. Let |promise| be a new Promise.
3. <a>Queue a control message</a> to flush the codec with |promise|,
    |codec implementation|, and |output algorithm|.
4. Return |promise|.

Running a control message to flush the codec means running these steps
    with |promise|, |codec implementation|, and |output algorithm|.
1. Signal |codec implementation| to emit all pending outputs.
2. For each |output|, run |output algorithm| with |output|.
3. Resolve |promise|.

<dfn>Codec Error</dfn>{#codec-error-algorithm}
----------------------------------------------
Given |state|, |codec implementation| and |error callback|, this algorithm fires
the error callback and permanently closes the codec.

Run these steps:
1. Cease processing of the <a>control message queue</a>.
2. Let |error| be a new instance of {{EncodingError}}.
3. Run the <a>Close</a> algorithm with |state|, |codec implementation|, |error|
    and |error callback|.

<dfn>AudioFrame Output</dfn>{#audio-frame-output-algorithm}
-----------------------------------------------------------
Given an |output callback| and a decoded audio |output|, this algorithm
constructs an {{AudioFrame}} from |output| and invokes the |output callback|.

Run these steps:
1. Let |buffer| be an {{AudioBuffer}} containing the decoded audio data from
    |output|.
2. Let |frame| be an {{AudioFrame}} containing |buffer| and a timestamp from the
    EncodedAudioChunk associated with |output|.
3. Invoke |output callback| with |frame|.

<dfn>VideoFrame Output</dfn>{#video-frame-output-algorithm}
-----------------------------------------------------------
Given an |output callback| and a decoded video |output|, this algorithm
constructs a {{VideoFrame}} from |output| and invokes the |output callback|.

Run these steps:
1. Let |planes| be a sequence of {{Plane}}s containing the decoded video frame
    data from |output|.
2. Let |pixelFormat| be the {{PixelFormat}} of |planes|.
3. Let |frameInit| be a {{VideoFrameInit}} with the following keys:
    1. Let timestamp and duration be the presentation timestamp and duration
        from the EncodedVideoChunk associated with |output|.
    2. Let codedWidth and codedHeight be the width and height of the decoded
        video frame in pixels, prior to any cropping or aspect ratio
        adjustments.
    3. Let cropLeft, cropTop, cropWidth, and cropHeight be the crop region of
        the decoded video frame in pixels, prior to any aspect ratio
        adjustments.
    4. Let displayWidth and displayHeight be the display size of the decoded
        video frame in pixels.
4. Let |frame| be a {{VideoFrame}}, constructed with |pixelFormat|, |planes|,
    and |frameInit|.
5. Invoke |output callback| with |frame|.

<dfn>Reset</dfn>{#reset-algorithm}
----------------------------------
Given a |state| and |codec implementation|), this algorithm immediately resets
all state including configuration, control messages in the control message
queue, and all pending callbacks.

Run these steps:
1. If |state| is `“closed”`, throw an {{InvalidStateError}}.
2. Set |state| to `“unconfigured”`.
3. Signal |codec implementation| to cease producing output
    for the previous configuration.
4. For each <a>control message</a> in the <a>control message queue</a>:
    1. If a control message has an associated promise, reject the promise.
    2. Remove the message from the queue.

<dfn>Close</dfn>{#close-algorithm}
----------------------------------
Given |state| and |codec implementation|, |error|, and |error callback|, this
algorithm immediately aborts all pending work and releases system resources.

Run these steps:
1. Run the <a>Reset</a> algorithm, with |state| and |codec implementation|.
2. Set |state| to `“closed”`.
3. Clear |codec implementation| and release associated system resources.
4. If |error| is set, invoke |error callback| with |error|.

<dfn>Configure Encoder</dfn>{#configure-encoder-algorithm}
----------------------------------------------------------
Given a |config|, |state|, and an internal slot for |codec implementation|, this
algorithm attempts to assign |codec implementation| with an implementation that
supports |config|.

Run the following steps:
1. If |state| is `"closed"`, throw an {{InvalidStateError}}.
2. If the user agent cannot provide a codec implementation to support |config|,
    throw a {{NotSupportedError}}.
3. Set |state| to `"configured"`.
4. <a>Queue a control message</a> to configure the encoder using |config|.
5. <a>Run the control message processing loop</a>.

Running a control message to configure the encoder means running these steps:
1. Assign |codec implementation| with an implementation
    supporting |config|.

<dfn>Encode Frame</dfn>{#encode-frame-algorithm}
------------------------------------------------
Given a |frame|, |options|, |state|, |encodeQueueSize|, |codec implementation|,
|error callback|, |output callback| and |output algorithm|, this algorithm will
encode the provided |frame|.

Run these steps:
1. If |state| is not `"configured"`, throw an {{InvalidStateError}}.
2. Let |frameClone| hold the result of running the <a>Clone Frame</a> algorithm
    with |frame|.
3. Destroy the original |frame| by invoking `frame.destroy()`.
4. Increment |encodeQueueSize|.
5. <a>Queue a control message</a> to encode |frameClone| with |output algorithm|
    and |options| if provided.
6. Run the control message processing loop.

Running a control message to encode the frame means running these steps.
1. Decrement |encodeQueueSize|.
2. Let |codec implementation queue| be the result of starting a new
    <a>parallel queue</a>.
3. Enqueue the following steps to |codec implementation queue|:
    1. Attempt to use |codec implementation| and |options| to encode
        |frameClone|.
    2. If encoding results in an error, queue a task on the media element task
        source to run the <a>Codec Error</a> algorithm.
    3. Otherwise, for each |output|, queue a task on the media element task source
        to run the provided output algorithm with |output callback| and
        |output|.

<dfn>EncodedAudioChunk Output</dfn>{#encodedaudiochunk-output-algorithm}
------------------------------------------------------------------------
Given an |output callback| and an encoded audio |output|, this algorithm
constructs an {{EncodedAudioChunk}} from |output| and invokes the
|output callback|.

Run these steps:
1. If `state` is not `“configured”`, abort the following steps.
2. Let |chunkInit| be an {{EncodedAudioChunkInit}} with the following keys:
    1. Let data contain the encoded audio data.
    2. Let type be the EnocdedAudioChunkType of the encoded audio data.
    3. Let timestamp be the timestamp from the associated input AudioFrame.
    4. Let duration be the duration from the associated input AudioFrame.
7. Let |chunk| be a new {{EncodedAudioChunk}} constructed with |chunkInit|.
8. Invoke **[[output callback]]** with |chunk|.

<dfn>EncodedVideoChunk Output</dfn>{#encodedvideochunk-output-algorithm}
------------------------------------------------------------------------
Given an |output callback| and an encoded video |output|, this algorithm
constructs an {{EncodedVideoChunk}} from |output| and invokes the
|output callback|.

Run these steps:
1. Let |chunkInit| be an {{EncodedVideoChunkInit}} with the following keys:
    1. Let {{EncodedVideoChunkInit/data}} contain the encoded video data.
    2. Let {{EncodedVideoChunkInit/type}} be the {{EncodedVideoChunkType}} of
        the encoded video data.
    3. Let {{EncodedVideoChunkInit/timestamp}} be the timestamp from the
        associated input {{VideoFrame}}.
    4. Let {{EncodedVideoChunkInit/duration}} be the duration from the
        associated input {{VideoFrame}}.
2. Let |chunk| be a new {{EncodedVideoChunk}} constructed with |chunkInit|.
3. Invoke |output callback| with chunk.

Configurations{#configurations}
===============================

<dfn export>Codec String</dfn>{#config-codec-string}
----------------------------------------------------
In other media specifications, codec strings historically accompanied a
    <a>MIME type</a> as the “codecs=” parameter
    ({{MediaSource/isTypeSupported()}}, {{HTMLMediaElement/canPlayType()}})
    [[RFC6381]]. In this specification, encoded media is not containerized; hence,
    only the value of the codecs parameter is accepted.

A <dfn>valid codec string</dfn> must meet the following conditions.
1. Is valid per the relevant codec specification (see examples below).

2. It describes a single codec.

NOTE: Not a comma separated list.

3. It is unambiguous about codec profile and level for codecs that define these
    concepts.


<div class='note'>
  NOTE: There is no unified specification for codec strings. Each codec has its
  own unique string format, specified by the authors of the codec. Relevant
  specifications include:

  * h264, aac - [[RFC6381]]
  * vp9 -
      <a href="https://www.webmproject.org/vp9/mp4/#codecs-parameter-string">
        https://www.webmproject.org/vp9/mp4/#codecs-parameter-string
      </a>
  * hevc -
      <a href="https://www.iso.org/standard/74429.html">
        ISO IEC 14496-15 dated 2012 or newer in the Annex E.3
      </a>
  * av1 -
      <a href="https://aomediacodec.github.io/av1-isobmff/#codecsparam">
        https://aomediacodec.github.io/av1-isobmff/#codecsparam
      </a>

</div>

<div class='example'>
Valid examples include:<br>
  * 'vp8'
  * 'vp09.00.10.08'
  * 'avc1.4D401E',
  * 'opus',
  * 'mp4a.40.2',
  * 'flac'

Invalid examples include:<br>
  * 'video/webm; codecs="vp8"' (invalid to supply full mimetype; valid as just
        'vp8')<br>
  * 'codecs="opus"' (invalid to include codecs= prefix)<br>
  * ‘flac,vorbis’ (describes more than one codec)<br>
  * ‘vp9’ (ambiguous about profile and level)<br>
  * 'video/mp4' (describes a container, not a codec)<br>

</div>


AudioDecoderConfig{#audio-decoder-config}
-----------------------------------------
<pre class='idl'>
<xmp>
dictionary AudioDecoderConfig {
  required DOMString codec;
  required unsigned long sampleRate;
  required unsigned long numberOfChannels;
  BufferSource description;
};
</xmp>
</pre>

To check if an {{AudioDecoderConfig}} is a <dfn>valid AudioDecoderConfig</dfn>,
    run these steps:
1. If codec is not a <a>valid codec string</a>, return `false`.
2. Return `true`.

<dl>
  <dt><dfn dict-member for=AudioDecoderConfig>codec</dfn></dt>
  <dd>Contains a codec string describing the codec.</dd>

  <dt><dfn dict-member for=AudioDecoderConfig>sampleRate</dfn></dt>
  <dd>The number of frame samples per second.</dd>

  <dt><dfn dict-member for=AudioDecoderConfig>numberOfChannels</dfn></dt>
  <dd>The number of audio channels.</dd>

  <dt><dfn dict-member for=AudioDecoderConfig>description</dfn></dt>
  <dd>
    A sequence of codec specific bytes, commonly known as extradata.

    NOTE: For example, the vorbis “code book”.
  </dd>
</dl>


VideoDecoderConfig{#video-decoder-config}
-----------------------------------------
<pre class='idl'>
<xmp>
dictionary VideoDecoderConfig {
  required DOMString codec;
  BufferSource description;
  required unsigned long codedWidth;
  required unsigned long codedHeight;
  unsigned long cropLeft;
  unsigned long cropTop;
  unsigned long cropWidth;
  unsigned long cropHeight;
  unsigned long displayWidth;
  unsigned long displayHeight;
};
</xmp>
</pre>

To check if a {{VideoDecoderConfig}} is a <dfn>valid VideoDecoderConfig</dfn>,
run these steps:
1. If {{VideoDecoderConfig/codec}} is not a <a>valid codec string</a>, return
    `false`.
2. If {{VideoDecoderConfig/codedWidth}} = 0 or
    {{VideoDecoderConfig/codedHeight}} = 0, return `false`.
3. If {{VideoDecoderConfig/cropWidth}} = 0 or {{VideoDecoderConfig/cropHeight}}
    = 0, return `false`.
4. If {{VideoDecoderConfig/cropTop}} + {{VideoDecoderConfig/cropHeight}} >=
    {{VideoDecoderConfig/codedHeight}}, return `false`.
5. If {{VideoDecoderConfig/cropLeft}} + {{VideoDecoderConfig/cropWidth}} >=
    {{VideoDecoderConfig/codedWidth}}, return `false`.
6. If {{VideoDecoderConfig/displayWidth}} = 0 or
    {{VideoDecoderConfig/displayHeight}} = 0, return `false`.
7. Return `true`.

<dl>
  <dt><dfn dict-member for=VideoDecoderConfig>codec</dfn></dt>
  <dd>Contains a codec string describing the codec.</dd>

  <dt><dfn dict-member for=VideoDecoderConfig>description</dfn></dt>
  <dd>
    A sequence of codec specific bytes, commonly known as extradata.

    NOTE: For example, the VP9 vpcC bytes.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>codedWidth</dfn></dt>
  <dd>
    Width of the VideoFrame in pixels, prior to any cropping or aspect ratio
        adjustments.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>codedHeight</dfn></dt>
  <dd>
    Height of the VideoFrame in pixels, prior to any cropping or aspect ratio
        adjustments.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>cropLeft</dfn></dt>
  <dd>
    The number of pixels to remove from the left of the VideoFrame, prior to
        aspect ratio adjustments. Defaults to zero if not present.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>cropTop</dfn></dt>
  <dd>
    The number of pixels to remove from the top of the VideoFrame, prior to
        aspect ratio adjustments. Defaults to zero if not present.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>cropWidth</dfn></dt>
  <dd>
    The width of pixels to include in the crop, starting from cropLeft.
        Defaults to codedWidth if not present.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>cropHeight</dfn></dt>
  <dd>
    The height of pixels to include in the crop, starting from cropLeft.
        Defaults to codedHeight if not present.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>displayWidth</dfn></dt>
  <dd>
    Width of the VideoFrame when displayed. Defaults to cropWidth if not
        present.
  </dd>

  <dt><dfn dict-member for=VideoDecoderConfig>displayHeight</dfn></dt>
  <dd>
    Height of the VideoFrame when displayed. Defaults to cropHeight if not
        present.
  </dd>
</dl>


AudioEncoderConfig{#audio-encoder-config}
-----------------------------------------
<pre class='idl'>
<xmp>
dictionary AudioEncoderConfig {
  required DOMString codec;
  unsigned long sampleRate;
  unsigned long numberOfChannels;
};
</xmp>
</pre>

To check if an {{AudioEncoderConfig}} is a <dfn>valid AudioEncoderConfig</dfn>,
run these steps:
1. If {{AudioEncoderConfig/codec}} is not a <a>valid codec string</a>, return
    `false`.
2. Return `true`.

<dl>
  <dt><dfn dict-member for=AudioEncoderConfig>codec</dfn></dt>
  <dd>Contains a codec string describing the codec.</dd>

  <dt><dfn dict-member for=AudioEncoderConfig>sampleRate</dfn></dt>
  <dd>The number of frame samples per second.</dd>

  <dt><dfn dict-member for=AudioEncoderConfig>numberOfChannels</dfn></dt>
  <dd>The number of audio channels.</dd>
</dl>


VideoEncoderConfig{#video-encoder-config}
-----------------------------------------
<pre class='idl'>
<xmp>
dictionary VideoEncoderConfig {
  required DOMString codec;
  unsigned long long bitrate;
  required unsigned long width;
  required unsigned long height;
};
</xmp>
</pre>

To check if a {{VideoEncoderConfig}} is a <dfn>valid VideoEncoderConfig</dfn>,
    run these steps:
1. If {{VideoEncoderConfig/codec}} is not a <a>valid codec string</a>, return
    `false`.
2. If {{VideoEncoderConfig/width}} = 0 or {{VideoEncoderConfig/height}} = 0,
    return `false`.
4. Return `true`.

<dl>
  <dt><dfn dict-member for=VideoEncoderConfig>width</dfn></dt>
  <dd>The expected cropWidth of input VideoFrames to encode.</dd>

  <dt><dfn dict-member for=VideoEncoderConfig>height</dfn></dt>
  <dd>The expected cropHeight of input VideoFrames to encode.</dd>
</dl>


VideoEncoderEncodeOptions{#video-encoder-options}
-------------------------------------------------

<pre class='idl'>
<xmp>
dictionary VideoEncoderEncodeOptions {
  boolean keyFrame = false;
};
</xmp>
</pre>

<dl>
  <dt><dfn dict-member for=VideoEncoderEncodeOptions>keyFrame</dfn></dt>
  <dd>
    A value of `true` indicates that the given frame MUST be encoded as a key
    frame. A value of `false` indicates that the user agent has flexibility to
    decide whether the frame will be encoded as a key frame.
  </dd>
</dl>


CodecState{#codec-state}
------------------------
<pre class='idl'>
<xmp>
enum CodecState {
  "unconfigured",
  "configured",
  "closed"
};
</xmp>
</pre>

<dl>
  <dt><dfn enum-value for=CodecState>unconfigured</dfn></dt>
  <dd>The codec is not configured for encoding or decoding.</dd>
  <dt><dfn enum-value for=CodecState>configured</dfn></dt>
  <dd>
    A valid configuration has been provided. The codec is ready for encoding or
        decoding.
  </dd>
  <dt><dfn enum-value for=CodecState>closed</dfn></dt>
  <dd>
    The codec is no longer usable and underlying system resources have been
      released.
  </dd>
</dl>

WebCodecsErrorCallback{#error-callback}
---------------------------------------
<pre class='idl'>
<xmp>
callback WebCodecsErrorCallback = undefined(DOMException error);
</xmp>
</pre>


Encoded Media Interfaces (Chunks) {#encoded-media-interfaces}
=============================================================
These interfaces represent chunks of encoded media.

EncodedAudioChunk Interface {#encodedaudiochunk-interface}
------------------------------------------------------------
<pre class='idl'>
<xmp>
interface EncodedAudioChunk {
  constructor(EncodedAudioChunkInit init);
  readonly attribute EncodedAudioChunkType type;
  readonly attribute unsigned long long timestamp;  // microseconds
  readonly attribute ArrayBuffer data;
};

dictionary EncodedAudioChunkInit {
  required EncodedAudioChunkType type;
  required unsigned long long timestamp;
  required BufferSource data;
};

enum EncodedAudioChunkType {
    "key",
    "delta",
};
</xmp>
</pre>

### Constructors ###{#encodedaudiochunk-constructors}
<dfn constructor for=EncodedAudioChunk title="EncodedAudioChunk(init)">
  EncodedAudioChunk(init)
</dfn>
1. Let |chunk| be a new {{EncodedAudioChunk}} object, initialized as follows
    1. Assign `init.type` to `chunk.type`.
    2. Assign `init.timestamp` to `chunk.timestamp`.
    3. Assign a copy of `init.data` to `chunk.data`.
5. Return |chunk|.

### Attributes ###{#encodedaudiochunk-attributes}
<dl>
  <dt><dfn attribute for=EncodedAudioChunk>type</dfn></dt>
  <dd>Describes whether the chunk is a key frame.</dd>

  <dt><dfn attribute for=EncodedAudioChunk>timestamp</dfn></dt>
  <dd>The presentation timestamp, given in microseconds.</dd>

  <dt><dfn attribute for=EncodedAudioChunk>data</dfn></dt>
  <dd>A sequence of bytes containing encoded audio data.</dd>
</dl>

EncodedVideoChunk Interface{#encodedvideochunk-interface}
-----------------------------------------------------------
<pre class='idl'>
<xmp>
[Exposed=(Window,Worker)]
interface EncodedVideoChunk {
  constructor(EncodedVideoChunkInit init);
  readonly attribute EncodedVideoChunkType type;
  readonly attribute unsigned long long timestamp;  // microseconds
  readonly attribute unsigned long long? duration;  // microseconds
  readonly attribute ArrayBuffer data;
};

dictionary EncodedVideoChunkInit {
  required EncodedVideoChunkType type;
  required unsigned long long timestamp;
  unsigned long long duration;
  required BufferSource data;
};

enum EncodedVideoChunkType {
    "key",
    "delta",
};
</xmp>
</pre>

### Constructors ###{#encodedvideochunk-constructors}
<dfn constructor for=EncodedVideoChunk title="EncodedVideoChunk(init)">
  EncodedVideoChunk(init)
</dfn>
1. Let |chunk| be a new {{EncodedVideoChunk}} object, initialized as follows
    1. Assign `init.type` to chunk type.
    2. Assign `init.timestamp` to `chunk.timestamp`.
    3. If duration is present in init, assign `init.duration` to
        `chunk.duration`. Otherwise, assign null to `chunk.duration`.
2. Assign a copy of `init.data` to `chunk.data`.
3. Return |chunk|.

### Attributes ###{#encodedvideochunk-attributes}
<dl>
  <dt><dfn attribute for=EncodedVideoChunk>type</dfn></dt>
  <dd>Describes whether the chunk is a key frame or not.</dd>

  <dt><dfn attribute for=EncodedVideoChunk>timestamp</dfn></dt>
  <dd>The presentation timestamp, given in microseconds.</dd>

  <dt><dfn attribute for=EncodedVideoChunk>duration</dfn></dt>
  <dd>The presentation duration, given in microseconds.</dd>

  <dt><dfn attribute for=EncodedVideoChunk>data</dfn></dt>
  <dd>A sequence of bytes containing encoded video data.</dd>
</dl>


Raw Media Interfaces (Frames){#raw-media-interfaces}
====================================================
These interfaces represent unencoded (raw) media.


AudioFrame Interface {#audioframe-interface}
---------------------------------------------

<pre class='idl'>
<xmp>
[Exposed=(Window,Worker)]
interface AudioFrame {
  constructor(AudioFrameInit init);
  readonly attribute unsigned long long timestamp;
  readonly attribute AudioBuffer? buffer;
  undefined close();
};

dictionary AudioFrameInit {
  required unsigned long long timestamp;
  required AudioBuffer buffer;
};
</xmp>
</pre>

### Internal Slots ###{#audioframe-internal-slots}
<dl>
  <dt><dfn attribute for=AudioFrame>\[[detached]]</dfn></dt>
  <dd>
    Boolean indicating whether close() was invoked and underlying resources
        have been released.
  </dd>
</dl>


### Constructors ###{#audioframe-constructors}
<dfn constructor for=AudioFrame title="AudioFrame(init)">
  AudioFrame(init)
</dfn>
1. Let |frame| be a new {{AudioFrame}} object.
2. Assign `init.timestamp` to `frame.timestamp`.
3. Assign `init.buffer` to `frame.buffer`.
4. Assign `false` to the {{AudioFrame/[[detached]]}} internal slot.
5. Return |frame|.


### Attributes ###{#audioframe-attributes}
<dl>
  <dt><dfn attribute for=AudioFrame>timestamp</dfn></dt>
  <dd>The presentation timestamp, given in microseconds.</dd>

  <dt><dfn attribute for=AudioFrame>buffer</dfn></dt>
  <dd>The buffer containing decoded audio data.</dd>
</dl>


### Methods ###{#audioframe-methods}
<dl>
  <dt><dfn method for=AudioFrame>close()</dfn></dt>
  <dd>
    Immediately frees system resources. When invoked, run these steps:
    1. Release system resources for buffer and set its value to null.
    2. Assign `true` to the {{AudioFrame/[[detached]]}} internal slot.

    NOTE: This section needs work. We should use the name and semantics of
        VideoFrame destroy(). Similarly, we should add clone() to make a deep
        copy.
  </dd>
</dl>

VideoFrame Interface {#videoframe-interface}
--------------------------------------------

<pre class='idl'>
<xmp>
[Exposed=(Window,Worker)]
interface VideoFrame {
  constructor(ImageBitmap imageBitmap, VideoFrameInit frameInit);
  constructor(PixelFormat pixelFormat, sequence<(Plane or PlaneInit)> planes,
              VideoFrameInit frameInit);

  readonly attribute PixelFormat format;
  readonly attribute FrozenArray<Plane> planes;
  readonly attribute unsigned long codedWidth;
  readonly attribute unsigned long codedHeight;
  readonly attribute unsigned long cropLeft;
  readonly attribute unsigned long cropTop;
  readonly attribute unsigned long cropWidth;
  readonly attribute unsigned long cropHeight;
  readonly attribute unsigned long displayWidth;
  readonly attribute unsigned long displayHeight;
  readonly attribute unsigned long long? duration;
  readonly attribute unsigned long long? timestamp;

  undefined destroy();
  VideoFrame clone();

  Promise<ImageBitmap> createImageBitmap(
    optional ImageBitmapOptions options = {});

};

dictionary VideoFrameInit {
  unsigned long codedWidth;
  unsigned long codedHeight;
  unsigned long cropLeft;
  unsigned long cropTop;
  unsigned long cropWidth;
  unsigned long cropHeight;
  unsigned long displayWidth;
  unsigned long displayHeight;
  unsigned long long duration;
  unsigned long long timestamp;
};
</xmp>
</pre>

### Internal Slots ###{#videoframe-internal-slots}
<dl>
  <dt><dfn attribute for=VideoFrame>\[[detached]]</dfn></dt>
  <dd>
    Boolean indicating whether {{destroy()}} was invoked and underlying
        resources have been released.
  </dd>
</dl>

### Constructors ###{#videoframe-constructors}

NOTE: this section needs work. Current wording assumes a VideoFrame can always
    be easily represented using one of the known pixel formats. In practice, the
    underlying UA resources may be GPU backed or formatted in such a way that
    conversion to an allowed pixel format requires expensive copies and
    translation. When this occurs, we should allow planes to be null and format
    to be “opaque” to avoid early optimization. We should make conversion
    explicit and user controlled by offering a `videoFrame.convertTo(format)`
    that returns a Promise containing a new VideoFrame for which the
    copies/translations are performed.

<dfn constructor for=VideoFrame title="VideoFrame(imageBitmap, frameInit)">
  VideoFrame(imageBitmap, frameInit)
</dfn>
1. If |frameInit| is not a <a>valid VideoFrameInit</a>, throw a {{TypeError}}.
2. If the value of |imageBitmap|'s' {{PlatformObject/[[Detached]]}} internal
    slot is set to `true`, then throw an {{InvalidStateError}} DOMException.
3. Let |frame| be a new {{VideoFrame}}.
4. Assign `false` to |frame|’s {{VideoFrame/[[detached]]}} internal slot.
5. Use a copy of the pixel data in |imageBitmap| to initialize to following
    frame attributes:
    1. Initialize `frame.pixelFormat` be the underlying format of imageBitmap.
    2. Initialize `frame.planes` to describe the arrangement of memory of the
        copied pixel data.
    3. Assign regions of the copied pixel data to the
        {{Plane/[[plane buffer]]}} internal slot of each plane as
        appropriate for the pixel format.
    4. Initialize `frame.codedWidth` and `frame.codedHeight` describe the width
        and height of the imageBitamp prior to any cropping or aspect ratio
        adjustments.
6. Use |frameInit| to initialize the remaining frame attributes:
    1. If `frameInit.cropLeft` is present, initialize it `frame.cropLeft`.
        Otherwise, default `frame.cropLeft` to zero.
    2. If `frameInit.cropTop` is present, initialize it to `frame.cropTop`.
        Otherwise, default `frame.cropTop` to zero.
    3. If `frameInit.cropWidth` is present, initialize it to `frame.cropWidth`.
        Otherwise, default `frame.cropWidth` to `frame.codedWidth`.
    4. If `frameInit.cropHeight` is present, initialize it to
        `frame.cropHeight`. Otherwise, default `frame.cropHeight` to
        `frame.codedHeight`.
    5. If `frameInit.displayWidth` is present, initialize it to
        `frame.displayWidth`. Otherwise, default `frame.displayWidth` to
        `frame.codedWidth`.
    6. If `frameInit.displayHeight` is present, initialize it to
        `frame.displayHeight`. Otherwise, default `frame.displayHeight` to
        `frame.codedHeight`.
    7. If `frameInit.duration` is present, initialize it to `frame.duration`.
        Otherwise, default `frame.duration` to null.
    8. If `frameInit.timestamp` is present, initialize it to `frame.timestamp`.
        Otherwise default `frame.timestamp` to null.
7. Return |frame|.

<dfn constructor for=VideoFrame title="VideoFrame(pixelFormat, planes, frameInit)">
  VideoFrame(pixelFormat, planes, frameInit)
</dfn>
1. If either {{VideoFrameInit/codedWidth}} or {{VideoFrameInit/codedHeight}} is
    not present in |frameInit|, throw a {{TypeError}}.
2. If |frameInit| is not a <a>valid VideoFrameInit</a>, throw a {{TypeError}}.
3. If the length of |planes| is incompatible with the given pixelFormat, throw a
    TypeError.
4. Let |frame| be a new {{VideoFrame}} object.
5. Assign `false` to |frame|’s {{VideoFrame/[[detached]]}} internal slot.
6. Assign `init.pixelFormat` to `frame.pixelFormat`.
7. For each element |p| in |planes|:
    1. If |p| is a {{Plane}}, append a copy of p to `frame.planes`. Continue
        processing the next element.
    2. If |p| is a {{PlaneInit}}, append a new {{Plane}} <var ignore>q</var> to
        `frame.planes` initialized as follows:
        2. Assign a copy of `p.src` to q's [[plane buffer]] internal slot.

        NOTE: the samples should be copied exactly, but the user agent may add
            row padding as needed to improve memory alignment.

        3. Assign the width of each row in [[plane buffer]], including any
            padding, to  `q.stride`.
        4. Assign `p.rows` to `q.rows`.
        5. Assign the product of (`q.rows` * `q.stride)` to `q.length`
8. Assign `frameInit.codedWidth` to `frame.codedWidth`.
9. Assign `frameInit.codedHeight` to `frame.codedHeight`.
10. If `frameInit.cropLeft` is present, assign it `frame.cropLeft`. Otherwise,
    default `frame.cropLeft` to zero.
11. If `frameInit.cropTop` is present, assign it to `frame.cropTop`. Otherwise,
    default `frame.cropTop` to zero.
12. If `frameInit.cropWidth` is present, assign it to `frame.cropWidth`.
    Otherwise, default `frame.cropWidth` to `frame.codedWidth`.
13. If `frameInit.cropHeight` is present, assign it to `frame.cropHeight`.
    Otherwise, default `frame.cropHeight` to `frame.codedHeight`.
14. If `frameInit.displayWidth` is present, assign it to `frame.displayWidth`.
    Otherwise, default `frame.displayWidth` to `frame.codedWidth`.
15. If `frameInit.displayHeight` is present, assign it to `frame.displayHeight`.
    Otherwise, default `frame.displayHeight` to `frame.codedHeight`.
16. If `frameInit.duration` is present, assign it to `frame.duration`.
    Otherwise, default `frame.duration` to null.
17. If `frameInit.timestamp` is present, assign it to `frame.timestamp`.
    Otherwise, default `frame.timestamp` to null.
18. Return frame.

### Attributes ###{#videoframe-attributes}
<dl>
  <dt><dfn attribute for=VideoFrame>timestamp</dfn></dt>
  <dd>
    The presentation timestamp, given in microseconds. The timestamp is copied
        from the EncodedVideoChunk corresponding to this VideoFrame.
  </dd>
  <dt><dfn attribute for=VideoFrame>duration</dfn></dt>
  <dd>
    The presentation duration, given in microseconds. The duration is copied
        from the EncodedVideoChunk corresponding to this VideoFrame.
  </dd>
  <dt><dfn attribute for=VideoFrame>format</dfn></dt>
  <dd>
    Describes the arrangement of bytes in each plane as well as the number and
        order of the planes.
  </dd>
  <dt><dfn attribute for=VideoFrame>planes</dfn></dt>
  <dd>
    Holds pixel data data, laid out as described by format and Plane
        attributes.
  </dd>
  <dt><dfn attribute for=VideoFrame>codedWidth</dfn></dt>
  <dd>
    Width of the VideoFrame in pixels, prior to any cropping or aspect ratio
        adjustments.
  </dd>
  <dt><dfn attribute for=VideoFrame>codedHeight</dfn></dt>
  <dd>
    Height of the VideoFrame in pixels, prior to any cropping or aspect ratio
        adjustments.
  </dd>
  <dt><dfn attribute for=VideoFrame>cropLeft</dfn></dt>
  <dd>
    The number of pixels to remove from the left of the VideoFrame, prior to
        aspect ratio adjustments.
  </dd>
  <dt><dfn attribute for=VideoFrame>cropTop</dfn></dt>
  <dd>
    The number of pixels to remove from the top of the VideoFrame, prior to
        aspect ratio adjustments.
  </dd>
  <dt><dfn attribute for=VideoFrame>cropWidth</dfn></dt>
  <dd>The width of pixels to include in the crop, starting from cropLeft.</dd>
  <dt><dfn attribute for=VideoFrame>cropHeight</dfn></dt>
  <dd>The height of pixels to include in the crop, starting from cropLeft.</dd>
  <dt><dfn attribute for=VideoFrame>displayWidth</dfn>
  <dd>Width of the VideoFrame when displayed.</dd>
  <dt><dfn attribute for=VideoFrame>displayHeight</dfn></dt>
  <dd>Height of the VideoFrame when displayed.</dd>
</dl>

### Methods ###{#videoframe-methods}
<dfn method for=VideoFrame>destroy()</dfn>
Immediately frees system resources. Destruction applies to all references,
    including references that are serialized and passed across Realms.

NOTE: Authors should take care to manage frame lifetimes by calling
    {{VideoFrame/destroy()}} immediately when frames are no longer needed.

NOTE: Use clone() to create a deep copy. Cloned frames have their own lifetime
    and will not be affected by destroying the original frame.

When invoked, run these steps:
1. If {{VideoFrame/[[detached]]}} is `true`, throw an {{InvalidStateError}}.
2. Remove all {{Plane}}s from {{VideoFrame/planes}} and release associated
    memory.
3. Assign `true` to the {{VideoFrame/[[detached]]}} internal slot.

<dfn method for=VideoFrame>clone()</dfn>
Creates a new {{VideoFrame}} with a separate lifetime containing a deep copy of
    this frame’s resources.

NOTE:  VideoFrames may require a large amount of memory. Use
    {{VideoFrame/clone()}} sparingly.

When invoked, run the following steps:
1. If the value of the {{VideoFrame/[[detached]]}} slot is `true`, return a
    Promise rejected with a newly created {{InvalidStateError}}.
2. Let |p| be a new Promise.
3. In parallel, resolve |p| with the result of running the <a>Clone Frame</a>
    algorithm with <a>this</a>.
4. Return |p|.

<dfn method for=VideoFrame>createImageBitmap(options)</dfn>
Creates an ImageBitmap from this {{VideoFrame}}.

When invoked, run these steps:
1. Let |p| be a new Promise.
2. If either |options|'s {{ImageBitmapOptions/resizeWidth}} or
    {{ImageBitmap/resizeHeight}} is present and is 0, then return |p| rejected
    with an {{InvalidStateError}} {{DOMException}}.
3. If the <a>this'</a> {{VideoFrame/[[detached]]}} internal slot is set to
    `true`, then return |p| rejected with an {{InvalidStateError}}
    {{DOMException}}.
4. Let |imageBitmap| be a new {{ImageBitmap}} object.
5. Set |imageBitmap|'s bitmap data to a copy of the {{VideoFrame}} pixel data,
    at the frame's intrinsic width and intrinsic height (`i.e`., after any
    aspect-ratio correction has been applied), cropped to the source rectangle
    with formatting.
6. If the origin of |imageBitmap|'s image is not same origin with entry settings
    object's origin, then set the origin-clean flag of |imageBitmap|'s bitmap to
    `false`.
7. Run this step in parallel:
  1. Resolve p with imageBitmap.

### Algorithms ###{#videoframe-algorithms}
To check if a {{VideoDecoderConfig}} is a <dfn>valid VideoFrameInit</dfn>,
run these steps:
1. If {{VideoFrameInit/codedWidth}} = 0 or {{VideoFrameInit/codedHeight}} = 0,
    return `false`.
2. If {{VideoFrameInit/cropWidth}} = 0 or {{VideoFrameInit/cropHeight}} = 0,
    return `false`.
3. If {{VideoFrameInit/cropTop}} + {{VideoFrameInit/cropHeight}} >=
    {{VideoFrameInit/codedHeight}}, return `false`.
4. If {{VideoFrameInit/cropLeft}} + {{VideoFrameInit/cropWidth}} >=
    {{VideoFrameInit/codedWidth}}, return `false`.
5. If {{VideoFrameInit/displayWidth}} = 0 or
    {{VideoFrameInit/displayHeight}} = 0, return `false`.
6. Return `true`.


Plane Interface {#plane-interface}
----------------------------------
A {{Plane}} acts like a thin wrapper around an {{ArrayBuffer}}, but may actually
    be backed by a texture. {{Plane}}s hide any padding before the first sample
    or after the last row.

A {{Plane}} is solely constructed by its {{VideoFrame}}. During construction,
    the User Agent may use knowledge of the frame’s {{PixelFormat}} to add
    padding to the {{Plane}} to improve memory alignment.

A {{Plane}} cannot be used after the {{VideoFrame}} is destroyed. A new
    {{VideoFrame}} can be assembled from existing {{Plane}}s, and the new
    {{VideoFrame}} will remain valid when the original is destroyed. This makes
    it possible to efficiently add an alpha plane to an existing {{VideoFrame}}.


<pre class='idl'>
<xmp>
interface Plane {
  readonly attribute unsigned long stride;
  readonly attribute unsigned long rows;
  readonly attribute unsigned long length;

  undefined readInto(ArrayBufferView dst);
};

dictionary PlaneInit {
  required BufferSource src;
  required unsigned long stride;
  required unsigned long rows;
};
</xmp>
</pre>

### Internal Slots ###{#plane-internal-slots}
<dl>
  <dt><dfn attribute for=Plane>[[parent frame]]</dfn></dt>
  <dd>Refers to the {{VideoFrame}} that constructed and owns this plane.</dd>
  <dt><dfn attribute for=Plane>[[plane buffer]]</dfn></dt>
  <dd>Internal storage for the plane’s pixel data.</dd>
</dl>

### Attributes ###{#plane-attributes}
<dl>
  <dt><dfn attribute for=Plane>stride</dfn></dt>
  <dd>The width of each row including any padding.</dd>
  <dt><dfn attribute for=Plane>rows</dfn></dt>
  <dd>The number of rows.</dd>
  <dt><dfn attribute for=Plane>length</dfn></dt>
  <dd>The total byte length of the plane (stride * rows).</dd>
</dl>

### Methods ###{#plane-methods}
<dfn method for=Plane>readInto(dst)</dfn>

Copies the plane data into dst.

When invoked, run these steps:
1. If {{Plane/[[parent frame]]}} has been destroyed, throw an
    {{InvalidStateError}}.
2. If {{Plane/length}} is greater than |`dst.byteLength`|, throw a
    {{TypeError}}.
3. Copy the {{Plane/[[plane buffer]]}} into <var ignore>dst</var>.


Pixel Format{#pixel-format}
---------------------------
Pixel formats describe the arrangement of bytes in each plane as well as the
number and order of the planes.

NOTE: This section needs work. We expect to add more pixel formats and offer
    much more verbose definitions. For now, please see
    <a href="http://www.fourcc.org/pixel-format/yuv-i420/">
    http://www.fourcc.org/pixel-format/yuv-i420/</a> for a more complete
    description.

<pre class='idl'>
<xmp>
enum PixelFormat {
  "I420"
};
</xmp>
</pre>

<dl>
  <dt><dfn enum-value for=PixelFormat>I420</dfn></dt>
  <dd>
    Planar 4:2:0 YUV.
  </dd>
</dl>


Algorithms{#raw-media-algorithms}
---------------------------------
<h3 id='clone-frame-algo'><dfn>Clone Frame</dfn> (with |frame|)</h3>

1. Let |cloneFrame| be a new object of the same type as frame (either
    {{AudioFrame}} or {{VideoFrame}}).
2. Initialize each attribute and internal slot of clone with a copy of the value
    from the corresponding attribute of this frame.

NOTE: User Agents are encouraged to avoid expensive copies of large objects
    (for instance, {{VideoFrame}} pixel data). Frame types are immutable, so the
    above step may be implemented using memory sharing techniques such as
    reference counting.

3. Return |cloneFrame|.


VideoTrackReader Interface{#videotrackreader-interface}
=======================================================
{{VideoTrackReader}} emits {{VideoFrame}}s from a {{MediaStreamTrack}}. Authors
may use this interface to manipulate, render, or encode streams from
{{mediaDevices/getUserMedia()}} and {{mediaDevices/getDisplayMedia()}}.

<pre class='idl'>
<xmp>
[Exposed=Window]
interface VideoTrackReader {
  constructor(MediaStreamTrack track);

  readonly attribute VideoTrackReaderState readyState;
  attribute EventHandler onended;

  undefined start(VideoFrameOutputCallback callback);
  undefined stop();
};

enum VideoTrackReaderState {
  "started",
  "stopped",
  "ended"
};
</xmp>
</pre>

VideoTrackReaderState Values{#videotrackreaderreadystate}
--------------------------------------------------------------
<dl>
  <dt><dfn enum-value for=VideoTrackReaderState>started</dfn></dt>
  <dd>
    Indicates that the {{VideoTrackReader/[[track]]}} is
        {{MediaStreamTrackState/live}} and {{VideoFrame}}s are being output to
        the {{VideoTrackReader/[[callback]]}} provided to
        {{VideoTrackReader/start()}}.

  </dd>
  <dt><dfn enum-value for=VideoTrackReaderState>stopped</dfn></dt>
  <dd>
    Indicates that the {{VideoTrackReader/[[track]]}} is
        {{MediaStreamTrackState/live}}, but the
        {{VideoTrackReader/[[callback]]}} is not set, so no {{VideoFrame}}s are
        being output.
  </dd>
  <dt><dfn enum-value for=VideoTrackReaderState>ended</dfn></dt>
  <dd>
    Indicates that the {{VideoTrackReader/[[track]]}} is
        {{MediaStreamTrackState/ended}} and this object can no longer be
        {{VideoTrackReaderState/started}} nor {{VideoTrackReaderState/stopped}}.
  </dd>
</dl>

Internal Slots {#videotrackreader-slots}
----------------------------------------
<dl>
  <dt><dfn attribute for=VideoTrackReader>\[[track]]</dfn></dt>
  <dd>The {{MediaStreamTrack}} provided at construction.</dd>
  <dt><dfn attribute for=VideoTrackReader>\[[callback]]</dfn></dt>
  <dd>
    The {{VideoFrameOutputCallback}} assigned by the last call to
      {{VideoTrackReader/start()}}.
  </dd>
</dl>


Constructors{#videotrackreader-constructors}
---------------------------------------------
<dfn constructor for=VideoTrackReader title="VideoTrackReader(track)">
  VideoTrackReader(track)
</dfn>
1. If `track.kind` is not `"video"`, throw a {{TypeError}}.
2. If `track.readyState` is `"ended"`, throw an {{InvalidStateError}}.
3. Let |reader| be a new {{VideoTrackReader}} object.
4. Assign <var ignore>track</var> to the {{VideoTrackReader/[[track]]}} internal
    slot.
5. Assign `"stopped"` to `reader.readyState`.
6. Return |reader|.


Attributes{#videotrackreader-attributes}
----------------------------------------
<dl>
  <dt><dfn attribute for=VideoTrackReader>readyState</dfn></dt>
  <dd>
    Indicates the current state of the {{VideoTrackReader}} object.
  </dd>
  <dt><dfn attribute for=VideoTrackReader>onended</dfn></dt>
  <dd>The event handler for the ended event.</dd>
</dl>

Event Summary{#videotrackreader-events}
---------------------------------------
<dl>
  <dt><dfn event for=VideoTrackReader>ended</dfn></dt>
  <dd>
    Dispatched when the {{VideoTrackReader/[[track]]}}'s
        {{VideoTrackReader/readyState}} becomes `"ended"`, indicating no further
        {{VideoFrame}}s will be output.
  </dd>
</dl>


Methods{#videotrackreader-methods}
----------------------------------
<dfn method for=VideoTrackReader>start(callback)</dfn>

Starts calling the callback with {{VideoFrame}}s from the {{MediaStreamTrack}}.

When invoked, run these steps:
1. If {{VideoTrackReader/readyState}} is not `"stopped"`, throw an
    {{InvalidStateError}}.
2. Assign `"started"` to {{VideoTrackReader/readyState}}.
3. Assign <var ignore>callback</var> to the {{VideoTrackReader/[[callback]]}}
    internal slot.
4. In parallel, <a>run the track monitor</a>.

<dfn method for=VideoTrackReader>stop()</dfn>

Stops calling the {{VideoFrameOutputCallback}} with {{VideoFrame}}s from the
    {{MediaStreamTrack}}.

When invoked, run these steps:
1. If readyState is not `"started"`, throw an {{InvalidStateError}}.
2. Cease <a>running the track monitor</a>.
3. Assign `"stopped"` to the {{VideoTrackReader/readyState}}.
4. Assign `null` to the {{VideoTrackReader/[[callback]]}} internal slot.


MediaStreamTrack Monitoring{#mediastreamtrack-monitoring}
---------------------------------------------------------

The <dfn export>track monitor</dfn> may be started and stopped by the user to
    control the calling of the {{VideoFrameOutputCallback}}.

<dfn lt="running the track monitor|run the track monitor">Running the track
    monitor</dfn> means monitoring {{VideoTrackReader/[[track]]}} for the
    arrival of new picture data as well as changes to `[[track]].readyState`.

While `[[track]].readyState` is {{MediaStreamTrackState/live}}, for each new
    picture that arrives in {{VideoTrackReader/[[track]]}}, execute the
    following steps:

    NOTE: Pictures that arrived prior to the start of this loop are not
        considered.


    NOTE: Video data in a MediaStreamTrack does not have a canonical binary
        form. The user agent should tokenize "pictures" by discrete times of
        capture. For example, if the source is a camera capturing 60 frames per
        second, the UA should construct 60 corresponding VideoFrame's each
        second.

1. Let |planes| be a sequence of {{Plane}}s containing the picture data.
2. Let |pixelFormat| be the {{PixelFormat}} of |planes|.

    NOTE: This section needs work. The UA should avoid early optimizations to
        convert between PixelFormats, but currently only a narrow set of formats
        is defined in this spec. We should consider adding an "opaque" format
        along with an API coverter API to make pixel format conversion
        transparent to authors.


3. Let |frameInit| be an {{VideoFrameInit}} with the following keys:
    1. Let <var ignore>timestamp</var> and <var ignore>duration</var> be the
        presentation timestamp and (optionally) presentation duration as
        determined by the {{VideoTrackReader/[[track]]}} source.
    2. Let <var ignore>codedWidth</var> and <var ignore>codedHeight> be the
        width and height of the decoded video frame in pixels, prior to any
        cropping or aspect ratio adjustments.
    3. Let <var ignore>cropLeft</var>, <var ignore>cropTop</var>,
        <var ignore>cropWidth</var>, and <var ignore>cropHeight</var> be the
        crop region of the decoded video frame in pixels, prior to any aspect
        ratio adjustments.
    4. Let <var ignore>displayWidth</var> and <var ignore>displayHeight</var>
        be the display size of the decoded video frame in pixels.
4. Let |frame| be a {{VideoFrame}}, constructed with |pixelFormat|,
        |planes|, and |frameInit|.
5. Invoke {{VideoTrackReader/[[callback]]}} with |frame|.

If {{VideoTrackReader/[[track]]}}.readyState becomes `"ended"`,
    <a>queue a task</a> on the media element task source to run the
    following steps:

1. Set {{VideoTrackReader/readyState}} to "ended".
2. <a>Queue a task</a> on the media element task source to run a simple
    event named {{VideoTrackReader/ended}} at the {{VideoTrackReader}}.
